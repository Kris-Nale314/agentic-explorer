{
  "type": "earnings_call_mix",
  "companies": [
    "DELL",
    "NVDA",
    "AAPL"
  ],
  "transcripts": [
    {
      "symbol": "DELL",
      "date": "2025-02-28 17:26:00",
      "quarter": 4,
      "year": 2025,
      "content": "Operator: Good afternoon and welcome to the Fiscal Year 2025 Fourth Quarter Financial Results Conference Call for Dell Technologies Inc. I'd like to inform all participants that this call is being recorded at the request of Dell Technologies. This broadcast is a copyrighted property of Dell Technologies Inc. Any rebroadcast of this information in whole or part without the prior written permission of Dell Technologies is prohibited. [Operator Instructions] I'd like to turn the call over to Paul Frantz, Head of Investor Relations. Mr. Frantz, you may begin.\nPaul Frantz: Thanks, everyone, for joining us. With me today are Jeff Clarke, Yvonne McGill and Tyler Johnson. Our earnings materials are available on our IR website, and I encourage you to review those materials. Also, please take some time to review the presentation, which includes additional content to complement our discussion this afternoon. Guidance will be covered on today's call. During this call, unless otherwise indicated, all references to financial metrics refer to GAAP financial measures, including non- GAAP gross margin, operating expenses, operating income, net income, diluted earnings per share, free cash flow and adjusted free cash flow. A reconciliation of these measures to the most directly comparable GAAP measures can be found in our web deck and our press release. Growth percentages refer to year-over-year change unless otherwise specified. Statements made during this call that relate to future results and events are forward-looking statements based on current expectations. Actual results and events could differ materially from those projected due to a number of risks and uncertainties, which are discussed in our web deck and SEC filings. We assume no obligation to update our forward-looking statements. Now I'll turn it over to Jeff.\nJeff Clarke: Thanks, Paul, and thanks, everyone, for joining us. I am proud of the team's execution this year. We navigated an incredibly dynamic AI environment and accelerating server consolidation, a significant pivot to Dell IP storage and a lagging PC refresh and delivered results above our long-term value-creation framework. We grew our company while reducing our operating expenditures over the course of the year. Our modernization have made us more efficient and provided us the ability to invest more innovation and in areas of strategic differentiation. Our FY '25 revenue was $95.6 billion, up 8%, with operating income of $8.5 billion. OpEx was reduced by 4% over the course of the year. This resulted in record EPS of $8.14, up 10%, and cash flow of $4.5 billion. We continue to differentiate ourselves with consistent performance through numerous economic cycles, different technology buying and adoption cycles and our rapidly innovating technology ecosystem. Some examples of the innovation from this past year. We added five platforms to our AI-optimized portfolio, including support of the oil architectures, the highlight being the PowerEdge XE9712 supporting NVIDIA's NVL72 GB200, which we were the first to ship in the world. We launched the Dell Infrastructure Rack Sobel system, our IR7000 and 5000 in both 21-inch and 19-inch versions, providing up to 96 GPUs in a rack and 786 GPUs in a scalable unit. We have made significant advancements of CPUs, cold plates metals and power distribution with our IR7000 supporting up to 480 kilowatts per rep. We introduced our direct-to-chip liquid cooling version of the 9680, providing 33% density improvement and 2.5x improvement in energy efficiency. We made significant advancements to PowerStore with PowerStore Prime, our mid-range storage solution addressing the fastest-growing portion of the market. And we introduced the PowerScale F910 and F710 in our unstructured portfolio that is prime to support unstructured and AI workloads. We introduced the most Copilot+ PCs powered by ARM-based Qualcomm Snapdragon processors and also launched the broadest portfolio of Intel Meteor Lake commercial PCs, furthering our number one leadership position in commercial AI PCs worldwide. We continued our number one leadership in PC monitors with the world's first 4k monitors to achieve 5-star Eye Comfort certification. focused on expanding our peripherals portfolio selling everything around the PC docking stations, cameras, mice, keyboards and headsets, including the first and only holistic solution to manage your fleet of PCs and peripherals remotely, creating the best possible customer experience. And finally, we simplified our branding, redesigned our PC portfolio and broadened our silicon options across Intel, AMD and Qualcomm, setting us up well for the PC refresh. We are extremely well positioned to capture growth across every segment of our business and extend AI from the largest at-scale CSPs to enterprise workloads and out to the edge with the PC. These tailwinds and our unique operating model that leverages our leading product positions, our go-to-market engine, services and supply chain, underpin our confidence that our opportunity continues to grow as we look ahead to FY '26. Moving to Q4. Revenue was $23.9 billion, up 7%, driven by a robust ISG growth. We executed particularly strong with substantial operating margin improvement in ISG driven by our Dell IP storage portfolio. This resulted in EPS of $2.68, up 18%, growing faster than revenue. Turning to BU results. Let's start with ISG. The prospects for AI are strong, and we are very well positioned. In Q4, AI orders demand was $1.7 billion with $2.1 billion in shipments in order with $4.1 billion in backlog as customers work through technology changes. And in February, our partnership with XAI and other customers continued. We booked deals putting our AI backlog at roughly $9 billion as of today. Our pipeline expanded sequentially and has grown every quarter since the introduction of the 9680. We are seeing continued progress in AI from enterprise customers, albeit still earlier in their journey with sequential growth in both orders and customers. And our engineering services, financing and ability to optimize density and performance per watt are important differentiators for the largest at-scale CSPs and provide very efficient enterprise solutions. In traditional servers, the growth trajectory continues, up double digits in Q4. We've now seen 5 quarters of year-over-year demand. Our mix of 16G servers continues to increase as customers remain focused on consolidation to improve power efficiency and increase floor space. The server consolidation in the data center is expanding server TRUs driven by service with more CPU cores, storage and memory. In storage, we saw P&L growth for the second consecutive quarter with very strong profitability driven by our Dell IP storage portfolio. PowerStore, our flagship midrange product, has had strong demand growth for four consecutive quarters, the most recent three at double-digit demand growth. As I mentioned, the software and hardware updates we made with PowerStore Prime resonate with customers and partners. We have industry-leading 5:1 data reduction, delivered 30% improvement in IOPS Native MetroSync and QLC availability. We also saw double-digit demand growth in PowerScale, our leading unstructured storage platform, and continued growth in our buyer base with PowerFlex. We are well positioned in some of the fastest-growing categories within storage as customers shift towards disaggregated architectures. In CSG, we are seeing the recovery coming with strength in SMB, which historically is a leading indicator. We also saw large opportunities within the quarter, which were very competitive. Commercial was up 5%, marking the second consecutive quarter of year-over-year growth and the fourth consecutive quarter of demand growth. Consistent with what we saw coming out of Q3, customers are waiting to refresh to buy AI PCs that future-proof their purchases going forward. Consumer continues to be challenged with softer demand and elevating levels of discounting. We expect a broader PC refresh this year as the installed base continues to age, we get closer to the Windows 10 end of life and AI PCs are more broadly available. To close, I am proud of our FY '25 results and our ability to execute our strategy, leveraging our strengths to extend our leadership positions and capture new growth. The AI hardware and services TAM has nearly doubled over the course of the year to $295 billion in 2027, growing at a 33% CAGR. We are well positioned in AI, traditional servers, storage with our focus on Dell IP and PCs, including everything around the device. We continue to drive a disproportionate level of AI growth by demonstrating the value we provide to our customers and I'm excited for the tailwinds surrounding our business as we enter FY '26. Now over to Yvonne for more details about Q4.\nYvonne McGill: Thanks, Jeff. Let me begin with an overview of our Q4 performance, then I'll move to ISG, CSG cash and guidance. In the fourth quarter, we delivered strong profitability, specifically in ISG. Our total revenue was up 7% to $23.9 billion. This was driven by continued strength in servers. Our combined ISG and CSG business grew 10%. Gross margin was $5.8 billion or 24.3% of revenue. This is down 50 basis points due to a more competitive pricing environment, predominantly in CSG and an increase in our AI-optimized server mix. Within gross margin, we discovered previously unrecognized accumulated credits from suppliers. You'll find revised financial results within our Q4 press release that reflect higher gross margin and increased earnings per share for the relevant period. Operating expense was down 6% to $3.1 billion or 13.1% of revenue. FY '25 was a transformative year as we reevaluated, reimagined and modernized how we operate. This enabled us to unlock efficiencies and increase productivity, all while growing our core business double digits. Now let's look at operating income. We delivered a 22% increase to $2.7 billion or 11.2% of revenue. This was driven by higher revenue and lower operating expenses, partially offset by a decline in our gross margin rate. Q4 net income was up 15% to $1.9 billion primarily driven by stronger operating income. And our diluted EPS was up 18% to $2.68. Now let's move to ISG, where we delivered another quarter of strong performance. ISG revenue was $11.4 billion, up 22%. Servers and networking revenue was a Q4 record at $6.6 billion, up 37%. We continue to see strong demand across both AI and traditional servers. Storage revenue was up 5% to $4.7 billion, a second consecutive quarter of growth. We executed very well in storage. We had a record demand quarter for PowerStore. PowerScale grew double digits, and our PowerFlex buyer base grew. While the overall demand environment is lagging that of traditional servers, we see some promising trends. We had record ISG operating income of $2.1 billion, up 44%. This was driven primarily by higher revenue. Our ISG operating income rate was up again sequentially to a record 18.1% of revenue. The rate improvement of 480 basis points was the result of improved gross margins, especially in storage, and reduced operating expense. Within storage, we saw record profitability driven by a higher mix of Dell IP versus partner IP, improved product profitability and revenue scaling in what is seasonally our strongest quarter. Now let's turn to CSG. CSG revenue was up 1% to $11.9 billion. Commercial revenue was up 5% to $10 billion, while consumer revenue was down 12% to $1.9 billion. CSG operating income was $0.6 billion or 5.3% of revenue. This is down 90 basis points sequentially due to a more competitive pricing environment. We saw some promising signs as we went through November and December with pockets of strength in large deals, but overall saw a slowdown in January. As Jeff mentioned, we saw strength in small and medium business, which is historically a leading indicator. Profitability in commercial was weaker than expected as demand continued to push into the next fiscal year. In consumer, the demand environment remains soft and profitability remains challenged. We are ready and well positioned for a PC refresh with our simplified rebrand, leading go-to-market engine and focus on commercial PCs, the most profitable segments of the market. Shifting gears, Dell Financial Services continues to drive differentiated payment solutions for our customers. We exited the year with a record $15 billion in assets under management, up 5%. And when you normalize for the exit of our VMware resell business and the discontinuation of our commercial revolving product, DFS originations were up 7% in Q4 with a strong attach rate across the business. Now let's move to cash flow and the balance sheet. Q4 cash flow from operations was $0.6 billion. This was primarily driven by profitability, partially offset by working capital. Our cash conversion cycle was negative 31 days with $6.7 billion in inventory. We ended the quarter with $5.2 billion in cash and investments, down $1.4 billion sequentially. Our core leverage ratio was down sequentially to 1.2x. We returned $1.1 billion of capital to shareholders with 6.4 million shares of stock repurchased at an average price of $117.51 and paid a dividend of $0.45 per share. Since our capital reaching program began at the beginning of FY '23, we've returned $10.8 billion to shareholders through stock repurchases and dividends. We announced an 18% increase in our annual dividend to $2.10 per share, well above our long-term value-creation framework. Additionally, the Board of Directors has approved a $10 billion increase in our share repurchase authorization. This is a testament to our confidence in the business and our ability to generate strong cash flow. Turning to FY '26 guidance. IT spending is expected to grow with 3 underlying trends that we see. First, businesses are leveraging AI to enable competitive advantages, and we are seeing that in our opportunity pipeline that continues to expand. Second, data center modernization is well underway with a focus on consolidation and power efficiency. Third, customers are planning to refresh their PC installed base with AI-enabled devices. As these trends materialize, we will leverage our operating model that has driven value creation over the last 40 years. Against that backdrop, we expect revenue and EPS growth in FY '26 above our long-term value-creation framework. We expect FY '26 revenue to be between $101 billion and $105 billion with a midpoint of $103 billion, up 8%. We expect ISG to grow high teens driven by $15 billion of AI server shipments and continued growth in traditional server and storage. And we expect CSG to grow low to mid-single digits, more weighted towards the second half of the year. We expect the combination of ISG and CSG to grow 10% at the midpoint. Given the higher mix of our AI-optimized servers and the current competitive environment, we expect our gross margin rate to decline roughly 100 basis points. As our modernization efforts continue, we expect OpEx to be down low single digits year-over-year. We expect ISG operating income rate to be roughly flat year-over-year with CSG down slightly. We expect I&O to be between $1.4 billion and $1.5 billion. Diluted non-GAAP EPS is expected to be $9.30 plus or minus $0.25, up 14% at the midpoint, assuming an annual non-GAAP tax rate of 18%. For Q1, we expect revenue to be between $22.5 million and $23.5 billion, up 3% at the midpoint of $23 billion. ISG and CSG combined are expected to grow 6% at the midpoint with ISG growing low teens and CSG flat year-over-year. Gross margin rate will be lower sequentially given seasonally lower storage mix and a higher AI-optimized server mix. OpEx will be down low single digits year-over-year. We expect operating income rate to be down sequentially given typical seasonality in ISG with lower storage mix. We expect our diluted share count to be between 706 million and 710 million shares, and our diluted non-GAAP EPS is expected to be $1.65 plus or minus $0.10, up 25% at the midpoint. In closing, we delivered solid FY '25 results, well above our long-term value-creation framework. We generated $95.6 billion in revenue, record EPS of $8.14 and returned $3.9 billion of capital to our shareholders. We executed our strategy and expanded our lead in AI while positioning our core business for the opportunity ahead. Internally, we began a transformation to future-proof the company, focusing on supplying, automating and modernizing how we work. And as we look forward, I'm excited about the sustainable growth we see and the value we will continue to deliver to our customers and our shareholders. Now I'll turn it back to Paul to begin Q&A.\nPaul Frantz: Thanks, Yvonne. Let's get to Q&A. In order to ensure we get to as many of as possible, please ask one concise question. Let's go to the first question, operator.\nOperator: [Operator Instructions]. And the first question comes from Wamsi Mohan with Bank of America.\nWamsi Mohan: Yes, thank you so much. Yvonne, could you talk through the fiscal '26 guide? And what sort of maybe some of the assumptions that are incorporated beyond what you stated? Your revenues are going to be up roughly in total about 7.7%, EPS up about 14%. But your comments on ISG and CSG margins are flat to down, and you noted a fairly competitive environment. So can you just bridge those sort of comments to your EPS growth? How much is coming potentially from buybacks? And have you made any tariff-related assumptions in these margin guides? Thank you so much.\nYvonne McGill: Thanks, Wamsi. So yes, in the guide for the year, we guided to the $103 billion of midpoint, up 8%, with everything growing, right? ISG and CSG expected to be up combined about 10%. If I look at ISG, which I think some of your question is coming from, we expect that to be in the high teens, fueled by that $15 billion of AI server shipments that we referred to as well as continued growth in both traditional server and storage, I'd say with storage in the low single digits. CSG, we do expect to grow in the mid-single digits coming up for the year that's just begun with that refresh cycle that we're expecting to be more weighted towards the second half of the year. OpEx is another area. We guided to it being down low single digits year-over-year. That's just a continuation of all of the efficiencies that we're driving across the entire company. And then the improving year-over-year to the 9.1%, up from 8.9%, so an improvement there. When I think of what to expect from an ISG standpoint from an offing level, we're saying roughly flat year-over-year. And we expect there to be continued competition, I guess, is the right way to put it in CSG. But again, we've guided and embedded that in there. And I go back to ISG real quick and say, hey, we are going to be growing the AI business while continuing to drive profitability there. So we'll continue to balance, as we have been doing, our growth and profitability. And we're going to manage pricing, we're going to manage the competitive environment, and we're going to continue to drive value for our shareholders.\nJeff Clarke: Thanks, Wamsi.\nOperator: And the next question comes from Erik Woodring with Morgan Stanley.\nErik Woodring: Great guys, thanks so much for taking my question. Jeff, a question I often get from investors is kind of about the risk of ODM encroachment in the AI server market. As customers get more sophisticated over time, competition intensifies, potentially margins face downward pressure. Effectively, the concern is AI servers become somewhat of a cloud 2.0 type of disintermediation. Clearly, your AI server backlog helps to refute this concern. But I would love if you could just maybe -- how would you respond to those concerns if you got that question? Thanks so much.\nJeff Clarke: Sure. Thanks, Erik. I mean, do we see the ODMs in these large opportunities? Of course, we do. These are multibillion-dollar opportunities. Everybody tends to show up and wants an opportunity to win the business. When I step back and reflect why Dell and why we continue to be optimistic here is this is custom work. It takes significant engineering capability. It takes significant architecture capability to win. And in many cases, we're building a unique and differentiated solution for each and every customer. And our customers have learned to value what we've been able to bring to them across their deployments, whether that is the service side when we extend beyond an L10 server out of the factory with L11 and L12 and full integration of Iraq, on the network expertise we bring to do the install and deployment of very complex network arrays. When I think about service, the ability that we have a global service footprint, professional servers can show up anywhere to solve any related problem or hands-on in these very large deployments with full-time teams. Literally, they're 24/7 trying to get them up and running. I think about the financing capabilities that we have in our company and the ability to help these CSPs, these fast- growing companies grow at the rates they want with our financing capabilities, I think about our go-to-market coverage and I think about the expertise we have in the top 30-or-so CSPs digital natives, our ability to scale this to enterprise. Erik, every time I look at this question, and I don't really focus on ODMs or for that matter, other OEMs. I look at the differentiated value we are bringing to the marketplace with the Dell company bringing end-to-end solutions. And right now, it's valued. And right now, we continue to differentiate. Right now, we help these large scale clusters get deployed faster than anybody else. I'll remind you, I probably did last time as well, we were the first to bring to market a GB200 rack. That's not by luck. It's by a lot of hard work, detailed engineering, collaborating in this case with NVIDIA and our customer to be able to take out every ounce of time and run at the speed of light, so to speak. So we're going to continue to invest in that differentiation. We're going to continue to make us stand out to be different. Our customers really value the full range of our capabilities. They like the notion of a one place to go. I'm not sure others bring that. I know we do, and I know we're extracting value from the marketplace for that with our customers and our deployments.\nErik Woodring: Awesome. Thank you, Jeff. I appreciate it. Good luck, guys.\nJeff Clarke: You're welcome.\nOperator: And the next question will come from Simon Leopold with Raymond James.\nSimon Leopold: Thank you very much for taking the question. I was wondering if you could give us your thoughts on your exposure to the U.S. federal government. Basically, how big is it typically as a percent of your revenue? And how are you thinking about the trend given all the noise we hear out of Washington around budget cuts and spending cuts?\nYvonne McGill: So Simon, I'll take a pass at that. We do business in 170-plus countries around the world. Obviously, our largest country is the United States, and we do business with the federal government. But I can't really parse out exactly what you're asking for. We're certainly going to lean into all opportunities that are ahead of us and continue to be successful in that space. I don't know...\nJeff Clarke: No, I would add to what Yvonne said. We've had numerous times in our history where a country or a particular segment demand was suppressed for various reasons. We've been able to navigate the cycles, I think, pretty successfully. Our underlying belief is United States government will need technology. AI plays a pretty significant role in our nation. And I think the demand will materialize. We'll get through whatever is happening today. And we have a broad business to be able to do that. Whether it's PC, servers, storage, AI solutions, our services making it up in other parts of the world, other parts of the United States, we've again proven we've done that consistently, and we'll do so here.\nYvonne McGill: We can help drive efficiencies in every environment. So excited about the opportunity ahead.\nSimon Leopold: Thanks, Yvonne.\nOperator: And our next question will come from Aaron Rakers with Wells Fargo.\nAaron Rakers: Yes, thanks for taking the question. Just building on Erik's fire question, I'm curious, Jeff, as we really start to see the materialization of the Blackwell product cycle through your AI backlog, I'm curious, when you're engaged in like rack scale configurations, how would you compare the margin profile of those relative to the AI business on, let's say, the Hopper product cycle? And can you talk a little bit about the levers that you see to improve that margin as we move through 2025? Thank you.\nJeff Clarke: Sure, Aaron. I think I mentioned in the last call that the Blackwell margins were lower than the Hopper margins and remains so today. We're still early. The deals are very large upfront. There's more competitors, so it's a more competitive landscape. And I'll probably sound a little redundant with the last answer with Erik. Look, this is a system design and architecture work. There's an ability to really distinguish our engineering and value add in that step, which is an opportunity for us to extract value and opportunity for us to reduce cost. These aren't reference designs or as we would affectionately call in the engineering community, they're not cookie-cutter designs. We're designing a unique rack, a unique power distribution unit. Our cooling, our manifold, the cold plate, the ability to engineer that and to drive that through the scale of our supply chain are opportunities for us, helping our customers attach with our networking with our storage or opportunities. And while still small, it remains an opportunity because every large cluster, and for that matter, every AI workload requires data to fulfill its need. Services, installation, deployment, those are value-add opportunities for us that we continue to build on, and then obviously, the ability to be a time-to-market advantage. Those are areas that we continue to focus on. They drive differentiation. I think Yvonne and I have been consistent for the better part of the year that AI servers are margin rate-dilutive. They are margin dollar-accretive. They are operating margin-positive. They are profitable. And what's really interesting for us, if we take the work that we're doing in these large clusters, it really scales nicely to the enterprise. It allows us to really take the efficiencies and learnings from what we're doing with the largest clusters in the world and build optimized solutions for very specific domain-specific AI use cases. And our experience to date is the AI margins in enterprise are better, and I think they'll continue to be, and that's what we're focusing on.\nAaron Rakers: Okay, thanks, Eric.\nOperator: And our next question will come from Michael Ng with Goldman Sachs.\nMichael Ng: Hi good afternoon. Thank you for the question. I just have one on the ISG margin outlook of flat year-over-year for the upcoming year. It's a great outlook, particularly considering AI server revenues growing 50%. So can you talk a little bit about the expectations for margins for some of the components, traditional servers, storage AI servers? I'm just trying to understand the ability to keep ISG margins flat despite presumably the dilutive effect from the AI server margins. Thank you.\nJeff Clarke: I think, Mike, maybe the way to look at this is the, first and foremost, as we think about holding ISG margins flat, I love the way that you asked the question, we're going to do that by growing at least $15 billion in AI servers. I know your question is how we're going to do that. But for us, that's a very important mark that we're going to be able to meet that operating range that we've committed in our long-term framework and we're going to grow at a minimum of $15 billion in AI servers. And we're going to do that by what we've done in traditional servers and what we've done in storage. The storage leverage that Yvonne talked about earlier is front and center. When we grow the storage business and we control our expenses, scale matters, the operating margins improve. When we pivot to Dell IP storage, which we have done, our margins improve. The margins of our own IP are vastly superior than third-party IP. We've been doing that for some time. We made mention, I think, in our remarks about PowerStore. It's grown four consecutive quarters on the van line, the last three, double-digit; in the largest space in the external storage marketplace, midrange. It has differentiated features. We're going to continue to leverage our IP storage. We're building out the customer base with our direct sales force and our partner-first channel program. We're continuing to invest in the innovation and differentiation in our storage. And with our coverage, the broadest coverage in our industry, and the deepest specialty capability, we're going to continue to grow the customer base, which I might add, the PowerFlex customer base grew, the PowerScale customer base grew, the PowerStore customer base grew. And then lastly, we're looking to attach more storage to every AI opportunity that we have. Our traditional storage business continues to grow, 5 consecutive quarters of year-over-year growth. We've seen an expansion of ERUs as we see the consolidation continuing to occur in the data center to free up more floor space and become more power efficiency. We see our 16G and 17G products ramping nicely. And those are driving, again, more cores, more memory, more SSDs, more margin dollars per server that we put in the marketplace. That's how we're doing it. If I missed anything, Yvonne...\nYvonne McGill: Thank you. I think you hit it.\nOperator: And the next question will come from Ben Reitzes with Melius Research.\nBen Reitzes: Hey, thanks guys. Appreciate it. Could you be more specific on the guidance for this year with regard to tariffs? What are you factoring in for China in particular? Is it the 10% or today, this morning's 20%? And then are you instituting any remedies? And what are your thoughts about remedies like raising prices, moving stuff around? And how are you adjusting for that? Thanks a lot.\nJeff Clarke: Well, Ben, maybe I'll take a swing at it, and Yvonne can clean up on this one here. Whatever was announced this morning, which we know things were announced this morning is not on what we just said. That said, this is a pretty darn dynamic environment as represented what we heard this morning. It's fluid. We built an industry-leading supply chain that's globally diverse, agile, resilient that helps us minimize the impacts of these trade regulations, tariffs to our customers and shareholders. We've been monitoring this for some time. We've taken our digital supply chain, our digital twins actually using some AI modelling to look at every possible scenario that you might imagine of this country, that country restrictions here, awaits here. To help us understand how we optimize our network and how we that in the least amount of time at the speed of Dell. And whatever tariff we cannot mitigate, we view that as an input cost. And as our input costs go up, it may require us to adjust prices. That's what we've done in the past. I can't imagine we're going to do anything differently. Yvonne, if I missed something.\nYvonne McGill: No, I think you hit it. We'll take into account the input costs and price accordingly in this competitive environment that we're operating in such, continue onwards.\nOperator: And we'll take a question from David Vogt with UBS.\nDavid Vogt: Great, thanks guys. Maybe just on ISG xAI. So if we take -- maybe Yvonne for you, if we take your kind of outlook at face value, it points to incredibly strong growth in traditional server and storage. I know you just posted relatively good numbers. But what are you seeing in the marketplace vis-\u00e0-vis your traction versus your competitors? And kind of how do we think about getting to high single-digit growth in that part of the business given sort of the macro environment that we just talked about? Thanks.\nYvonne McGill: So David, we are expecting to have growth across the full portfolio in ISG. We -- as I talked about, we're expecting to have storage growing in the low single digits, server higher than that and then the $15 billion at least in AI servers. So I guess we'll continue -- there's lots of opportunities out there where there continues to be multiples of what we've already seen. The pipeline continues to grow. I don't know, Jeff, what you'd add to that around ISG. I feel confident and comfortable in the guide we've laid out for the full year and the opportunity that it has.\nJeff Clarke: Yes. Maybe a little bit of color. Let's take storage as an example. You're seeing a pivot to our Dell IP storage. Modern workloads demand an architecture that can be flexible, sufficient, optimizes performance. And we think a disaggregated architecture is the right answer with the modern workloads. That presents a headwind of our large position that we have in HCI, which will become smaller. But we're going to overcome that by taking share in our Dell IP storage portfolio across the board in the midrange. Our software to find project like -- or product like PowerFlex and then PowerScale in the infrastructure space. So I mean, I think that gives you a sense of a headwind that may exist there that on the surface may not be obvious, but it's certainly something that we're challenged as we pivot towards our storage, which is more profitable.\nYvonne McGill: I was going to say it's more profitable to do our own.\nJeff Clarke: There's revenue that we'll see go away at a lower margin rate, the HCI business. We have a secular decline in the high-end space where we're the market leader with our PowerMax product. So we're going to overcome those and drive the growth that Yvonne mentioned. And then traditional servers, I don't know if you've seen some of the recent market forecast. It's low single-digit growth. We're going to take share. We've now had five consecutive quarters of year-over-year growth that's coming off 8 quarters of a consolidation period or - of a consumption period, I should say. And we think this consolidation continues. But the consolidation drives fewer units. Those units are actually higher in TRU because of the more cores, memory and SSDs I mentioned earlier. And we continue to see that driving our traditional server business. I hope that context helped a little bit.\nDavid Vogt : Great. Thanks, Jeff. Thanks a lot.\nJeff Clarke: Thanks, David.\nOperator: And moving on to Amit Daryanani with Evercore.\nAmit Daryanani: Thanks a lot. I guess I have a question on free cash flow. In fiscal '25, it looks like your free cash flow is down a couple of billion dollars versus '24. Can you just talk about what's driving this contraction in free cash flow? And maybe, Yvonne, you can help us kind of understand how do we think about free cash flow expectations as we head into fiscal '26? What are sort of puts and takes around it? It would be really helpful to kind of get the context, at least for fiscal '26, what's going on? And then, Jeff, if I could just have you talk a little bit more about -- well, I think it's really impressive that your folks are showing operating leverage in fiscal '26 despite the mix being negative. I think the fear everyone seems to have is, is this really durable or is it really driven by one-off headcount reduction or something else. So just maybe you can touch on the durability of that would be great as well?\nJeff Clarke: You go to, Tyler, then I'll come in on the durability of which structural changes we are making up in.\nTyler Johnson: Amit, look, I think -- as I was sitting here last year, I definitely thought cash flow was going to be a little bit stronger. If you look at what played out, one, we didn't see the growth in CSG that we were expecting. And as you know that throw off really good cash. And then two, we invested a lot in our AI business through inventory. And so you can see that our inventory has gone up, and that had a big impact to CCC. Now if I look where I am today and I think about FY '26, I would say I've got a few things working in my favor. So one, we're at a CCC level where historically, we've always shown improvement from here. And that will throw off good cash. We expect good CSG this year, and that will throw off good cash. And if I think about the growth in the P&L, that will throw off good cash. So look, I think we feel pretty good about cash. I do expect it to be greater than 1x and so yes.\nJeff Clarke: And then to your second question, I probably won't give you as much detail as you like because we think some of the changes we're making are very proprietary and differentiating us in the market, the fact that we can grow while reducing our operating expenditures, but Yvonne hit on it, Amit: simplify, standardize, automate. We are building a new company. We are what we call modernizing it. We've made reference to modernization. If you prefer, we're future-proofing the company and we're systematically going throughout all of the value streams in the company. And we are modernizing the work, the workflows, taking steps out of processes, taking out manual touches, simplifying and standardizing those processes, applying automation in the very technologies that we've talked about that get us excited in this marketplace, which is why we believe this AI thing makes its way to enterprise, we are deploying AI in the enterprise. The broad categories of use cases are industry-known, whether that's content creation and management, support assistance, natural language search, design and data creation, cogeneration or document automation. Those are broad enterprise use cases. We are deploying those types of technologies inside our company and seeing tremendous efficiency from that and it is durable. It's not a one- timer.\nYvonne McGill: What's so exciting as we're making all these changes, we're making investments. But we're driving all this efficiency to enable that. So the net, what you're seeing us guide to is a lower spend, but it's because we're driving all of these efficiencies will enable us to invest OP spending.\nJeff Clarke: Well, I think that's very important. I think I mentioned it in the remarks comment that we are reducing the cost. And we've built, if you will, the ability to invest more in our innovation engines, more in our areas where we drive distinct advantages. Our sales force, we've invested in our sales force over the past year, we've invested in services, we've invested in the supply chain while reducing our cost.\nYvonne McGill: And it's just the beginning. Thanks Amit.\nOperator: And the next question will come from Matt Niknam with Deutsche Bank. Please go ahead.\nMatt Niknam: Hi, thanks so much for taking my question. My question is on CSG. I can ask about a different segment. The guidance implies an acceleration over the course of the year. And I'm just wondering what sort of visibility or confidence level you have there that this long-awaited PC refresh will finally materialize. And I ask that in context of a relative slowdown that was referenced in January?\nJeff Clarke: Yes. Matt, maybe this will shed some optimism on why we believe that this refresh that we've talked about is in the making. I mean, clearly, we've talked about there's 1.5 billion or so PCs in the installed base. We'll say half of them are 4 years or older. It's got to flip 360 million PCs turned 4 years old that were bought in 2021 this year. Those are normally flags for opportunity for refresh, but probably the more compelling reasons, and I think there are two. We're 9 months away from the Windows 10 end of life. There's over 500 million PCs running today that can't -- running Windows 10 that can't run Windows 11. There's more than 200 million PCs today running Windows 10 that can run Windows 11. Those are prime targets for upgrades. It's just a large pool of old machines running an older version of the operating system that could be upgraded. If you were to reflect on where we were with the Windows 7 end of life compared to where we are today, let's just say we have a long way to go in the next 9 months to catch up and be ready for the end of life. We made reference that SMB for us had strength. That's always an indicator that things are beginning to move. One of the countries that really show a traditional or historical perspective that the refresh is underway is Japan. If you look at the dynamics in the Japan marketplace, it is clearly moving through refresh as it will get done towards the end of October. And then probably the last thing and the most exciting thing and what is actually driving some of the - I think, reticence to refresh right now is AI PCs. And the number of new AI PCs that are coming out in the first half of the year, we clearly just launched a bunch of Lunar Lake-based notebooks in January. Suffice to say, there's more coming. We've announced AMD AI PCs. Customers are going to want to look under the hood at each of those and then make a decision that will future-proof their decision of what is the right correct AI PC for them because they'll have the asset for at least 4 years. All of that makes us feel more confident that the refresh is coming, albeit delayed, slower than any that I've encountered in my career. But all of the data suggests it's there, it's coming, it's coming at a good rate and probably extends. Does that help?\nMatt Niknam: It did. Thanks.\nJeff Clarke: Thanks, Matt.\nMatt Niknam: You are welcome.\nOperator: And the next question will come from Ananda Baruah with Loop Capital.\nAnanda Baruah: Yes, good afternoon guys. Thanks for taking the question. Really appreciate it. One for me, maybe two parts, but related. Could you talk to, Jeff, how you guys are thinking about the server refresh durability? I believe after last call, you talked about part of the current catalyst is folks sort of refreshing older PCs for space and power savings in some to prepare for GenAI. And this is ahead of processor refreshes, so I guess sort of the context of durability of the traditional server growth you see going on now. And then just the sort of add-on to that is you had mentioned focusing -- or targeting to increase attach -- store attach to your GenAI servers. Would just love what you're thinking about there. And what are the mechanics of getting that taken care of over time? That's it for me. Thanks, guys.\nJeff Clarke: Sure. Let me try the server one again. As I mentioned, we're 5 quarters now of year-over-year growth that's coming off an 8-quarter digestion period. In our guide and what we're trying to articulate is that continues for another 4 quarters. So 5 quarters becomes 9 quarters of growth, tempering a little bit. Still driven by the same dynamics that you so well said is freeing up floor space and driving energy efficiency and cooling efficiency. The consolidation occurs, as you look at the installed base, and we have -- just Dell has a very large installed base of 13G and 14G servers all ripe to be replaced with the new 16G server and -- or 17G server. Those conversion rates are roughly a 3 to 4 of the old servers can be, if you will, replaced by a single 16G server, and 6 to 7 of the old servers can be replaced by a single 7G server. Why? Because they have more cores, they're more memory, more storage, they're more energy-efficient. And again, that continues, we believe, throughout the fiscal '26, calendar '25. We've seen no signs that is going to go away from us in that period of time. If you flip over to your other question, again, the fundamental premises, AI needs data. It devours data. You got to feed the beast. The feeding of that beast, if you will, has to be closer to where the computational capability is. So hot and warm storage, the notion of parallel file systems, unstructured file systems, data management tools that help find data and help data be ingested are the opportunities. We have the leading platform for unstructured data. We continue to make it better with the F910 and F710 that I mentioned earlier. Nearly a year ago, we talked about a parallel file system that we are building, Project Lightning, we referred to it. So we're coming to the marketplace with a AI-driven parallel file system. And our Dell data lake house allows us to help customers prepare their information, manage their information and just their information. Our sales force is incented to attach storage with AI opportunities. They will continue to be incented and we inspect that, and we continue to see progress in that area.\nAnanda Baruah: Okay, thanks.\nOperator: And our next question will come from Samik Chatterjee with JPMorgan. Again, Samik Chatterjee, your line is open. Please go ahead with your questions. Perhaps you place this on mute.\nSamik Chatterjee: Hi, hopefully you can hear me now. Jeff, I just wanted to go back to some of your prepared remarks and -- about the $15 billion of AI server revenue that you were highlighting that you at least expect to grow to that level. Just wondering, how much of that is gated by supply, particularly versus the visibility into supply that you're getting? And how much of that commentary around sort of at least growing there is a supply dynamic versus a demand dynamic? And should we be expecting more sort of linear growth for the quarter as we think about the -- with visibility on supply? Thank you.\nJeff Clarke: Well, I think clearly, Hopper supply is available today. I believe there is references yesterday that Blackwell is in production and ramping. We're open for business and taking orders. The message that I really wanted to drive in our remarks is on day 27 of the fiscal year, we're trying to communicate that we are at least $15 billion in AI shipments. Our 5-quarter pipeline continues to grow. It's several multiples of our backlog. We are going to pursue every opportunity with the CSPs and in enterprise. These large-scale systems are accelerating and getting bigger. Models are quickly moving to reasoning models, which consume and require more computational capability, i.e., more computers. And the use cases continue to get clearer for enterprise to drive the return on investments they want to see to actually use AI more broadly. Algorithm innovation continues to accelerate. Again, these reasoning models are -- will consume more computational capability. They're moving to be multimodal, which even consumes more kind of like where this is going. We're optimistic. I don't see supply as an issue. Clearly, these are about building the right architecture. There's a customer preparation or customer readiness component of this, new data centers getting powered, getting water, getting cooling. There's other materials beyond the GPU, getting the rack, getting the cold plates, getting the CDUs, the PDUs, all of that is what we orchestrate. We have line of sight that is at least $15 billion. We'll continue to update as that might change. And we're all in. I don't know what else I can tell you. I hope that helped.\nPaul Frantz: Thanks a lot, Samik. Justin, we'll take one more question, please, and then we'll hand it over to Jeff for a close.\nOperator: Our final question will come from Asiya Merchant with Citigroup.\nAsiya Merchant: Great, thank you for squeezing me in here. Jeff, if I can just ask about your pipeline and the backlog itself, I mean to the extent that you see enterprises and sovereigns in that makes -- how has that changed, say, relative to a quarter ago and how you see that progressing as you ramp up or as you flush through your pipeline and your backlog? Thank you.\nJeff Clarke: Well, it's maybe slightly repetitive to the previous question. The 5-quarter pipeline grew quarter-over-quarter and has grown every quarter since the 9680 was launched. The CSP component grew, the enterprise component grew, the enterprise customer base grew, sectors like education, technology, manufacturing and government grew. Our buyer base in AI continues to grow, what we shipped in Q4. The revenue in Q4 was up. The number of new buyers was up. We're well over several -- a couple of thousand of unique customers. So it has a healthy mix of enterprise. It clearly has a healthy mix of CSPs. It continues to grow to this notion of several multiples. It's with the technologies that are out and available today, and we're excited to see that. And quite honestly, I can't remember the second half of your question. So if you'll refresh my memory, I will answer it.\nAsiya Merchant: No, that's good. And then just to the extent that you see your attach with those enterprises, how much of that is really factored into your fiscal '26 guide?\nJeff Clarke: To the best of our ability, we factor in the attach of services, our professional services, our deployment services, our installation services, the ability to sell networking and network installation, the ability to sell storage. It's an all-inclusive number when we look at that at least $15 billion of AI servers in the marketplace -- shipped in the marketplace.\nPaul Frantz: Asiya, thank you, and handing it over to Jeff for our close.\nJeff Clarke: Sure. Thanks, everybody. I hope you can tell FY '25 was a strong year. We delivered 8% revenue and 10% EPS growth with $3.9 billion in capital returned to shareholders. Our AI business grew to $10 billion while also improving ISG margins year-over-year. In FY '26, we expect to grow revenue and EPS in excess of our long-term value framework. We expect our AI business will grow to at least $15 billion given our robust opportunity pipeline, our engineering, our services and financing advantages. This AI business drives incremental operating profit and is EPS-accretive. We'll continue to modernize the company, reducing operating expenses as we grow, driving further leverage in the P&L. We remain committed to our capital allocation framework, where we've announced an 18% increase in our annual dividend, and our share repurchase authorization increased by $10 billion. We're excited for the year ahead. Thanks for your time today.\nOperator: Thank you. This concludes today's conference call. We appreciate your participation. You may disconnect at this time.",
      "company": "DELL"
    },
    {
      "symbol": "AAPL",
      "date": "2025-01-30 17:00:00",
      "quarter": 1,
      "year": 2025,
      "content": "Suhasini Chandramouli: Good afternoon, and welcome to the Apple Q1 Fiscal Year 2025 Earnings Conference Call. My name is Suhasini Chandramouli, Director of Investor Relations. Today's call is being recorded. Speaking first today are Apple CEO, Tim Cook, and he will be followed by CFO, Kevan Parekh. After that, we'll open the call to questions from analysts. Please note that some of the information you'll hear during our discussion today will consist of forward-looking statements, including, without limitation, those regarding revenue, gross margin, operating expenses, other income and expense, taxes, capital allocation, and future business outlook, including the potential impact of macroeconomic conditions on the company's business and results of operations. These statements involve risks and uncertainties that may cause actual results or trends to differ materially from our forecast. For more information, please refer to the risk factors discussed in Apple's most recently filed annual report on Form 10-K and the Form 8-K filed with the SEC today along with the associated press release. Apple assumes no obligation to update any forward-looking statements, which speak only as of the date they are made. I'd now like to turn the call over to Tim for introductory remarks.\nTim Cook: Thank you, Suhasini. Good afternoon, everyone, and thanks for joining the call. Before I talk about our results I'd like to take a moment to acknowledge the devastating wildfires that impacted the Los Angeles area this month. From our retail teams to Apple TV+, Apple Music, Fitness Plus, Beats and more LA is home to many of our team members. Our thoughts are with everyone who is beginning the road to recovery. For our part, we are contributing to the relief efforts and we will continue to support our teams and the local community. Now turning to the quarter. Today, Apple is reporting revenue of $124.3 billion for the December quarter, up 4% from a year ago, and an all-time record. EPS also set an all-time record of $2.40, 10% higher year-over-year. We achieved all-time revenue records across the majority of the countries and regions we track, including the Americas, Europe, Japan, and the rest of Asia Pacific. We also continue to see momentum in emerging markets, setting all-time revenue records in a number of markets, including Latin America, the Middle East, and South Asia, among others. In services, we achieved an all-time revenue record, and in the past year, we've seen nearly $100 billion in revenue from our services business. I'm also pleased to announce that we reached a new record for our installed base with over 2.35 billion active devices. In October, we released the first set of Apple Intelligence features in U.S. English for iPhone, iPad, and Mac, and we rolled out more features and expanded to more countries in December. Now users can discover the benefits of these new features in the things they do every day. They can use writing tools to help find just the right words, create fun and unique images with Image Playground and Genmoji, handle daily tasks and seek out information with a more natural and conversational Siri, create movies of their memories with a simple prompt, and touch up their photos with clean up. We introduced visual intelligence with camera control to help users instantly learn about their surroundings. Users can also seamlessly access chat GPT across iOS, iPadOS and MacOS. And we were excited to recently begin our international expansion with Apple Intelligence now available in Australia, Canada, New Zealand, South Africa, and the U.K. We're working hard to take Apple Intelligence even further. In April, we're bringing Apple Intelligence to more languages, including French, German, Italian, Portuguese, Spanish, Japanese, Korean, and simplified Chinese, as well as localized English to Singapore and India. And we'll continue to roll out more features in the future, including an even more capable Siri. Apple Intelligence builds on years of innovations we've made across hardware and software to transform how users experience our products. Apple Intelligence also empowers users by delivering personal context that's relevant to them. And importantly, Apple Intelligence is a breakthrough for privacy and AI with innovations like Private Cloud Compute, which extends the industry-leading security and privacy of Apple devices into the cloud. Apple Intelligence opens up an exciting new frontier and is already elevating experiences across iPhone, iPad, and Mac. We're going to keep investing in innovation and in transformative tools that help users in their everyday lives. Let me now turn to our results for the quarter, starting with iPhone. iPhone revenue came in at $69.1 billion, reaching all-time iPhone revenue records in dozens of markets and regions. Our iPhone 16 lineup takes the smartphone experience to the next level in so many ways, and Apple Intelligence is one of many reasons why customers are excited. With the A18 powered iPhone 16 and iPhone 16 Plus, users are getting a big boost in battery life and incredible camera experiences with camera control. Our amazingly powerful iPhone 16 Pro models go even further with larger-than-ever displays and a pro camera system so advanced it can turn moments into masterpieces. In Mac, revenue was $9 billion for the December quarter, 16% higher year-over-year, driven by significant excitement around the world for our latest Mac lineup. The Mac is more than just a powerful tool. It's a launchpad to enable users to bring their best ideas and boldest creations to life. And there are so many reasons to choose Mac, from the breathtaking performance of the M4 family of chips to the groundbreaking and growing capabilities of Apple Intelligence. Every product in the Mac lineup offers something extraordinary, whether that's the super portable MacBook Air, the powerhouse MacBook Pro, the world's best all-in-one iMac, or the small wonder that is the Mac Mini, which is not only stunningly capable, but is our first carbon neutral Mac. All of this is enabled by the unparalleled power of Apple Silicon. iPad revenue was $8.1 billion, up 15% from a year ago, driven by strong interest for our latest products. We love hearing from customers, who are discovering for the first time the versatility of iPad from the ultra-portal iPad Mini, built from the ground up for Apple intelligence, to the powerful M4 iPad Pro in a stunningly thin and light design. iPad is there for our users whenever they need it and wherever they go and we are pleased to see so much excitement and enthusiasm for our lineup. Wearables home and accessories revenue came in at $11.7 billion. With its most advanced display yet and a thinner more comfortable design, the all-new Apple Watch Series 10 is the perfect companion to help users pursue their health and fitness goals this year. From the powerful Vitals app to more customizable activity rings, users have an ever-increasing set of innovative health tools at their fingertips and watchOS 11. Health innovation has long been a focus for us, and we're committed to continuing to advance this work, because we know how much it matters to our users. We've introduced new hearing health features on AirPods Pro 2, and new sleep apnea notifications on Apple Watch are also helping users learn of a potentially serious condition that's thought to affect up to a billion people worldwide. During the quarter, we also brought Apple Vision Pro to even more countries, enabling more customers to discover the magic of spatial computing. Users are enjoying incredible immersive entertainment experiences and powerful new features and enhancements to Mac virtual display. Vision Pro is also supercharging the creative process and the incredibly talented director John M. Chu recently shared how its extraordinary capabilities helped him bring the movie Wicked to life. Turning to services, we set an all-time revenue record of $26.3 billion for the December quarter, growing 14% from a year ago. We set all-time records in the Americas, Europe, and rest of Asia-Pacific, and a December quarter record in Japan. Five years since launch, Apple TV+ continues to be home to incredible storytelling that viewers love. There's nothing quite like the anticipation that comes when a fan favorite returns, and we were thrilled to debut the second season of Severance earlier this month. We have so much in store for our subscribers this year with new shows like The Studio and Your Friends and Neighbors. And we can't wait for the premiere of Formula 1 starring Brad Pitt on June 27, which will take viewers inside the sport in a truly unprecedented way. We're excited that Apple TV+ continues to draw attention and accolades. To-date, Apple TV+ productions have earned more than 2,500 nominations and 538 wins. During the quarter, we were also excited to launch a new Find My Service that can help our users when they lose their luggage. For the first time, if you put an air tag in your suitcase, you'll be able to share its location information with many major airlines, so they can quickly track down your bags if they get lost. Turning to retail, our teams went above and beyond to help customers find the perfect gift throughout the holiday season. We also celebrated openings of new stores in China, Spain, and the U.S. and we were excited to announce plans to connect with even more customers this year by adding a fifth store in the UAE and bringing our online store to Saudi Arabia this summer. We can't wait to welcome customers to the first of several flagship store locations in Saudi Arabia that were opening beginning in 2026. I just had the chance to visit both countries last month, and I had a great time meeting with customers and team members. There's an incredible energy and passion for technology in these growing markets. Every day, I get deeply moving notes about the many ways our technology is enriching our users' lives. I recently got a note from a customer who put his watch on his father's wrist when he feared something was wrong with him. The watch alerted them that the father was an AFib and they were able to get him to the hospital for potentially life-saving treatment. Another user put his new watch on for the first time and within 15 minutes was notified of a low heart rate that led to a necessary pacemaker. And there are so many touching notes around the profound impact of our new hearing health feature like a recent user who told me it had changed her life, allowing her to take part in conversations with her children and grandchildren. These are the kind of stories that remind us of how profoundly important our work is, and it drives us to innovate each and every day. At Apple, the future is full of promise and potential. We're always searching across a world of possibilities, finding those places where we can do the most good and putting all of our energy and ingenuity into making something special. With that, I'll turn it over to Kevin.\nKevan Parekh: Thanks Tim, and good afternoon everyone. I'm going to cover the results for the first quarter of our fiscal year. We are very pleased to report an all-time high for revenue with December quarter revenue of $124.3 billion, up 4% year-over-year. We achieved all-time revenue records in the Americas, Europe, Japan, and rest of Asia Pacific and grew in the vast majority of markets we track. Products revenue was $98 billion, up 2% year-over-year, driven by growth from iPad and Mac. Thanks to our incredible customer satisfaction and strong loyalty, our installed base of active devices reached an all-time high across all products and geographic segments and is now over 2.35 billion active devices. Services revenue reached an all-time record of $26.3 billion, up 14% year-over-year. We grew in every geographic segment and achieved all-time records in both developed and emerging markets. Company gross margin was 46.9% at the high-end of our guidance range and up 70 basis points sequentially, primarily driven by favorable mix. Products gross margin was 39.3%, up 300 basis points sequentially, primarily driven by favorable mix and leverage. Services gross margin was 75%, up 100 basis points sequentially, primarily driven by mix. Operating expenses of $15.4 billion landed at the midpoint of our guidance range and up 7% year-over-year. This strong business performance resulted in all-time records for both net income at $36.3 billion and diluted earnings per share of $2.40, up 10% year-over-year. Operating cash flow was also strong at $29.9 billion, which included the impact of the $11.9 billion we paid during the quarter in connection with the state aid decision. Now, I'm going to provide some more details for each of our revenue categories. iPhone revenue was $69.1 billion, roughly flat to the prior year. We grew in the majority of markets we track and reached all-time revenue records in several developed markets, including Canada, Western Europe, and Japan and in emerging markets like Latin America, the Middle East, and South Asia. The iPhone Active installed base grew to an all-time high in total in an average geographic segment. We also set an all-time record for upgraders. According to a recent survey from Kantar during the December quarter, iPhone was a top-selling model in the U.S., Urban China, India, the U.K., France, Australia, and Japan. We continue to see high levels of customer satisfaction in the U.S. at 96% as measured by 451 research. Mac generated $9 billion in revenue, up 16% year-over-year. We saw strength across our lineup from the new Mac Mini to the latest MacBook Air and MacBook Pro models. This incredible performance was broad-based with double-digit growth in every geographic segment. With our latest advances in Apple Silicon and our fastest neural engine ever, customers are able to take advantage of the full capabilities of AI and Mac. The Mac installed base reached an all-time high and we saw a double-digit growth for both upgraders and customers new to the Mac. Additionally, customer satisfaction in the U.S. was recently measured at 94%. iPad revenue was $8.1 billion, up 15% year-over-year, driven by the new iPad Mini and latest iPad Air. The iPad installed base reached another all-time high, and over half of the customers who purchased an iPad during the quarter were new to the product. Customer satisfaction was at 96% in the U.S. based on the latest reports from 451 Research. Wearable's home and accessories revenue was $11.7 billion, down 2% year-over-year. Customers are excited about the new AirPods 4 and the latest hearing health features in AirPods Pro 2. On watch, although we face a difficult compare against the watch Ultra 2 launch last year, the Apple Watch installed base reached a new all-time high, with over half of customers purchasing an Apple Watch during the quarter being new to the product. Customer satisfaction for watch in the U.S. was reported at 94%. Our services revenue reached an all-time high of $26.3 billion, up 14% year-over-year. Services continues to see strong momentum, and the growth of our installed base of active devices gives us great opportunities for the future. We also see increased customer engagement with our services offerings. Both transacting and paid accounts reached new all-time highs, with paid accounts growing double-digits year-over-year. Paid subscriptions also grew double-digits. We have well over 1 billion paid subscriptions across the services on our platform. We remain focused on improving the breadth and quality of our services offerings, from new games on Apple Arcade to exciting new programming on Fitness Plus, and the continued expansion of features like Tap to Pay, now live in 20 markets. Turning to enterprise, we have seen businesses continue to expand their deployments of our products and services. Deutsche Bank launched its Mac as Choice program for the developers and also issued the latest MacBook Air as a standard computer for their entire mortgage lending division. And we're excited to see leading enterprises such as SAP leverage Apple Intelligence in the U.S., with features like writing tools, summarize, and priority notifications to enhance both their employee and customer experiences. We also see strong demand in our emerging markets. For example, Zomato, a leading food ordering and delivery company in India, has deployed 1,000 of Macs across their workforce to foster innovation. In Vision Pro continues to see more use cases in enterprise, with Cisco's new spatial meetings delivering a fully immersive video conferencing experience for remote collaboration and learning. Let me quickly summarize our cash position and capital return program. We ended the quarter with $141 billion in cash and marketable securities. We repaid $1 billion in maturing debt and decreased commercial paper by $8 billion, resulting in $97 billion in total debt. Therefore, net cash at the end of the quarter was $45 billion. During the quarter, we returned over $30 billion to shareholders. This included $3.9 billion in dividends and equivalents and $23.3 billion through open market repurchases of 100 million Apple shares. As usual, we will provide an update to our capital return program when we report results for the March quarter. As we move ahead into the March quarter, I'd like to review our outlook which includes the types of forward-looking information that Suhasini referred to at the beginning of the call. The color we're providing today assumes that the macroeconomic outlook doesn't worsen from what we're projecting today for the current quarter. As the dollar is strengthened significantly, we expect foreign exchange to be a headwind and to have a negative impact on revenue of about 2.5 percentage points on a year-over-year basis. Despite that headwind, we expect our March quarter total company revenue to grow low to mid-single-digits year-over-year. We expect services revenue to grow low-double-digits year-over-year. When you remove the negative impact of the foreign exchange headwinds I described earlier, the year-over-year growth rate would be comparable to that of the December quarter. We expect gross margin to be between 46.5% and 47.5%. We expect operating expenses to be between $15.1 billion and $15.3 billion. We expect OI&E to be around negative $300 million, excluding any potential impact from the mark-to-market of minority investments, and our tax rate to be around 16%. Finally, today our Board of Directors has declared a cash dividend of $0.25 per share of common stock payable on February 13, 2025, to shareholders of record as of February 10, 2025. With that, let's open to call the questions.\nSuhasini Chandramouli: Thank you, Kevin. We ask that you limit yourself to two questions. Operator, may we have the first question please?\nOperator: Certainly, we will go ahead and take our first question from Erik Woodring with Morgan Stanley. Please go ahead.\nErik Woodring: Great guys, Thanks so much for taking my questions. Tim, in your prepared remarks, you had noted that iPhone 16 models are selling better in markets where Apple Intelligence is available? And I'm just wondering if you could double-click on that comment a bit and share any other details you believe could better help us understand how Apple Intelligence is really impacting iPhone demand and/or what features you find that users are using most often already? And then I just have a quick follow-up. Thank you.\nTim Cook: Yes, Eric. Hi, it's Tim. The -- we did see that the markets where we had rolled out Apple Intelligence, that the year-over-year performance on the iPhone 16 family was stronger than those where Apple Intelligence was not available. In terms of the features that people are using, they're using all of the ones that I'd referenced in my opening comments from writing tools to image playground and Genmoji to visual intelligence and more. And so we see all of those being used. The cleanup is another one that is popular and people love seeing that one demoed in the stores as well. We only had 2, 2.5 weeks or so during the December quarter of the second release of [18.2] (ph) and then only had the U.K. and the other English language countries for the 2.5 weeks. And so we've got just the early indications at the moment, but we were glad\u2026\nErik Woodring: Okay, that's really helpful.\nTim Cook: Yes.\nErik Woodring: Okay, thank you for that, Tim. It's helpful. And then, you know, if we just touch on China, obviously, in the news fairly frequently, if we set aside China Macro, which I understand is still challenging, can you maybe talk about the headwinds that that Apple faces, whether that's, you know, shifting preferences for Western technology brands in favor of domestic vendors, or is this just a function of not necessarily having Apple intelligence available with the iPhone 16, which is, you know, not necessarily helping replacement cycles. Just maybe double clicking on, on what you think and what you're hearing in China as a regard as it relates to the iPhone. Thanks so much.\nTim Cook: Yes, sure. If you look at our greater China revenue for the quarter, we were down 11% year-over-year. And over half of the decline that we experienced was driven by change in channel inventory from the beginning to the end of the quarter. And of course on the Apple intelligence side we have not rolled out in China and as we just talked about we did see better results in the markets that we had rolled out in than markets we hadn't rolled out in. And of course, it's the most competitive market in the world. And so all of those things are true. In terms of the macro situation, there was a fiscal stimulus or subsidy announced in very recently in January that did not affect the December quarter. There were some provincial subsidies in the December quarter, but the national program was announced, I believe, on January 20. And it does cover the categories that we have products in from smartphones to tablets and PCs and smart watches up to a certain, a maximum price point. And so we do see fiscal stimulus occurring and we'll be glad to talk about what that looks like on the next call.\nErik Woodring: Great. Thanks so much, Tim. Good luck.\nTim Cook: Thank you.\nSuhasini Chandramouli: Thank you, Eric. Operator, can we have the next question, please?\nOperator: Our next question is from Ben Reitzes with Melius. Please go ahead.\nBen Reitzes: Hey, guys. Thanks a lot for the question. And, hey, Tim, I wanted to ask you who -- you knew this one was coming, but there's a perception that you're a big beneficiary of lower cost of compute and I was wondering if you could give your worldly perspective here on the DeepSeek situation and if you are going to, if you, if anything's happened to change your views in terms of a tailwind to margins and your ability to execute even due to the potential for cost to come down due to that development and probably what was going to happen anyway. But I'd love your perspective on that and then have a quick follow-up. Thanks.\nTim Cook: Sure. In general, I think innovation that drives efficiency is a good thing. And that's what you see in that model. Our tight integration of silicon and software, I think, will continue to serve us very well. As you know, we do things on the device, and we do things in the private cloud and which mimics from a architectural point of view the -- what happens on the device. And from a CapEx point of view, we've always taken a very prudent and deliberate approach to our expenditure and we continue to leverage a hybrid model, which I think continues to serve us well.\nBen Reitzes: Oh, great. All right. Thanks, Tim. And then, you know, just with regard to, you know, the iPhone trajectory, do you feel like, I guess, what is -- you obviously don't talk about new products and stuff like that, but do you feel that there's a lot of room for form factor innovation in the future? Or do you feel that the current lineup kind of it shows where you're going? I guess without pulling punches wondering if you, you thought you know in terms of the phone innovation if there's a lot more to come and you could see the kind of current market changing a bit over the next two to three years. Thanks.\nTim Cook: I think, Ben, I think there's a lot more to come and I could not feel more optimistic about our product pipeline. So I think there's a lot of innovation left on the smartphone.\nBen Reitzes: Thanks a lot, Tim.\nTim Cook: Yes, thank you.\nSuhasini Chandramouli: Thank you, Ben. Operator, could we have the next question, please?\nOperator: Our next question is from Michael Ng with Goldman Sachs. Please go ahead.\nMichael Ng: Good afternoon. Thank you for the question. I have two as well. First, it was encouraging to hear about the record for iPhone upgraders, which I think is something you haven't said for about a year now. I was wondering if you could talk a little bit about what you would attribute this upgrade strength to? Has Apple Intelligence played a role in helping upgrades in the markets that you've launched in? Thanks.\nTim Cook: Yes, thank you for the question. If you look at iPhone, we did set an all-time record for upgraders, so we've never seen a higher level of upgraders before. The installed base hit a new all-time high as well. And if you look at the 16, compared to the 15 from launch, which occurred, as you know, in September, so this is across now two quarters from September to the end of the December fiscal quarter, the 16 outperformed the 15. And so I think you can conclude from that, that there are compelling reasons to upgrade. And in the markets where we had launched Apple Intelligence, they outperformed the markets that we did not. So lots\u2026\nMichael Ng: Great, thank you, Tim. That's\u2026\nTim Cook: Yes, lots of good color there.\nMichael Ng: Great, thank you, Tim. That's very clear. And then I had one about the iPad Pro and for the thinner version. I was just wondering if you could talk about that thin form factor for the iPad Pro. How did it help iPad sales overall and what did your kind of marketing consumer research tell you about how consumers valued that thin product form factor? Thank you.\nTim Cook: It's a good question. iPad overall grew 15% for the quarter and it was more driven by iPad Air and the entry level iPad than it was the top level iPad. But overall we could not be more pleased with the iPad category growing 15%. It's a great achievement for the quarter. And probably what is most important is that over half of the sales in the December quarter went to customers who were new to the iPad. So that tells us that there's a good amount of customers there to attract.\nMichael Ng: Thank you very much, Tim.\nTim Cook: Yes. Thank you.\nSuhasini Chandramouli: Thanks, Mike. Operator, could we have the next question, please?\nOperator: Our next question is from Amit Daryanani from Evercore. Please go ahead.\nAmit Daryanani: Good afternoon, everyone. I have two as well. Maybe to start with, you folks are seeing some very robust growth trends in emerging markets right now for Apple products? Can you just add a high level, just talk about the durability of growth that you see in emerging markets? And then do you think the summation of these emerging markets are starting to get big enough or perhaps starting to grow fast enough that it can actually offset some of the China headwinds you're going through?\nTim Cook: We have great results in a number of emerging markets. And as you know from past calls, I'm particularly keen on India. India set a December quarter record during the quarter. And we're opening more stores there. We've announced that we're going to open four new stores there. We also, the iPhone was the top selling model in India for the quarter. And it's the second largest smartphone market in the world and the third largest for PCs and tablets and so there's a huge market and we are -- we have very modest share in these markets. And so I think there's lots of upside there. And that's just one of the emerging markets.\nKevan Parekh: Yes, maybe I'll add, Amit, that in emerging markets we're also seeing double-digit growth on the install base, both in total and for the iPhone as well. So that's also an encouraging sign.\nAmit Daryanani: Perfect. Thank you. And then, you know, just a question on gross margins for the March quarter. You folks are guiding gross margin is flattish on a sequential basis. Typically, I think it tends to be guided up a little bit, 50 basis points, so sequentially. Can we just touch on like, what are the offsets of the puts and takes you see here on gross margins? And Kevan, maybe you can just talked about its FX having an outsized impact in your margin profile as well in March?\nKevan Parekh: Yes, Amit, let me take that One. You know, as we mentioned in my remarks, we're guiding to 46.5% to 47.5%. So we think it's, you know, we're very pleased with that level of guidance. As you mentioned, there's always puts and takes. We do think there's going to be some FX headwinds, which we talked about, that's going to affect, you know, our revenue growth as well. You know, it'll have an impact here on the margin, a sequential impact on margins. But we think that's going to be offset by favorable costs and the relative mix of services. We also, as you know, when we move from Q1 to Q2, especially on the product side, because Q1 is such a large quarter for a products business, we do have a loss of leverage. So there are some puts and takes, and I think we feel good about the range. We think it's a very, very strong guide for gross margin.\nSuhasini Chandramouli: Thanks, Amit. Operator, could we get the next question, please?\nOperator: Our next question is from Wamsi Mohan with Bank of America. Please go ahead.\nWamsi Mohan: Yes, thank you so much. Tim, I want to follow-up on your comment about channel inventory in China. I was wondering if you could maybe address more broadly if channel inventory across your different product lines and regions? Do you feel they're elevated or out of range in any other regions? And given the clearing event that kind of happened in China, I guess in the quarter, should we think of a more normal progression quarter-on-quarter into the March quarter in China in particular, and I will follow.\nTim Cook: Yes, I don't want to project sales for the current quarter by region, but if you if you look at the channel inventory and look at iPhone in the aggregate, so on a worldwide basis we're very comfortable with our channel inventory position in the -- in China my point was that our channel inventory reduced from the beginning of the quarter to the end of the quarter, and that was over half of the reduction in the reported results. And so if you look, part of the reason for that is that our sales were a bit higher than we forecasted them to be toward the end of the quarter. And so we ended a little leaner than we had expected to.\nWamsi Mohan: Okay, that's very clear. Thank you.\nTim Cook: Yes, thank you.\nWamsi Mohan: And then maybe as my follow-up, your services growth has been very strong and I know you've kind of been navigating some pretty challenging regulatory burdens on the business globally. So how should investors think about maybe either a top line or margin headwind that let's say you're currently absorbing in your results that could potentially maybe reverse in a more balanced regulatory environment? Thank you so much.\nKevan Parekh: Yes. So I think one, I just wanted to kind of reiterate the fact that, you know, our services business had an all-time record for December quarter of 14%. And that was a one strength that we saw across all geographic segments and also was very broad base across all of our services. So we have, as you know, a very broad services portfolio. And so we do see, you know, good momentum across the board. And as well, we continue to see increasing engagement across the customer base, across all of the service offerings, both transacting and paid accounts. We talked about reaching all-time highs, and we have over now 1 billion paid subscriptions across the services platform.\nSuhasini Chandramouli: All right. Thanks, Wamsi. Operator, could we get the next question, please?\nOperator: Our next question is from Samik Chatterjee with JPMorgan. Please go ahead.\nSamik Chatterjee: Hi. Thanks for taking my questions. I guess for the first one, if I -- I mean, you had a great quarter on Macs and iPads both. And I'm just curious, in terms of if you can help us think about the sustainability of this double-digit growth that you saw in both the product lines, and more interest are also here, we are talking about Apple Intelligence sort of influencing volumes on iPhones, but any thoughts on sort of how -- what does that influence look like in terms of volumes for Macs, for example, where I think there's a lot of conversation on AI PCs, how you're thinking about the impact there? And I have a quick follow-up. Thank you.\nTim Cook: Yes. If you look at Mac, Mac was up 16% and on iPad, we were up 15%. The Mac was driven by the very strong uptake on our new products during the quarter and the continued success of the MacBook Air. And so as you know, we've launched an M4-based MacBook Pro, an iMac and a Mac Mini during the quarter. We believe we've got the best AI PC out there for running workloads. The silicon in the Mac is, and it has been for several years now, designed by us and really designed for these workloads. And so I don't want to project at the category level for the future, but we're incredibly pleased with both the Mac and the iPad for the quarter.\nSamik Chatterjee: Okay. And Tim, I'm going to use your earlier discussion about India as a strong emerging market to sort of ask you about the supply chain planning there in terms of how much of the supply chain planning there that you're doing is more of a reflection of the growth expectations from that market relative to in terms of diversification of the supply chain? And how should we sort of think about that strategy in terms of that particular country? Thank you.\nTim Cook: Yes. If you look at the manufacturing we do there, we do manufacturing both for the domestic market, and we export. And so in -- our business needs a certain economies of scale for it to make sense to manufacture in country. And so that really means that we're going to be both a use for the domestic market and an export market.\nSamik Chatterjee: Great. Thank you.\nTim Cook: Yes, thanks.\nSuhasini Chandramouli: Thank you, Samik. Operator, could we get the next question, please?\nOperator: Our next question is from David Vogt with UBS. Please go ahead.\nDavid Vogt: Great, thanks, guys, for taking my question. So maybe, Tim, this is for you. I'm trying to think about your commentary around Apple Intelligence being sort of a momentum driver for the iPhone business. But when I think about your kind of framework for the March quarter, if I kind of adjust for channel inventory over the last couple of years, kind of, feels like your iPhone revenue for the March quarter is going to be relatively similar to the quarter two years ago and even the quarter last year? So how do we square kind of the momentum versus kind of the iPhone business effectively really kind of unchanged over the last couple of years? And then second, when I think about kind of the gross margin profile of the business, obviously, you've done a great job in taking gross margins up. Where do you think we sit in terms of, on the services side at least, where margins could go? It looks like the 75% margin has been incredibly successful quarter. But just trying to get a sense for where do you think this number could go over the intermediate term? Thank you.\nTim Cook: Yes. If you look at Apple Intelligence, what my point earlier was, that markets where we had rolled out Apple Intelligence during the Q1 period performed better on a year-over-year basis than markets where we had not. And so that gives us -- it's a positive indicator that we were pleased with. There are many compelling reasons to upgrade. And the other thing I would say, that I think I mentioned earlier, is that if you look at it from a launch to the end of the December quarter, and so that goes back to September, the 16 family is outperforming the 15 family. And so I think those are two good data points. Our next round of language rollouts will be in April. And so it will be at the -- in our Q3 quarter. And I'll let Kevan take the gross margin question.\nDavid Vogt: Yes, great.\nKevan Parekh: Hi, David. How are you? So on the Services gross margin, I think maybe just stepping back a second. Services business in general in aggregate is accretive to the overall company margin. And one of the things, as an important reminder, is we've got a very broad services portfolio. And those businesses have very different margin profiles. And so I think, one, it's because of the nature of those businesses and in part also because of the way we account for them. And so one of the big factors that drive the Services gross margins and relative performance of those different businesses within the portfolio. We also have the dynamic of some scale businesses like payment services, iCloud, that are actually growing. And there, when we add incremental users, those end up being accretive to margins as well. And so in general, what we saw in the December quarter was nice momentum across our entire services business that allows us to deliver that 75% margin at the services level. And I think our guidance takes into consideration what we think we're going to land from a company standpoint of 46.5% to 47.5%, which again, we think is a strong guide.\nDavid Vogt: Great, thanks, guys.\nSuhasini Chandramouli: All right, thank you, David. Operator, could we have the next question, please?\nOperator: Our next question is from Krish Sankar with TD Cowen. Please go ahead.\nKrish Sankar: Yes, thanks for taking my question. I also had two of them. One, the first one for Tim. You had very strong Mac growth, 16% year-over-year last quarter. Just wondering how much of that was driven by some of the Mac silicon innovation versus a replacement cycle for Macs?\nTim Cook: I don't know the answer to your question precisely, but I think it is a combination of these products are so compelling, the M4-based products are so compelling, that it's driving both upgrades at the double-digit level and it's driving switchers at a double-digit level. And so we're seeing both come out, and I think it's just because of the compelling products.\nKrish Sankar: Got it. Got it. Thanks for that, Tim. And then a follow-up for Kevan on the gross margin. I want to ask you on the product side. Last quarter, you had 39.3%, which is very strong, similar to a year ago period. I'm kind of curious how much more levels do you have on the product side to improve the gross margin? Or do you think with some of the more new AI-related devices, there's more upside to gross margin from here on the product hardware side?\nKevan Parekh: Yes. Thanks, Krish, for the question. So on the product side, as you mentioned, we had pretty strong sequential improvement, 300 basis points, for the December quarter. That was really driven by, we talked about, favorable mix and leverage. As you know, in Q1, again, it's a launch quarter for many products, and so we tend to benefit from the leverage that we get from that higher volume. I would say, in general, our gross margin on products is driven by a number of factors. One of them is the various product launches that we have. Different products do have different margin profiles. And so that mix does make a difference. And in particular, what we're seeing is, for example, many of our mix is across like phone, for example, we're seeing customers gravitate towards our Pro products because of things like affordability that allows our customers to get into our best products, which have favorable gross margins. So we're continuing to see that trend, that impacted us in the December quarter. As well, I think we're in a favorable commodity environment from a cost standpoint. And so we're benefiting from that as well in the December quarter. And then that's going to be, as we talked about, we're going to have a foreign exchange headwind heading into the March quarter, but we figured that's contemplated in the guidance range that we gave, the 46.5% to 47.5%.\nKrish Sankar: Thanks, Kevan. Thanks, Tim.\nSuhasini Chandramouli: Thank you, Krish. Operator, could we get the next question, please?\nOperator: Our next question is from Richard Kramer with Arete Research. Please go ahead.\nRichard Kramer: Thanks very much. My first question is for Tim. I'd like to ask about what might accelerate the pace of Apple Intelligence adoption. I guess do you see this simply as a question of time i.e., to launch more markets and languages or increase the percentage of installed base devices that can support it? Or is it a question of money, i.e., shifting R&D or marketing spend towards AI? And based on other prior Apple services, do you expect a sort of tipping point where adoption will go mainstream? Thanks.\nTim Cook: I do believe it will go mainstream. I'm getting feedback from people using different features today. And this is -- keep in mind that on the iPhone side of our business, you either have to have an iPhone 15 Pro or iPhone 16 to use Apple Intelligence. And so the -- as that base grows, I think the usage will continue to grow. And I think -- I know from my own personal experience, once you start using the features, you can't imagine not using them anymore. I know I get 100s of e-mails a day, and the summarization function is so important. So I think it's a combination of that. And of course, in April, we roll out a whole series of new languages that we had mentioned, and so the base grows further.\nRichard Kramer: Okay, thank you. And then, Kevan, one of Luca's legacies was really getting Apple to record margin levels and also maintaining very consistent pricing across the product range. But taking the current high levels of profitability as fairly stable, what observations might you share about price sensitivity of users and whether having a wider range of pricing across the products might unlocks potentially further market share gains or boost overall product growth?\nKevan Parekh: Yes, it's a good question. I think one, I don't think we're going to really depart from what served us pretty well to now. I mean we always take it into consideration, looking at short-term -- comparison between the short term and the long term. I think we've had a pretty disciplined pricing strategy, which would serve us pretty well. And I think we're going to continually kind of stick with that as far as I can tell.\nRichard Kramer: Okay, thanks.\nSuhasini Chandramouli: Thank you, Richard. Operator, could we get the next question, please?\nOperator: Our next question is from Atif Malik with Citi. Please go ahead.\nAtif Malik: Hi, thank you for taking my question. How do you guys see the potential tariff impact to your product for consumer demand under Trump 2.0 you guys did find under Trump 1.0?\nTim Cook: We are monitoring the situation and don't have anything more to add than that.\nAtif Malik: Great. And Tim, as a follow-up, there is a lot of discussion on agentic AI, the use of agents. Do you guys see the upgraded series expected in April as something that will, let's say, be the killer application among the suite of features that you have announced in Apple Intelligence?\nTim Cook: I think the killer feature is different for different people. But I think for most, they're going to find that they're going to use many of the features every day. And certainly, one of those is the -- is Siri, and that will be coming over the next several months.\nAtif Malik: Thank you.\nSuhasini Chandramouli: All right. Thank you, Atif. Operator, could we please get the last question?\nOperator: Our last question is from Ben Bollin from Cleveland Research Company. Please go ahead.\nBen Bollin: Good evening, everyone. Thanks for taking the question. Tim, I'm interested in your thoughts and how you would have us think about the average useful life of these devices in the wild. And in particular, curious, if you look at the strength you saw in fiscal \u201821 and how that might support accelerated refresh opportunity into the future?\nTim Cook: Yes. Ben, I think it's different for different types of users. I mean you have very early adopter kind of users that are very quick to jump on the latest technology that upgrade very frequently. And then you have people that are on the entire opposite side of that barbell. And most people are between those two points. And so I do think there were lots of units that are sold during the COVID period of time, and it's a huge opportunity for us as a company to -- for more than one of the product categories.\nBen Bollin: That\u2019s it from me. Thanks, Tim.\nTim Cook: Thank you.\nSuhasini Chandramouli: All right. Thanks, Ben. A replay of today's call will be available for two weeks on Apple Podcasts or as a webcast on apple.com/investor and via telephone. The number for the telephone replay is 866-583-1035. Please enter confirmation code 7398532 followed by the pound sign. These replays will be available by approximately 5 p.m. at Pacific Time today. Members of the press with additional questions can contact Josh Rosenstock at 408-862-1142. And financial analysts can contact me, Suhasini Chandramouli, with additional questions at 408-974-3123. Thanks again for joining us here today.\nOperator: Once again, this does conclude today's conference. We do appreciate your participation.",
      "company": "AAPL"
    },
    {
      "symbol": "NVDA",
      "date": "2025-02-26 17:00:00",
      "quarter": 4,
      "year": 2025,
      "content": "Christa: Good afternoon. My name is Christa, and I will be your conference operator today. At this time, I would like to welcome everyone to NVIDIA Corporation's Fourth Quarter Earnings Call. All lines have been placed on mute to prevent any background noise. After the speakers' remarks, there will be a question and answer session. If you would like to ask a question during this time, simply press star followed by the number one on your telephone keypad. And if you would like to withdraw your question, Thank you. Stewart Stecker. You may begin your conference. Thank you.\nStewart Stecker: Good afternoon, everyone, and welcome to NVIDIA Corporation's conference call for the fourth quarter of fiscal 2025. With me today from NVIDIA Corporation are Jensen Huang, president and chief executive officer, and Colette Kress, executive vice president and chief financial officer. I'd like to remind you that our call is being webcast live on NVIDIA Corporation's Investor website. Webcast will be available for replay until the conference call discuss our financial results, the first quarter of fiscal 2026. The content of today's call is NVIDIA Corporation's property. It can't be reproduced or transcribed without prior written consent. During this call, we may make forward-looking statements based on current expectations, these are subject to a number of significant risks and uncertainties and our actual results may differ materially. A discussion of factors that could affect our future financial results and business, please refer to the disclosure in today's earnings release. Our most recent forms 10-K and 10-Q, and the reports that we may file on form 8-K with the Securities and Exchange Commission. All our statements are made as of today, February 26, 2025, based on information currently available to us. Except as required by law, we assume no obligation to update any such statements. During this call, we will discuss non-GAAP financial measures. Confined and reconciliation of these non-GAAP financial measures GAAP financial measures in our CFO commentary, which is posted on our website. With that, let me turn the call over to Colette.\nColette Kress: Thanks, Stewart. Q4 was another record quarter. Revenue of $39.3 billion was up 12% sequentially and up 78% year on year. And above our outlook, of $37.5 billion. For fiscal 2025, revenue was $130.5 billion. Up 114% in the prior year. Let's start with data center. Data center revenue for fiscal 2025 was $115.2 billion. More than doubling from the prior year. In the fourth quarter, it is in a revenue of $35.6 billion was a record, up 16% sequentially and 93% year on year. As the Blackwell ramp commenced, and Hopper 200 continued to contribute growth, In Q4, Blackwell sales exceeded our expectations. We delivered $11 billion of Blackwell revenue to meet strong demand. This is the fastest product ramp in our company's history. Unprecedented in its speed and scale. Blackwell production is in full gear across multiple configurations, and we are increasing supply quickly. Expanding customer adoption. Our Q4 data center compute revenue jumped 18% sequentially and over 2x year on year. Customers are racing to scale infrastructure to train the next generation of cutting-edge models and unlock the next level of AI capabilities. With Blackwell, it will be common for these clusters to start with 100,000 GPUs or more. Shipments have already started for multiple infrastructures of this size. Post-training and model customization are fueling demand for NVIDIA Corporation infrastructure and software as developers and enterprises leverage techniques such as fine-tuning, reinforcement learning, and distillation to tailor models for domain-specific use cases. Hugging Face alone hosts over 90,000 derivatives traded from the Llama Foundation model. The scale of post-training and model customization is massive and can collectively demand orders of magnitude more compute than pretraining. Our inference demand is accelerating. Driven by test time scaling and new reasoning models. Like OpenAI's O3, DeepSeq R1, and Grok 3. Long-thinking reasoning AI can require 100x more compute per task compared to one-shot inferences. Blackwell was architected for reasoning AI inference. Blackwell supercharges reasoning AI models with up to 25x higher token throughput and 20x lower cost versus Hopper 100. It is revolutionary. Transformer engine is built for LLM. And mixer of experts inference. And its NVLink domain delivers 14x the throughput of PCIe Gen 5. Ensuring the response time, throughput, and cost efficiency needed to tackle the growing complexity of inferences scale. Companies across industries are tapping into NVIDIA Corporation's full-stack inference platform to boost performance and slash cost. Now tripled inference throughput and cut cost by 66% using NVIDIA Corporation TensorRT for its screenshot feature. Perplexity sees 435 million monthly queries and reduced its inference costs 3x with NVIDIA Corporation Triton inference server and TensorRT LLM. Microsoft Bing achieved a 5x speedup at major TCO savings for visual search across billions of images with NVIDIA Corporation, TensorRT, and acceleration libraries. Blackwell has great demand for inference. Many of the early GV200 deployments are earmarked for inference. A first for a new architecture. Blackwell addresses the entire AI market from pretraining, post-training, to inference across clouds, to on-premise, to enterprise. Its programmable architecture accelerates every AI model and over 4,400 applications ensuring large infrastructure investments against obsolescence in rapidly evolving markets. Our performance and pace of innovation are unmatched. We're driven to a 200% reduction in inference cost in just the last two years. We delivered the lowest TCO and the highest ROI. And full-stack optimizations for NVIDIA Corporation and our large ecosystem including 5.9 million developers continuously improve our customers' economics. In Q4, large CSPs represented about half of our data center revenue. And these sales increased nearly 2x year on year. Large CSPs were some of the first to stand up Blackwell, with Azure, GCP, AWS, and OCI, bringing GV200 systems to cloud regions around the world to meet surging customer demand for AI. Regional cloud hosting NVIDIA Corporation GPUs increased as a percentage of data center revenue. Reflecting continued AI factory build-outs globally and rapidly rising demand for AI reasoning models and agents. Coreweave launched a 100,000 GV200 cluster-based instance with NVLink switch and Quantum-2 InfiniBand. Consumer Internet revenue grew 3x year on year. Driven by an expanding set of generative AI and deep learning use cases. These include recommender systems, vision language understanding, synthetic data generation search, and agentic AI. For example, XAI is adopting the GV200 to train and inference its next generation of Grok AI models. Meta's cutting-edge Andromeda, advertising engine runs on NVIDIA Corporation's Grace Hopper Superchip. Serving vast quantities of ads across Instagram, Facebook applications. Andromeda harnesses Grace Hopper's fast interconnect and large memory to boost inference, throughput by 3x. Enhanced ad personalization, and deliver meaningful jumps in monetization and ROI. Enterprise revenue increased nearly 2x year on accelerating demand model fine-tuning. Agentic AI workflows. And GPU-accelerated data processing. We introduced NVIDIA Corporation Llama Numitron model family nodes to help developers create and deploy AI agents across a range of applications, including customer support, fraud detection, and product supply chain and inventory management. Leading AI agent platform providers, including SAP and ServiceNow, are among the first to use new models. Health care leaders, IQVIA, and Lumenon. And Mayo Clinic as well as ARC and Institute are using NVIDIA Corporation AI to speed drug discovery enhance genomic research, and pioneer advanced health care services with generative and agentic AI. As AI expands beyond the digital world, NVIDIA Corporation infrastructure and software platforms are increasingly being adopted to power robotics and physical AI development. One of the early and largest robotics applications and autonomous vehicles were virtually every AV company is developing on NVIDIA Corporation, in the data center. NVIDIA Corporation's automotive vertical revenue is expected to grow to approximately $5 billion this fiscal year. At CES, Hyundai Motor Group announced it is adopting NVIDIA Corporation Technologies to accelerate AV and robotics development and smart factory initiatives. Vision transformers, self-supervised learning, multimodal sensor fusion, and high-fidelity simulation are driving breakthroughs in AV development and will require 10x more compute. At TDX, we announced the NVIDIA Corporation Cosmos World foundation model platform. Just as language foundation models have revolutionized language AI, Cosmos is a physical AI to revolutionize robotics. The robotics and automotive companies, including ride-sharing giant Uber, are among the first to adopt the platform. From a geographic perspective, sequential growth in our data center revenue was strongest in the US, driven by the initial ramp of Blackwell. Countries across the globe are building their AI ecosystems and demand for compute infrastructure is surging. France's \u20ac200 billion AI investment and the EU's \u20ac200 billion Invest AI initiative offer a glimpse into the build-out that will redefine global AI infrastructure in the coming years. Now as a percentage of total data center revenue, data center sales in China remained well below levels seen onset of export controls. China shipments absent any change in regulations, we believe that will remain roughly at the current percentage. The market in China for data center solutions remained very competitive. We will continue to comply with export controls while serving our customers. Networking revenue declined 3% sequentially. Our networking attached to GPU compute systems is robust at over 75%. We are transitioning from small NVLink 8 with InfiniBand to large NVLink 72. The Spectrum X. Spectrum X and NVLink switch revenue increased and represents a major new growth sector. We expect networking a return to growth in Q1. AI requires a new class of networking. NVIDIA Corporation offers NVLink switch systems for scale of compute. For scale out, we offer Quantum InfiniBand for HPC supercomputers, and SpectrumX for Ethernet environments. Spectrum X enhances the Ethernet for AI computing and has been a huge success. Microsoft Azure OCI, Fortease, and others are building large AI factories with SpectrumX. The first Stargate data centers will use Spectrum X. Yesterday, Cisco announced integrating Spectrum X into their networking portfolio to help enterprises build AI infrastructure. With its large enterprise footprint and global reach, Cisco will bring NVIDIA Corporation Ethernet to every industry. Now moving to gaming and AR PCs. Gaming revenue of $2.5 billion decreased 22% sequentially and 11% year on year. Full year revenue of $11.4 billion increased 9% year on year. And demand remains strong throughout the holiday. However, Q4 shipments were impacted by supply constraints. We expect strong sequential growth in Q1 as supply increases. The new GeForce RTX 50 series desktop and laptop GPUs are here. Built for gamers, creators, and developers, they fuse AI and graphics, redefining visual computing. Powered by the Blackwell architecture, fifth-generation tensor cores, and fourth-generation RT cores and featuring up to 3,400 AI TOPS. These GPUs deliver a 2x performance leap and new AI-driven rendering, including neural shaders, digital human technologies, geometry, and lighting. The new DLSS 4 boosts frame rates up to 8x with AI-driven frame generation turning one rendered frame into three. It also features the industry's first real-time application of transformer models packing 2x more parameters and 4x to compute unprecedented visual fidelity. We also announced a wave of GeForce Blackwell laptop GPUs with new NVIDIA Corporation Max-Q technology that extends battery life, by up to an incredible 40%. These laptops will be available starting in March from the world's top manufacturers. Moving to our professional visualization business. Revenue of $511 million was up 5% sequentially and 10% year on year. Full year revenue of $1.9 billion increased 21% year on year. Key industry verticals driving demand include automotive and health care. NVIDIA Corporation Technologies and generative AI are reshaping design engineering, and simulation workloads. Increasingly, these technologies are being leveraged in leading software platforms. From ANSYS, Cadence, and Siemens fueling demand for NVIDIA Corporation RTX workstations. Now moving to automotive. Revenue was a record $570 million, up 27% sequentially and up 103% year on year. Full year revenue of $1.7 billion increased 55% year on year. Strong growth was driven by the continued ramp in autonomous vehicles, including cars and robotaxis. At CES, we announced Toyota the world's largest automaker will build its next generation vehicles on NVIDIA Corporation Oren, running the safety-certified NVIDIA Corporation Drive OS. We announced Aurora and Continental. Will deploy driverless trucks at scale powered by NVIDIA Corporation Drive 4. Finally, our end-to-end autonomous vehicle platform, NVIDIA Corporation DRIVE Hyperion, has passed industry safety assessments by Ryland, two of the industry's foremost authorities, automotive-grade safety and cybersecurity, NVIDIA Corporation is the first AV platform to receive a comprehensive set of third-party assessments. Moving to the rest of the P&L. GAAP gross margins, was 73%. And non-GAAP gross margins were 73.5%. Down sequentially as expected with our first deliveries of the Blackwell architecture. As discussed last quarter, Blackwell is a customizable AI infrastructure with several different types of NVIDIA Corporation build chips. Multiple networking options, and for air and liquid-cooled data center. We exceeded our expectations in Q4, in ramping Blackwell, increasing system availability, providing several configurations to our customers. As Blackwell ramps, we expect gross margins to be in the low seventies. We initially, we are focused on expediting the manufacture as they race to build out Blackwell infrastructure. When fully ramped, we have many opportunities to improve the cost and gross margin. Will improve and return to the mid-seventies. Late this fiscal year. Sequentially, GAAP operating expenses were up 9% and non-GAAP operating expenses were 11%, reflecting higher engineering development costs and higher compute and infrastructure costs for new product introductions. In Q4, we returned $8.1 billion to shareholders, the form of share repurchases cash dividends. Let me turn to the outlook in the first quarter. Total revenue is expected to be $43 billion. Plus or minus 2%. Continuing with its strong demand, we expect a significant ramp of Blackwell in Q1. We expect sequential growth. In both data center and gaming. Within data center, we expect sequential growth from both. Compute and networking. GAAP and non-GAAP gross margins are expected to be 70.6%. And 71% respectively. Plus or minus 50 basis points. GAAP and non-GAAP operating expenses are expected to be approximately $5.2 billion and $3.6 billion. We expect full year fiscal year 2026 operating expenses grow to grow to be in the mid-thirties. GAAP and non-GAAP other incoming expenses are expected to be an income of approximately $400 million. Excluding gains and losses, from non-marketable and publicly held equity securities. GAAP and non-GAAP tax rates are expected to be 17% plus or minus 1% excluding any discrete items. Further financial details are included in the CFO commentary and other information available on our IR website. Including a new financial information AI agent. In closing, let me highlight upcoming events for the financial community. We will be at the TD Cowen Healthcare Conference in Boston on March 3rd. And at the Morgan Stanley Technology, Media, and Telecom Conference in San Francisco. On March 5th. Please join us for our annual GTC conference starting Monday, March 17th, in San Jose, California. Jensen will deliver a news-packed keynote on March 18th, and we will host a Q&A session for our financial analysts. Next day, March 19th. We look forward to seeing you at these events. Our earnings call to discuss the results for our first quarter of fiscal 2026 is scheduled for May 28th, 2025. We are going to open up the call, operator. To questions. If you could start that, that would be great.\nChrista: Thank you. At this time, I would like I also ask that you please limit yourself to one question. For any additional questions, please requeue. And your first question comes from C.J. Muse with Cantor Fitzgerald. Please go ahead.\nC.J. Muse: Yeah. Good afternoon. Thank you for taking the question. I guess, for me, Jensen, as test time compute and reinforcement learning shows such promise, we're clearly seeing increasing blurring in the lines between training and inference. What does this mean for the potential future of potentially inference-dedicated clusters? And how do you think about the overall impact to NVIDIA Corporation and your customers? Thank you.\nJensen Huang: Yeah. I appreciate that, C.J. There are now multiple scaling laws. There's the pretrained scaling laws. And that's gonna continue to scale because we have multimodality. We have data that came from reasoning that are now used to pretraining. And then the second is post-training scaling law. Using reinforcement learning human feedback, reinforcement learning AI feedback, reinforcement learning verifiable rewards, the amount of computation you use for post-training is actually higher than pretraining. And it's kinda sensible in the sense that you could while you're using reinforcement learning, generate an enormous amount of synthetic data or synthetically generated tokens. AI models are basically generating tokens to train AI models. That's post-train. And the third part, this is the part that you mentioned, is test time compute or reasoning. Long thinking, inference scaling, basically the same ideas. And there's you have chain of thought, you have search. The amount of tokens generated, the amount of inference compute needed, is already a hundred times more than the one-shot examples and the one-shot capabilities of large language models in the beginning and that's just the beginning. This is just the beginning. The idea that the next generation could have thousands of times and even hopefully extremely thoughtful and simulation-based and search-based models that could be hundreds of thousands, millions of times more compute than today, is in our future. And so the question is how do you design such an architecture? Some of the models are autoregressive. Some of the models are diffusion-based. Some of the times you want your data center to have disaggregated inference. Sometimes it's compacted. And so it's hard to figure out what is the best configuration of a data center, which is the reason why NVIDIA Corporation's architecture is so popular. We run every model. We are great at training. The vast majority of our compute today is actually inference, and Blackwell takes all of that to a new level. We designed Blackwell with the idea of reasoning models in mind. And you look at training, it's many times more performant. But what's really amazing is for long-thinking, test time scaling reasoning AI models, we're tens of times faster, 25 times higher throughput. And so Blackwell is gonna be incredible across the board. And when you have a data center, that allows you to configure and use your data center based on are you doing more pretraining now, post-training now? Or scaling out your inference our architecture is fungible, and easy to use. In all of those different ways. And so we're seeing, in fact, much, much more concentration of a unified architecture than ever before.\nChrista: Your next question comes from the line of Joseph Moore with JPMorgan. Please go ahead.\nJoseph Moore: I wonder if you could talk about GV200 at CES. You sort of talked about the complexity of the rack-level systems and the challenges you have. And then as you said in the prepared remarks, we've seen a lot of general availability. You know, where are you in terms of that ramp? Are there still bottlenecks to consider at a systems level above and beyond the chip level? And just you know, have you maintained your enthusiasm for the NVLink 72 platforms?\nJensen Huang: Well, I'm more enthusiastic today than I was at CES. And the reason for that is because we shipped a lot more to CES. We have some 350 plants manufacturing the one and a half million components that go into each one of the Blackwell racks. Base Blackwell racks. Yes. It's extremely complicated. And we successfully and incredibly ramped up Grace Blackwell. Delivering some $11 billion of revenues last quarter. We're gonna have to continue to scale as demand is quite high and customers are anxious and impatient to get their Blackwell systems. You'd probably seen on the web a fair number of celebrations about Grace Blackwell Systems coming online and we have them, of course. We have a fairly large installation of Grace Blackwell for our own engineering and our own design teams and software teams. Coreweave has now gone public about the successful bring-up of theirs. Microsoft has. Of course, OpenAI has. And you're starting to see many come online. So I think the answer to your question is nothing is easy about what we're doing. But we're doing great, and all of our partners are doing great.\nChrista: Your next question comes from the line of Vivek Arya with Bank of America Securities. Please go ahead.\nVivek Arya: Thank you for taking my question. Could I just you wouldn't mind confirming if Q1 is the bottom for gross margins? And then, Jensen, my question is for you. What is on your dashboard to give you the confidence that the strong demand can sustain into next year and has DeepSeq and whatever innovations they came up with, has that changed that view in any way? Thank you.\nColette Kress: Let me first take the first part of the question. Regarding the gross margin. During our Blackwell ramp, our gross margins will be in the low seventies. At this point, we are focusing on expediting our manufacturing. Expediting our manufacturing is to make sure that we can provide customers as soon as possible. Our Blackwell is fully ramped. And once it does, I'm sorry. Blackwell fully ramps, we can improve our cost and our gross margin. So we expect to probably be in the mid-seventies later this year. You know, walking through what you heard, Jensen speak about the systems and their complexity. They are customizable in some cases. They've got multiple networking options. Have liquid cool and water-cooled. So we know there is an opportunity for us to improve these gross margins going forward. But right now, we are gonna focus on getting the manufacturing plate into our customers as soon as possible.\nJensen Huang: We know several things, Vivek. We have a fairly good line of sight of the amount of capital investment that data centers are building out towards. We know that going forward, the vast majority of software is gonna be based on machine learning. And so accelerated computing and generative AI, reasoning AI, are going to be the type of architecture you want in your data center. We have, of course, forecast and plans from our top partners. And we also know that there are many innovative really exciting start-ups that are still coming online. As new opportunities for developing the next breakthroughs in AI, whether it's agentic AIs, reasoning AIs, or physical AIs. The number of start-ups are still quite vibrant and each one of them needs a fair amount of computing infrastructure. So I think the whether it's the near-term signals or the mid-term signals. Near-term signals, of course, are, you know, POs and forecasts and things like that. Mid-term signals, would be the level of infrastructure and CapEx scale out compared to previous years. And then the long-term signals it has to do with the fact that we know fundamentally software has changed. From hand coding that runs on CPUs through machine learning and AI-based software that runs on GPUs and accelerated computing systems. So we have a fairly good sense that this is the future of software. And then maybe as you roll it out, another way to think about that is we've really only touched consumer AI and search and some amount of consumer generative AI. Advertising, recommenders, kind of the early days of software. The next wave's coming. Agentic AI for enterprise, physical AI for robotics. And Sovereign AI has different regions build out their AI for their own ecosystems. And so each one of these are barely off the ground, and we can see them. We can see them because, you know, obviously, we're in the center of much of this development. And we can see great activity happening in all these different places. And these will happen. So near-term, mid-term, long-term.\nChrista: Your next question comes from the line of Matt Ramsay with Cowen. Please go ahead.\nMatt Ramsay: Yeah. Good afternoon. Thanks for taking my question. Your next generation Blackwell Ultra is set to launch in the second half of this year. In line with the team's annual product cadence. Jensen, can you help us understand the demand dynamics for Ultra given that you'll still be ramping the current generation Blackwell solutions? How do your customers and the supply chain also manage the simultaneous ramps of these two products and is the team still on track to execute Blackwell Ultra in the second half of this year?\nJensen Huang: Yes. Blackwell Ultra is second half. As you know, the first Blackwell was have we had a hiccup? That probably cost us a couple of months. We're fully recovered, of course. The team did an amazing job recovery. And all of our supply chain partners and just so many people helped us recover at the speed of light. And so now we've successfully ramped production of Blackwell. But that doesn't stop the next train. The next train is you know, it's on an annual rhythm. And, Blackwell Ultra with, new networking, new memories, and, of course, new processors and all of that is coming online. We've been working with all of our partners and customers laying this out. They have all of the necessary information. And we'll work with everybody to do the proper transition. This time between Blackwell, Blackwell Ultra, the system architecture is exactly the same. It's a lot harder going from Hopper to Blackwell because we went from an NVLink 8 system to a NVLink 72 base system. So the chassis, the architecture of the system, the hardware, the power delivery, all of that had to change. This was quite a challenging transition. But the next transition will slot right in. Grace Blackwell Ultra will slot right in. We've also already revealed and been working very closely with all of our partners on the click after that. And the click after that is called Vera Rubin. And, all of our partners are getting up to speed on the transition of that. And so preparing for that transition and, again, we're gonna provide a big, big, huge step up. And so come to GTC, and I'll hold on to you about Blackwell Ultra, Vera Rubin, and then show you what's the one click after that. Really, really exciting new product, so come to GTC, please.\nChrista: Your next question comes from the line of Timothy Arcuri with UBS. Please go ahead.\nTimothy Arcuri: Thanks a lot. Jensen, we hear a lot about custom ASICs. Can you kinda speak to the balance between custom ASIC and merchant GPU? We hear about some of these heterogeneous super clusters to use both GPU and ASIC. Is that something customers are planning on building or will these infrastructures remain fairly distinct? Thanks.\nJensen Huang: Well, we build very different things than ASICs. In some ways, completely different in some areas we intercept. We're different in several ways. One, NVIDIA Corporation's architecture is general. You know, whether you've optimized for autoregressive models or diffusion-based models or vision-based models or multimodal models or text models. We're great in all of it. We're great in all of it because our software stack is so our architecture is responsible. Our software stack is ecosystem is so rich that we're the initial target of, you know, most exciting innovations and algorithms. And so by definition, we're much, much more general than narrow. We're also really good from the end to end. From data processing, the curation of the training data, to the training of the data, of course, to reinforcement learning used in post-training. All the way to inference with test time scaling. So, you know, we're general. We're end to end. And we're everywhere. And because we're not in just one cloud, we're in every cloud, we could be on-prem. We could be in, you know, in a robot. Our architecture is much more accessible. And a great target initial target for anybody who's starting up a new company. And so we're everywhere. And then the third thing I would say is that our performance and our rhythm is so incredibly fast. Remember that these data centers are always fixed in size. They're fixed in size or they're fixed in power. And if our performance per watt is anywhere from 2x to 4x to 8x, which is not unusual. It translates directly to revenues. And so if you have a 100-megawatt data center, if the performance or the throughput that 100-megawatt or that gigawatt data center is four times or eight times higher your revenues for that gigawatt data center is eight times higher. And the reason that is so different than data centers of the past is because AI factories are directly monetizable through its tokens generated. And so the token throughput of our architecture being so incredibly fast is just incredibly valuable to all of the companies that are building these things for revenue generation reasons. And capturing the fast ROIs. So I think the third reason is performance. And then the last thing that I would say is the software stack is incredibly hard. Building an ASIC is no different than what we do. We have to build a new architecture. And the ecosystem that sits on top of our architecture is ten times more complex today than it was two years ago. And that's fairly obvious because the amount of software this world building on top of architecture is growing exponentially and AI is advancing very quickly. So bringing that whole ecosystem on top of multiple chips is hard. And so I would say that those four reasons and then finally, I will say this. Just because the chip is designed doesn't mean it gets deployed. And you've seen this over and over again. There are a lot of chips that get built. But when the time comes a business decision has to be made. And that business decision is about deploying a new engine, a new processor into a limited AI factory in size and power and find. And our technology is, you know, not only more advanced, more performant, it has much, much better software capability, and very importantly, our ability to deploy is lightning fast. And so these things are enough for the faint of heart as everybody knows now. And so there's a lot of different reasons why we do well. Why we win.\nChrista: Your next question comes from the line of Ben Reitzes with Melius Research. Please go ahead.\nBen Reitzes: Yeah. Hi. Ben Reitzes here. Hey. Thanks a lot for the question. Hey, Jensen. It's a geography-related question. You know, you did a great job explaining some of the demand underlying, you know, factors here on the strength. But the US was up about $5 billion or so sequentially. And I think, you know, there is a concern about whether the US can pick up the slack if there's regulations towards other geographies. And I was just wondering as we go throughout the year, you know, if this kind of surge in the US continues and it's gonna be whether that's okay. And if that underlies your growth rate, how can you keep growing so fast with this mix shift towards the US? Your guidance looks like China is probably up sequentially. So just wondering if you could go through that dynamic and maybe Colette can weigh in. Thanks a lot.\nJensen Huang: China is approximately the same percentage as Q4. And as in as previous quarters. It's about half of what it was before the export control. But it's approximately the same in percentage. With respect to geographies, the takeaway is that AI is software. It's modern software. It's incredible modern software. But it's modern software. And AI has gone mainstream. AI is used in delivery services everywhere, shopping services everywhere. You know? You were to buy a quart of milk is delivered to you. AI was involved. And so almost everything that a consumer service provides AI's at the core of it. Every student will use AI as a tutor. Health care services use AI. Financial services use AI. No fintech company will not use AI. Every fintech company will. Climate tech company uses AI. Mineral Discovery now uses AI. The number of every higher education, every university, uses AI. So I think it is fairly safe to say that AI has gone mainstream. And that it's being integrated into every application. And our hope is that, of course, the technology continues to advance safely and advance in a helpful way to our society. And with that, you know, we're I do believe that we're at the beginning of this new transition. And what I mean by that in the beginning, is remember behind us has been decades of data centers and decades of computers that have been built. And they've been built for a world of hand coding and general-purpose computing. And CPUs and so on and so forth. And going forward, I think it's fairly safe to say that that world is going to be almost all software will be infused with AI. All software and all services will be based on ultimately based on machine learning, and the data flywheel is gonna part of improving software and services. And that the future computers will be accelerated. The future computers will be based on AI. And we're really three years into that journey. And in modernizing computers that have taken decades to build out. And so I'm fairly sure that we're in the beginning of this new era. And then lastly, no technology has ever had the opportunity to address a larger part of the world's GDP than AI. No software tool ever has. And so this is now a software tool that can address a much larger part of the world's GDP, more than any time in history. And so the way we think about growth and the way we think about whether something is big or small. Has to be in the context of that. And when you take a step back and look at it from that perspective, we're really just in the beginnings.\nChrista: Your next question comes from the line of Aaron Rakers with Wells Fargo. Please go ahead. Erin, your line is open. Your next question comes from Mark Lipacis with Evercore ISI. Please go ahead.\nMarshall Pappas: Hi. This is Marshall Pappas. Thanks for taking the question. Question. I had a clarification and a question. Colette, for the clarification. Did you say that enterprise within the data center grew 2x year on year for the January quarter? And if so, does that would that make it the faster growing than the hyperscalers? And then, Jensen, for you, the question, hyperscalers are the biggest purchasers of your solutions, but they buy equipment for both internal and external workloads, external workloads being cloud services that enterprises use. So the question is, can you give us a sense of how that hyperscale expense splits between that external workload and internal and as these new AI workflows and applications come up, would you expect enterprises to become a larger part of that consumption mix? And does that impact how you develop your service your ecosystem? Thank you.\nColette Kress: Sure. Thanks for the question regarding our enterprise business. Yes. It grew 2x. Very similar to what we were seeing with our large CSPs. Keep in mind, these are both important areas to understand. Working with the CSPs can be working on large language models. Can be working on inference on their own work? But keep in mind, that is also where the enterprises are surfacing. Your enterprises are both with your CSPs, as well as in terms of building on their own. They're both growing quite well.\nJensen Huang: The CSPs are about half of our business. And the CSPs have internal consumption, and external consumption, as you say. And we're using of course, used for internal consumption. We work very closely with all of them to optimize workloads that are internal to them because they have a large infrastructure of NVIDIA Corporation gear that they could take advantage of. And the fact that we could be used for AI on the one hand, video processing on the other hand, data processing like Spark. We're fungible. And so the useful life. Our infrastructure is much better. If the useful life is much longer, then the TCO is also lower. And so the second part is how do we see the growth of enterprise or not CSPs, if you will, going forward? And the answer is I believe, long term. It is by far larger. And the reason for that is because if you look at the computer industry today, and what is not served by the computer industry is largely industrial. Let me give you an example. When we say enterprise, and let's say let's use a car company as an example because they make both soft things and hard things. And so in the case of a car company, the employees would be what we call enterprise. And agentic AI and software planning systems and tools, and we have some really exciting things to with you guys at GTC. Those agentic systems are for employees to make employees more productive. To design, to market, plan, to operate their company. That's agentic AIs. On the other hand, the cars that they manufacture also need AI. They need an AI system that trains the cars treats this entire giant fleet of cars, and you know, today, there's some billion cars on the road. Someday, there'd be a billion cars on the road, and every single one of those cars will be, you know, robotic cars. And they'll all be collecting data, and we'll be improving them using an AI factory where they whereas they have a car factory today, in the future, they'll have a car factory and an AI factory. And then inside the car itself is a robotic system. And so as you can see, there are three computers involved. And there's the computer that helps the people. There's the computer that builds the AI for it. The machineries. It could be, of course. Could be a tractor. It could be a lawnmower. It could be a human or a robot that's being developed today. It could be a building. It could be a warehouse. These physical systems require a new type of AI we call physical AI. They can't just understand the meaning of words and languages but they have to understand the meaning of the world. Friction and inertia, object permanence, and cause and effect, and all of those types of things that are common sense to you and I. But you know, AI has to go learn those physical effects. So we call that physical AI. That whole part of using agentic AI to revolutionize the way we work inside companies. That's just starting. This is now the beginning of the agentic AI era. And you hear a lot of people talking about it and got some really great things going on. And then there's the physical AI after that, and then there's robotic systems after that. And so these three computers are all brand new. And my sense is that long term, this will be by far a larger of a mold which kinda makes sense. You know, the world the world's GDP is represented by either heavy industries industrials. And companies that are providing for those.\nChrista: Your next question comes from the line of Aaron Rakers with Wells Fargo. Please go ahead.\nAaron Rakers: Yeah. Thanks for letting me back in. Jensen, I'm curious as we now approach the two-year anniversary of really the Hopper inflection that you saw in 2023 in Gen AI in general. We think about the roadmap you have in front of us, how do you think about the infrastructure that's been deployed from a replacement cycle perspective and whether, you know, if it's GV300 or if it's the Rubin cycle where we start to see maybe some refresh opportunity. I'm just curious to how you look at that.\nJensen Huang: Yeah. I appreciate it. First of all, people are still using Voltas. And Pascals, and Amperes. And the reason for that is because they're always things that because CUDA is so programmable, you could use it right well, one of the major use cases right now is data processing and data curation. You find a circumstance that an AI model is not very good at? You present that circumstance to a vision language model, let's say. Let's say it's a car? You present that circumstance to a vision language model, the vision language model actually looks at the circumstances. It's a this isn't this is what happened, and I wasn't very good at it. You then take that response, this the prompt, and you go and prompt an AI model to go find in your whole link of data of other circumstances like that. Whatever that circumstance was. And then you use an AI to do domain randomization and generate a whole bunch of other examples. And then from that, you can go train the model. And so you could use the Amperes to go and do data processing and data curation and machine learning-based search. And then you create the training dataset, which you then present to your Hopper systems for training. And so each one of these architectures are completely are you know, they're all CUDA compatible, and so everything runs on everything. But if you have infrastructure in place, and you can put the less intensive workloads onto the installed base of the past. All of our CPUs are very well employed.\nChrista: We have time for one more question, and that question comes from Atif Malik with Citi. Please go ahead.\nAtif Malik: Hi. Thank you for taking my question. I have a follow-up question on gross margins, Colette. I understand there are many moving parts that will yield and NVLink 72 and Ethernet mix. And you kind of tiptoed the earlier question if April quarter is the bottom. But second half would have to ramp, like, 200 basis point per quarter to get to the mid-seventies range that you're giving, for the end of the fiscal year. And we still don't know much about tariffs impact to broader semiconductor. So what kind of gives you the confidence in that trajectory in the back half of this year?\nColette Kress: Yeah. Thanks for the question. Our gross margins, they're quite complex. In terms of the material. And everything that we put together in a Blackwell system. Tremendous amount of opportunity to look at a lot of different pieces of that. On how we can better improve our gross margins over time. Remember, we have many different configurations as well. On Blackwell. That will be able to help us do that. So, together, working after we get some of these really strong ramping completed for our customers we can begin a lot of that work. If not, we're gonna probably start as soon as possible. If we can improve it in the short term, we will also do that. Tariffs, at this point, it's a little bit of an unknown. It's an unknown until we understand further what the US government's plan is, its timing, it's where, and how much. So at this time, we are awaiting but again, we would, of course, always follow export control and or tariffs in that manner.\nChrista: Ladies and gentlemen, that does conclude our question and answer session. I'm sorry. Thank you.\nJensen Huang: No. No. I'm gonna just wanna thank you. Up to, Jensen? And, like, the medium, a couple things. I just wanna thank you. Thank you, Colette. Demand for Blackwell is extraordinary. AI is evolving beyond perception. And generative AI into reasoning. With reasoning AI, we're observing another scaling law. Inference time or test time scaling. The more computation the more the model thinks the smarter the answer. Models like OpenAI's Grok 3, DeepSeq R1, are reasoning models that apply inference time scale. Reasoning models can consume a hundred times more compute. Future reasoning models can consume much more compute. DeepSeq R1 has ignited global enthusiasm. It's an excellent innovation. But even more importantly, it has open-sourced a world-class reasoning AI model. Nearly every AI developer is applying R1. Or chain of thought and reinforcement learning techniques like R1. To scale their model's performance. We now have three scaling laws, as I mentioned earlier. Driving the demand for AI computing. The traditional scaling laws of AI remain intact. Foundation models are being enhanced with multimodality. And pretraining is still growing. But it's no longer enough. We have two additional scaling dimensions. Post-training scaling, where reinforcement learning fine-tuning, model distillation, require orders of magnitude more compute than pretraining alone. Inference time scaling and reasoning where a single query can demand a hundred times more compute. We designed Blackwell for this moment a single platform that can easily transition from pretraining, post-training, and test time scaling. Blackwell's MP4 transformer engine, and NVLink 72 scale-up fabric. And new software technologies let Blackwell process reasoning AI models 25 times faster than Hopper. Blackwell, in all of these configurations, is in full production. Each Grace Blackwell NVLink 72 rack is an engineering marvel. One and a half million components produced across 350 manufacturing sites by nearly a hundred thousand factory operators. AI is advancing at light speed. We're at the beginning of reasoning AI and inference time scaling. But we're just at the start of the age of AI. Multimodal AIs. Enterprise AI, Sovereign AI. And physical AI are right around the corner. We will grow strongly in 2025. Going forward, data centers will dedicate most of CapEx to accelerated computing and AI. Data centers will increasingly become AI factories. And every company will have a either rented or self-operated. I wanna thank all of you for joining us today. Come join us at GTC in a couple of weeks gonna be talking about Blackwell Ultra, Rubin, and other new computing networking, reasoning AI, physical AI products. And a whole bunch more. Thank you.\nChrista: This concludes today's conference call. You may now disconnect.",
      "company": "NVDA"
    }
  ],
  "combined_text": "## DELL Earnings Call: 2025-02-28 17:26:00\n\nOperator: Good afternoon and welcome to the Fiscal Year 2025 Fourth Quarter Financial Results Conference Call for Dell Technologies Inc. I'd like to inform all participants that this call is being recorded at the request of Dell Technologies. This broadcast is a copyrighted property of Dell Technologies Inc. Any rebroadcast of this information in whole or part without the prior written permission of Dell Technologies is prohibited. [Operator Instructions] I'd like to turn the call over to Paul Frantz, Head of Investor Relations. Mr. Frantz, you may begin.\nPaul Frantz: Thanks, everyone, for joining us. With me today are Jeff Clarke, Yvonne McGill and Tyler Johnson. Our earnings materials are available on our IR website, and I encourage you to review those materials. Also, please take some time to review the presentation, which includes additional content to complement our discussion this afternoon. Guidance will be covered on today's call. During this call, unless otherwise indicated, all references to financial metrics refer to GAAP financial measures, including non- GAAP gross margin, operating expenses, operating income, net income, diluted earnings per share, free cash flow and adjusted free cash flow. A reconciliation of these measures to the most directly comparable GAAP measures can be found in our web deck and our press release. Growth percentages refer to year-over-year change unless otherwise specified. Statements made during this call that relate to future results and events are forward-looking statements based on current expectations. Actual results and events could differ materially from those projected due to a number of risks and uncertainties, which are discussed in our web deck and SEC filings. We assume no obligation to update our forward-looking statements. Now I'll turn it over to Jeff.\nJeff Clarke: Thanks, Paul, and thanks, everyone, for joining us. I am proud of the team's execution this year. We navigated an incredibly dynamic AI environment and accelerating server consolidation, a significant pivot to Dell IP storage and a lagging PC refresh and delivered results above our long-term value-creation framework. We grew our company while reducing our operating expenditures over the course of the year. Our modernization have made us more efficient and provided us the ability to invest more innovation and in areas of strategic differentiation. Our FY '25 revenue was $95.6 billion, up 8%, with operating income of $8.5 billion. OpEx was reduced by 4% over the course of the year. This resulted in record EPS of $8.14, up 10%, and cash flow of $4.5 billion. We continue to differentiate ourselves with consistent performance through numerous economic cycles, different technology buying and adoption cycles and our rapidly innovating technology ecosystem. Some examples of the innovation from this past year. We added five platforms to our AI-optimized portfolio, including support of the oil architectures, the highlight being the PowerEdge XE9712 supporting NVIDIA's NVL72 GB200, which we were the first to ship in the world. We launched the Dell Infrastructure Rack Sobel system, our IR7000 and 5000 in both 21-inch and 19-inch versions, providing up to 96 GPUs in a rack and 786 GPUs in a scalable unit. We have made significant advancements of CPUs, cold plates metals and power distribution with our IR7000 supporting up to 480 kilowatts per rep. We introduced our direct-to-chip liquid cooling version of the 9680, providing 33% density improvement and 2.5x improvement in energy efficiency. We made significant advancements to PowerStore with PowerStore Prime, our mid-range storage solution addressing the fastest-growing portion of the market. And we introduced the PowerScale F910 and F710 in our unstructured portfolio that is prime to support unstructured and AI workloads. We introduced the most Copilot+ PCs powered by ARM-based Qualcomm Snapdragon processors and also launched the broadest portfolio of Intel Meteor Lake commercial PCs, furthering our number one leadership position in commercial AI PCs worldwide. We continued our number one leadership in PC monitors with the world's first 4k monitors to achieve 5-star Eye Comfort certification. focused on expanding our peripherals portfolio selling everything around the PC docking stations, cameras, mice, keyboards and headsets, including the first and only holistic solution to manage your fleet of PCs and peripherals remotely, creating the best possible customer experience. And finally, we simplified our branding, redesigned our PC portfolio and broadened our silicon options across Intel, AMD and Qualcomm, setting us up well for the PC refresh. We are extremely well positioned to capture growth across every segment of our business and extend AI from the largest at-scale CSPs to enterprise workloads and out to the edge with the PC. These tailwinds and our unique operating model that leverages our leading product positions, our go-to-market engine, services and supply chain, underpin our confidence that our opportunity continues to grow as we look ahead to FY '26. Moving to Q4. Revenue was $23.9 billion, up 7%, driven by a robust ISG growth. We executed particularly strong with substantial operating margin improvement in ISG driven by our Dell IP storage portfolio. This resulted in EPS of $2.68, up 18%, growing faster than revenue. Turning to BU results. Let's start with ISG. The prospects for AI are strong, and we are very well positioned. In Q4, AI orders demand was $1.7 billion with $2.1 billion in shipments in order with $4.1 billion in backlog as customers work through technology changes. And in February, our partnership with XAI and other customers continued. We booked deals putting our AI backlog at roughly $9 billion as of today. Our pipeline expanded sequentially and has grown every quarter since the introduction of the 9680. We are seeing continued progress in AI from enterprise customers, albeit still earlier in their journey with sequential growth in both orders and customers. And our engineering services, financing and ability to optimize density and performance per watt are important differentiators for the largest at-scale CSPs and provide very efficient enterprise solutions. In traditional servers, the growth trajectory continues, up double digits in Q4. We've now seen 5 quarters of year-over-year demand. Our mix of 16G servers continues to increase as customers remain focused on consolidation to improve power efficiency and increase floor space. The server consolidation in the data center is expanding server TRUs driven by service with more CPU cores, storage and memory. In storage, we saw P&L growth for the second consecutive quarter with very strong profitability driven by our Dell IP storage portfolio. PowerStore, our flagship midrange product, has had strong demand growth for four consecutive quarters, the most recent three at double-digit demand growth. As I mentioned, the software and hardware updates we made with PowerStore Prime resonate with customers and partners. We have industry-leading 5:1 data reduction, delivered 30% improvement in IOPS Native MetroSync and QLC availability. We also saw double-digit demand growth in PowerScale, our leading unstructured storage platform, and continued growth in our buyer base with PowerFlex. We are well positioned in some of the fastest-growing categories within storage as customers shift towards disaggregated architectures. In CSG, we are seeing the recovery coming with strength in SMB, which historically is a leading indicator. We also saw large opportunities within the quarter, which were very competitive. Commercial was up 5%, marking the second consecutive quarter of year-over-year growth and the fourth consecutive quarter of demand growth. Consistent with what we saw coming out of Q3, customers are waiting to refresh to buy AI PCs that future-proof their purchases going forward. Consumer continues to be challenged with softer demand and elevating levels of discounting. We expect a broader PC refresh this year as the installed base continues to age, we get closer to the Windows 10 end of life and AI PCs are more broadly available. To close, I am proud of our FY '25 results and our ability to execute our strategy, leveraging our strengths to extend our leadership positions and capture new growth. The AI hardware and services TAM has nearly doubled over the course of the year to $295 billion in 2027, growing at a 33% CAGR. We are well positioned in AI, traditional servers, storage with our focus on Dell IP and PCs, including everything around the device. We continue to drive a disproportionate level of AI growth by demonstrating the value we provide to our customers and I'm excited for the tailwinds surrounding our business as we enter FY '26. Now over to Yvonne for more details about Q4.\nYvonne McGill: Thanks, Jeff. Let me begin with an overview of our Q4 performance, then I'll move to ISG, CSG cash and guidance. In the fourth quarter, we delivered strong profitability, specifically in ISG. Our total revenue was up 7% to $23.9 billion. This was driven by continued strength in servers. Our combined ISG and CSG business grew 10%. Gross margin was $5.8 billion or 24.3% of revenue. This is down 50 basis points due to a more competitive pricing environment, predominantly in CSG and an increase in our AI-optimized server mix. Within gross margin, we discovered previously unrecognized accumulated credits from suppliers. You'll find revised financial results within our Q4 press release that reflect higher gross margin and increased earnings per share for the relevant period. Operating expense was down 6% to $3.1 billion or 13.1% of revenue. FY '25 was a transformative year as we reevaluated, reimagined and modernized how we operate. This enabled us to unlock efficiencies and increase productivity, all while growing our core business double digits. Now let's look at operating income. We delivered a 22% increase to $2.7 billion or 11.2% of revenue. This was driven by higher revenue and lower operating expenses, partially offset by a decline in our gross margin rate. Q4 net income was up 15% to $1.9 billion primarily driven by stronger operating income. And our diluted EPS was up 18% to $2.68. Now let's move to ISG, where we delivered another quarter of strong performance. ISG revenue was $11.4 billion, up 22%. Servers and networking revenue was a Q4 record at $6.6 billion, up 37%. We continue to see strong demand across both AI and traditional servers. Storage revenue was up 5% to $4.7 billion, a second consecutive quarter of growth. We executed very well in storage. We had a record demand quarter for PowerStore. PowerScale grew double digits, and our PowerFlex buyer base grew. While the overall demand environment is lagging that of traditional servers, we see some promising trends. We had record ISG operating income of $2.1 billion, up 44%. This was driven primarily by higher revenue. Our ISG operating income rate was up again sequentially to a record 18.1% of revenue. The rate improvement of 480 basis points was the result of improved gross margins, especially in storage, and reduced operating expense. Within storage, we saw record profitability driven by a higher mix of Dell IP versus partner IP, improved product profitability and revenue scaling in what is seasonally our strongest quarter. Now let's turn to CSG. CSG revenue was up 1% to $11.9 billion. Commercial revenue was up 5% to $10 billion, while consumer revenue was down 12% to $1.9 billion. CSG operating income was $0.6 billion or 5.3% of revenue. This is down 90 basis points sequentially due to a more competitive pricing environment. We saw some promising signs as we went through November and December with pockets of strength in large deals, but overall saw a slowdown in January. As Jeff mentioned, we saw strength in small and medium business, which is historically a leading indicator. Profitability in commercial was weaker than expected as demand continued to push into the next fiscal year. In consumer, the demand environment remains soft and profitability remains challenged. We are ready and well positioned for a PC refresh with our simplified rebrand, leading go-to-market engine and focus on commercial PCs, the most profitable segments of the market. Shifting gears, Dell Financial Services continues to drive differentiated payment solutions for our customers. We exited the year with a record $15 billion in assets under management, up 5%. And when you normalize for the exit of our VMware resell business and the discontinuation of our commercial revolving product, DFS originations were up 7% in Q4 with a strong attach rate across the business. Now let's move to cash flow and the balance sheet. Q4 cash flow from operations was $0.6 billion. This was primarily driven by profitability, partially offset by working capital. Our cash conversion cycle was negative 31 days with $6.7 billion in inventory. We ended the quarter with $5.2 billion in cash and investments, down $1.4 billion sequentially. Our core leverage ratio was down sequentially to 1.2x. We returned $1.1 billion of capital to shareholders with 6.4 million shares of stock repurchased at an average price of $117.51 and paid a dividend of $0.45 per share. Since our capital reaching program began at the beginning of FY '23, we've returned $10.8 billion to shareholders through stock repurchases and dividends. We announced an 18% increase in our annual dividend to $2.10 per share, well above our long-term value-creation framework. Additionally, the Board of Directors has approved a $10 billion increase in our share repurchase authorization. This is a testament to our confidence in the business and our ability to generate strong cash flow. Turning to FY '26 guidance. IT spending is expected to grow with 3 underlying trends that we see. First, businesses are leveraging AI to enable competitive advantages, and we are seeing that in our opportunity pipeline that continues to expand. Second, data center modernization is well underway with a focus on consolidation and power efficiency. Third, customers are planning to refresh their PC installed base with AI-enabled devices. As these trends materialize, we will leverage our operating model that has driven value creation over the last 40 years. Against that backdrop, we expect revenue and EPS growth in FY '26 above our long-term value-creation framework. We expect FY '26 revenue to be between $101 billion and $105 billion with a midpoint of $103 billion, up 8%. We expect ISG to grow high teens driven by $15 billion of AI server shipments and continued growth in traditional server and storage. And we expect CSG to grow low to mid-single digits, more weighted towards the second half of the year. We expect the combination of ISG and CSG to grow 10% at the midpoint. Given the higher mix of our AI-optimized servers and the current competitive environment, we expect our gross margin rate to decline roughly 100 basis points. As our modernization efforts continue, we expect OpEx to be down low single digits year-over-year. We expect ISG operating income rate to be roughly flat year-over-year with CSG down slightly. We expect I&O to be between $1.4 billion and $1.5 billion. Diluted non-GAAP EPS is expected to be $9.30 plus or minus $0.25, up 14% at the midpoint, assuming an annual non-GAAP tax rate of 18%. For Q1, we expect revenue to be between $22.5 million and $23.5 billion, up 3% at the midpoint of $23 billion. ISG and CSG combined are expected to grow 6% at the midpoint with ISG growing low teens and CSG flat year-over-year. Gross margin rate will be lower sequentially given seasonally lower storage mix and a higher AI-optimized server mix. OpEx will be down low single digits year-over-year. We expect operating income rate to be down sequentially given typical seasonality in ISG with lower storage mix. We expect our diluted share count to be between 706 million and 710 million shares, and our diluted non-GAAP EPS is expected to be $1.65 plus or minus $0.10, up 25% at the midpoint. In closing, we delivered solid FY '25 results, well above our long-term value-creation framework. We generated $95.6 billion in revenue, record EPS of $8.14 and returned $3.9 billion of capital to our shareholders. We executed our strategy and expanded our lead in AI while positioning our core business for the opportunity ahead. Internally, we began a transformation to future-proof the company, focusing on supplying, automating and modernizing how we work. And as we look forward, I'm excited about the sustainable growth we see and the value we will continue to deliver to our customers and our shareholders. Now I'll turn it back to Paul to begin Q&A.\nPaul Frantz: Thanks, Yvonne. Let's get to Q&A. In order to ensure we get to as many of as possible, please ask one concise question. Let's go to the first question, operator.\nOperator: [Operator Instructions]. And the first question comes from Wamsi Mohan with Bank of America.\nWamsi Mohan: Yes, thank you so much. Yvonne, could you talk through the fiscal '26 guide? And what sort of maybe some of the assumptions that are incorporated beyond what you stated? Your revenues are going to be up roughly in total about 7.7%, EPS up about 14%. But your comments on ISG and CSG margins are flat to down, and you noted a fairly competitive environment. So can you just bridge those sort of comments to your EPS growth? How much is coming potentially from buybacks? And have you made any tariff-related assumptions in these margin guides? Thank you so much.\nYvonne McGill: Thanks, Wamsi. So yes, in the guide for the year, we guided to the $103 billion of midpoint, up 8%, with everything growing, right? ISG and CSG expected to be up combined about 10%. If I look at ISG, which I think some of your question is coming from, we expect that to be in the high teens, fueled by that $15 billion of AI server shipments that we referred to as well as continued growth in both traditional server and storage, I'd say with storage in the low single digits. CSG, we do expect to grow in the mid-single digits coming up for the year that's just begun with that refresh cycle that we're expecting to be more weighted towards the second half of the year. OpEx is another area. We guided to it being down low single digits year-over-year. That's just a continuation of all of the efficiencies that we're driving across the entire company. And then the improving year-over-year to the 9.1%, up from 8.9%, so an improvement there. When I think of what to expect from an ISG standpoint from an offing level, we're saying roughly flat year-over-year. And we expect there to be continued competition, I guess, is the right way to put it in CSG. But again, we've guided and embedded that in there. And I go back to ISG real quick and say, hey, we are going to be growing the AI business while continuing to drive profitability there. So we'll continue to balance, as we have been doing, our growth and profitability. And we're going to manage pricing, we're going to manage the competitive environment, and we're going to continue to drive value for our shareholders.\nJeff Clarke: Thanks, Wamsi.\nOperator: And the next question comes from Erik Woodring with Morgan Stanley.\nErik Woodring: Great guys, thanks so much for taking my question. Jeff, a question I often get from investors is kind of about the risk of ODM encroachment in the AI server market. As customers get more sophisticated over time, competition intensifies, potentially margins face downward pressure. Effectively, the concern is AI servers become somewhat of a cloud 2.0 type of disintermediation. Clearly, your AI server backlog helps to refute this concern. But I would love if you could just maybe -- how would you respond to those concerns if you got that question? Thanks so much.\nJeff Clarke: Sure. Thanks, Erik. I mean, do we see the ODMs in these large opportunities? Of course, we do. These are multibillion-dollar opportunities. Everybody tends to show up and wants an opportunity to win the business. When I step back and reflect why Dell and why we continue to be optimistic here is this is custom work. It takes significant engineering capability. It takes significant architecture capability to win. And in many cases, we're building a unique and differentiated solution for each and every customer. And our customers have learned to value what we've been able to bring to them across their deployments, whether that is the service side when we extend beyond an L10 server out of the factory with L11 and L12 and full integration of Iraq, on the network expertise we bring to do the install and deployment of very complex network arrays. When I think about service, the ability that we have a global service footprint, professional servers can show up anywhere to solve any related problem or hands-on in these very large deployments with full-time teams. Literally, they're 24/7 trying to get them up and running. I think about the financing capabilities that we have in our company and the ability to help these CSPs, these fast- growing companies grow at the rates they want with our financing capabilities, I think about our go-to-market coverage and I think about the expertise we have in the top 30-or-so CSPs digital natives, our ability to scale this to enterprise. Erik, every time I look at this question, and I don't really focus on ODMs or for that matter, other OEMs. I look at the differentiated value we are bringing to the marketplace with the Dell company bringing end-to-end solutions. And right now, it's valued. And right now, we continue to differentiate. Right now, we help these large scale clusters get deployed faster than anybody else. I'll remind you, I probably did last time as well, we were the first to bring to market a GB200 rack. That's not by luck. It's by a lot of hard work, detailed engineering, collaborating in this case with NVIDIA and our customer to be able to take out every ounce of time and run at the speed of light, so to speak. So we're going to continue to invest in that differentiation. We're going to continue to make us stand out to be different. Our customers really value the full range of our capabilities. They like the notion of a one place to go. I'm not sure others bring that. I know we do, and I know we're extracting value from the marketplace for that with our customers and our deployments.\nErik Woodring: Awesome. Thank you, Jeff. I appreciate it. Good luck, guys.\nJeff Clarke: You're welcome.\nOperator: And the next question will come from Simon Leopold with Raymond James.\nSimon Leopold: Thank you very much for taking the question. I was wondering if you could give us your thoughts on your exposure to the U.S. federal government. Basically, how big is it typically as a percent of your revenue? And how are you thinking about the trend given all the noise we hear out of Washington around budget cuts and spending cuts?\nYvonne McGill: So Simon, I'll take a pass at that. We do business in 170-plus countries around the world. Obviously, our largest country is the United States, and we do business with the federal government. But I can't really parse out exactly what you're asking for. We're certainly going to lean into all opportunities that are ahead of us and continue to be successful in that space. I don't know...\nJeff Clarke: No, I would add to what Yvonne said. We've had numerous times in our history where a country or a particular segment demand was suppressed for various reasons. We've been able to navigate the cycles, I think, pretty successfully. Our underlying belief is United States government will need technology. AI plays a pretty significant role in our nation. And I think the demand will materialize. We'll get through whatever is happening today. And we have a broad business to be able to do that. Whether it's PC, servers, storage, AI solutions, our services making it up in other parts of the world, other parts of the United States, we've again proven we've done that consistently, and we'll do so here.\nYvonne McGill: We can help drive efficiencies in every environment. So excited about the opportunity ahead.\nSimon Leopold: Thanks, Yvonne.\nOperator: And our next question will come from Aaron Rakers with Wells Fargo.\nAaron Rakers: Yes, thanks for taking the question. Just building on Erik's fire question, I'm curious, Jeff, as we really start to see the materialization of the Blackwell product cycle through your AI backlog, I'm curious, when you're engaged in like rack scale configurations, how would you compare the margin profile of those relative to the AI business on, let's say, the Hopper product cycle? And can you talk a little bit about the levers that you see to improve that margin as we move through 2025? Thank you.\nJeff Clarke: Sure, Aaron. I think I mentioned in the last call that the Blackwell margins were lower than the Hopper margins and remains so today. We're still early. The deals are very large upfront. There's more competitors, so it's a more competitive landscape. And I'll probably sound a little redundant with the last answer with Erik. Look, this is a system design and architecture work. There's an ability to really distinguish our engineering and value add in that step, which is an opportunity for us to extract value and opportunity for us to reduce cost. These aren't reference designs or as we would affectionately call in the engineering community, they're not cookie-cutter designs. We're designing a unique rack, a unique power distribution unit. Our cooling, our manifold, the cold plate, the ability to engineer that and to drive that through the scale of our supply chain are opportunities for us, helping our customers attach with our networking with our storage or opportunities. And while still small, it remains an opportunity because every large cluster, and for that matter, every AI workload requires data to fulfill its need. Services, installation, deployment, those are value-add opportunities for us that we continue to build on, and then obviously, the ability to be a time-to-market advantage. Those are areas that we continue to focus on. They drive differentiation. I think Yvonne and I have been consistent for the better part of the year that AI servers are margin rate-dilutive. They are margin dollar-accretive. They are operating margin-positive. They are profitable. And what's really interesting for us, if we take the work that we're doing in these large clusters, it really scales nicely to the enterprise. It allows us to really take the efficiencies and learnings from what we're doing with the largest clusters in the world and build optimized solutions for very specific domain-specific AI use cases. And our experience to date is the AI margins in enterprise are better, and I think they'll continue to be, and that's what we're focusing on.\nAaron Rakers: Okay, thanks, Eric.\nOperator: And our next question will come from Michael Ng with Goldman Sachs.\nMichael Ng: Hi good afternoon. Thank you for the question. I just have one on the ISG margin outlook of flat year-over-year for the upcoming year. It's a great outlook, particularly considering AI server revenues growing 50%. So can you talk a little bit about the expectations for margins for some of the components, traditional servers, storage AI servers? I'm just trying to understand the ability to keep ISG margins flat despite presumably the dilutive effect from the AI server margins. Thank you.\nJeff Clarke: I think, Mike, maybe the way to look at this is the, first and foremost, as we think about holding ISG margins flat, I love the way that you asked the question, we're going to do that by growing at least $15 billion in AI servers. I know your question is how we're going to do that. But for us, that's a very important mark that we're going to be able to meet that operating range that we've committed in our long-term framework and we're going to grow at a minimum of $15 billion in AI servers. And we're going to do that by what we've done in traditional servers and what we've done in storage. The storage leverage that Yvonne talked about earlier is front and center. When we grow the storage business and we control our expenses, scale matters, the operating margins improve. When we pivot to Dell IP storage, which we have done, our margins improve. The margins of our own IP are vastly superior than third-party IP. We've been doing that for some time. We made mention, I think, in our remarks about PowerStore. It's grown four consecutive quarters on the van line, the last three, double-digit; in the largest space in the external storage marketplace, midrange. It has differentiated features. We're going to continue to leverage our IP storage. We're building out the customer base with our direct sales force and our partner-first channel program. We're continuing to invest in the innovation and differentiation in our storage. And with our coverage, the broadest coverage in our industry, and the deepest specialty capability, we're going to continue to grow the customer base, which I might add, the PowerFlex customer base grew, the PowerScale customer base grew, the PowerStore customer base grew. And then lastly, we're looking to attach more storage to every AI opportunity that we have. Our traditional storage business continues to grow, 5 consecutive quarters of year-over-year growth. We've seen an expansion of ERUs as we see the consolidation continuing to occur in the data center to free up more floor space and become more power efficiency. We see our 16G and 17G products ramping nicely. And those are driving, again, more cores, more memory, more SSDs, more margin dollars per server that we put in the marketplace. That's how we're doing it. If I missed anything, Yvonne...\nYvonne McGill: Thank you. I think you hit it.\nOperator: And the next question will come from Ben Reitzes with Melius Research.\nBen Reitzes: Hey, thanks guys. Appreciate it. Could you be more specific on the guidance for this year with regard to tariffs? What are you factoring in for China in particular? Is it the 10% or today, this morning's 20%? And then are you instituting any remedies? And what are your thoughts about remedies like raising prices, moving stuff around? And how are you adjusting for that? Thanks a lot.\nJeff Clarke: Well, Ben, maybe I'll take a swing at it, and Yvonne can clean up on this one here. Whatever was announced this morning, which we know things were announced this morning is not on what we just said. That said, this is a pretty darn dynamic environment as represented what we heard this morning. It's fluid. We built an industry-leading supply chain that's globally diverse, agile, resilient that helps us minimize the impacts of these trade regulations, tariffs to our customers and shareholders. We've been monitoring this for some time. We've taken our digital supply chain, our digital twins actually using some AI modelling to look at every possible scenario that you might imagine of this country, that country restrictions here, awaits here. To help us understand how we optimize our network and how we that in the least amount of time at the speed of Dell. And whatever tariff we cannot mitigate, we view that as an input cost. And as our input costs go up, it may require us to adjust prices. That's what we've done in the past. I can't imagine we're going to do anything differently. Yvonne, if I missed something.\nYvonne McGill: No, I think you hit it. We'll take into account the input costs and price accordingly in this competitive environment that we're operating in such, continue onwards.\nOperator: And we'll take a question from David Vogt with UBS.\nDavid Vogt: Great, thanks guys. Maybe just on ISG xAI. So if we take -- maybe Yvonne for you, if we take your kind of outlook at face value, it points to incredibly strong growth in traditional server and storage. I know you just posted relatively good numbers. But what are you seeing in the marketplace vis-\u00e0-vis your traction versus your competitors? And kind of how do we think about getting to high single-digit growth in that part of the business given sort of the macro environment that we just talked about? Thanks.\nYvonne McGill: So David, we are expecting to have growth across the full portfolio in ISG. We -- as I talked about, we're expecting to have storage growing in the low single digits, server higher than that and then the $15 billion at least in AI servers. So I guess we'll continue -- there's lots of opportunities out there where there continues to be multiples of what we've already seen. The pipeline continues to grow. I don't know, Jeff, what you'd add to that around ISG. I feel confident and comfortable in the guide we've laid out for the full year and the opportunity that it has.\nJeff Clarke: Yes. Maybe a little bit of color. Let's take storage as an example. You're seeing a pivot to our Dell IP storage. Modern workloads demand an architecture that can be flexible, sufficient, optimizes performance. And we think a disaggregated architecture is the right answer with the modern workloads. That presents a headwind of our large position that we have in HCI, which will become smaller. But we're going to overcome that by taking share in our Dell IP storage portfolio across the board in the midrange. Our software to find project like -- or product like PowerFlex and then PowerScale in the infrastructure space. So I mean, I think that gives you a sense of a headwind that may exist there that on the surface may not be obvious, but it's certainly something that we're challenged as we pivot towards our storage, which is more profitable.\nYvonne McGill: I was going to say it's more profitable to do our own.\nJeff Clarke: There's revenue that we'll see go away at a lower margin rate, the HCI business. We have a secular decline in the high-end space where we're the market leader with our PowerMax product. So we're going to overcome those and drive the growth that Yvonne mentioned. And then traditional servers, I don't know if you've seen some of the recent market forecast. It's low single-digit growth. We're going to take share. We've now had five consecutive quarters of year-over-year growth that's coming off 8 quarters of a consolidation period or - of a consumption period, I should say. And we think this consolidation continues. But the consolidation drives fewer units. Those units are actually higher in TRU because of the more cores, memory and SSDs I mentioned earlier. And we continue to see that driving our traditional server business. I hope that context helped a little bit.\nDavid Vogt : Great. Thanks, Jeff. Thanks a lot.\nJeff Clarke: Thanks, David.\nOperator: And moving on to Amit Daryanani with Evercore.\nAmit Daryanani: Thanks a lot. I guess I have a question on free cash flow. In fiscal '25, it looks like your free cash flow is down a couple of billion dollars versus '24. Can you just talk about what's driving this contraction in free cash flow? And maybe, Yvonne, you can help us kind of understand how do we think about free cash flow expectations as we head into fiscal '26? What are sort of puts and takes around it? It would be really helpful to kind of get the context, at least for fiscal '26, what's going on? And then, Jeff, if I could just have you talk a little bit more about -- well, I think it's really impressive that your folks are showing operating leverage in fiscal '26 despite the mix being negative. I think the fear everyone seems to have is, is this really durable or is it really driven by one-off headcount reduction or something else. So just maybe you can touch on the durability of that would be great as well?\nJeff Clarke: You go to, Tyler, then I'll come in on the durability of which structural changes we are making up in.\nTyler Johnson: Amit, look, I think -- as I was sitting here last year, I definitely thought cash flow was going to be a little bit stronger. If you look at what played out, one, we didn't see the growth in CSG that we were expecting. And as you know that throw off really good cash. And then two, we invested a lot in our AI business through inventory. And so you can see that our inventory has gone up, and that had a big impact to CCC. Now if I look where I am today and I think about FY '26, I would say I've got a few things working in my favor. So one, we're at a CCC level where historically, we've always shown improvement from here. And that will throw off good cash. We expect good CSG this year, and that will throw off good cash. And if I think about the growth in the P&L, that will throw off good cash. So look, I think we feel pretty good about cash. I do expect it to be greater than 1x and so yes.\nJeff Clarke: And then to your second question, I probably won't give you as much detail as you like because we think some of the changes we're making are very proprietary and differentiating us in the market, the fact that we can grow while reducing our operating expenditures, but Yvonne hit on it, Amit: simplify, standardize, automate. We are building a new company. We are what we call modernizing it. We've made reference to modernization. If you prefer, we're future-proofing the company and we're systematically going throughout all of the value streams in the company. And we are modernizing the work, the workflows, taking steps out of processes, taking out manual touches, simplifying and standardizing those processes, applying automation in the very technologies that we've talked about that get us excited in this marketplace, which is why we believe this AI thing makes its way to enterprise, we are deploying AI in the enterprise. The broad categories of use cases are industry-known, whether that's content creation and management, support assistance, natural language search, design and data creation, cogeneration or document automation. Those are broad enterprise use cases. We are deploying those types of technologies inside our company and seeing tremendous efficiency from that and it is durable. It's not a one- timer.\nYvonne McGill: What's so exciting as we're making all these changes, we're making investments. But we're driving all this efficiency to enable that. So the net, what you're seeing us guide to is a lower spend, but it's because we're driving all of these efficiencies will enable us to invest OP spending.\nJeff Clarke: Well, I think that's very important. I think I mentioned it in the remarks comment that we are reducing the cost. And we've built, if you will, the ability to invest more in our innovation engines, more in our areas where we drive distinct advantages. Our sales force, we've invested in our sales force over the past year, we've invested in services, we've invested in the supply chain while reducing our cost.\nYvonne McGill: And it's just the beginning. Thanks Amit.\nOperator: And the next question will come from Matt Niknam with Deutsche Bank. Please go ahead.\nMatt Niknam: Hi, thanks so much for taking my question. My question is on CSG. I can ask about a different segment. The guidance implies an acceleration over the course of the year. And I'm just wondering what sort of visibility or confidence level you have there that this long-awaited PC refresh will finally materialize. And I ask that in context of a relative slowdown that was referenced in January?\nJeff Clarke: Yes. Matt, maybe this will shed some optimism on why we believe that this refresh that we've talked about is in the making. I mean, clearly, we've talked about there's 1.5 billion or so PCs in the installed base. We'll say half of them are 4 years or older. It's got to flip 360 million PCs turned 4 years old that were bought in 2021 this year. Those are normally flags for opportunity for refresh, but probably the more compelling reasons, and I think there are two. We're 9 months away from the Windows 10 end of life. There's over 500 million PCs running today that can't -- running Windows 10 that can't run Windows 11. There's more than 200 million PCs today running Windows 10 that can run Windows 11. Those are prime targets for upgrades. It's just a large pool of old machines running an older version of the operating system that could be upgraded. If you were to reflect on where we were with the Windows 7 end of life compared to where we are today, let's just say we have a long way to go in the next 9 months to catch up and be ready for the end of life. We made reference that SMB for us had strength. That's always an indicator that things are beginning to move. One of the countries that really show a traditional or historical perspective that the refresh is underway is Japan. If you look at the dynamics in the Japan marketplace, it is clearly moving through refresh as it will get done towards the end of October. And then probably the last thing and the most exciting thing and what is actually driving some of the - I think, reticence to refresh right now is AI PCs. And the number of new AI PCs that are coming out in the first half of the year, we clearly just launched a bunch of Lunar Lake-based notebooks in January. Suffice to say, there's more coming. We've announced AMD AI PCs. Customers are going to want to look under the hood at each of those and then make a decision that will future-proof their decision of what is the right correct AI PC for them because they'll have the asset for at least 4 years. All of that makes us feel more confident that the refresh is coming, albeit delayed, slower than any that I've encountered in my career. But all of the data suggests it's there, it's coming, it's coming at a good rate and probably extends. Does that help?\nMatt Niknam: It did. Thanks.\nJeff Clarke: Thanks, Matt.\nMatt Niknam: You are welcome.\nOperator: And the next question will come from Ananda Baruah with Loop Capital.\nAnanda Baruah: Yes, good afternoon guys. Thanks for taking the question. Really appreciate it. One for me, maybe two parts, but related. Could you talk to, Jeff, how you guys are thinking about the server refresh durability? I believe after last call, you talked about part of the current catalyst is folks sort of refreshing older PCs for space and power savings in some to prepare for GenAI. And this is ahead of processor refreshes, so I guess sort of the context of durability of the traditional server growth you see going on now. And then just the sort of add-on to that is you had mentioned focusing -- or targeting to increase attach -- store attach to your GenAI servers. Would just love what you're thinking about there. And what are the mechanics of getting that taken care of over time? That's it for me. Thanks, guys.\nJeff Clarke: Sure. Let me try the server one again. As I mentioned, we're 5 quarters now of year-over-year growth that's coming off an 8-quarter digestion period. In our guide and what we're trying to articulate is that continues for another 4 quarters. So 5 quarters becomes 9 quarters of growth, tempering a little bit. Still driven by the same dynamics that you so well said is freeing up floor space and driving energy efficiency and cooling efficiency. The consolidation occurs, as you look at the installed base, and we have -- just Dell has a very large installed base of 13G and 14G servers all ripe to be replaced with the new 16G server and -- or 17G server. Those conversion rates are roughly a 3 to 4 of the old servers can be, if you will, replaced by a single 16G server, and 6 to 7 of the old servers can be replaced by a single 7G server. Why? Because they have more cores, they're more memory, more storage, they're more energy-efficient. And again, that continues, we believe, throughout the fiscal '26, calendar '25. We've seen no signs that is going to go away from us in that period of time. If you flip over to your other question, again, the fundamental premises, AI needs data. It devours data. You got to feed the beast. The feeding of that beast, if you will, has to be closer to where the computational capability is. So hot and warm storage, the notion of parallel file systems, unstructured file systems, data management tools that help find data and help data be ingested are the opportunities. We have the leading platform for unstructured data. We continue to make it better with the F910 and F710 that I mentioned earlier. Nearly a year ago, we talked about a parallel file system that we are building, Project Lightning, we referred to it. So we're coming to the marketplace with a AI-driven parallel file system. And our Dell data lake house allows us to help customers prepare their information, manage their information and just their information. Our sales force is incented to attach storage with AI opportunities. They will continue to be incented and we inspect that, and we continue to see progress in that area.\nAnanda Baruah: Okay, thanks.\nOperator: And our next question will come from Samik Chatterjee with JPMorgan. Again, Samik Chatterjee, your line is open. Please go ahead with your questions. Perhaps you place this on mute.\nSamik Chatterjee: Hi, hopefully you can hear me now. Jeff, I just wanted to go back to some of your prepared remarks and -- about the $15 billion of AI server revenue that you were highlighting that you at least expect to grow to that level. Just wondering, how much of that is gated by supply, particularly versus the visibility into supply that you're getting? And how much of that commentary around sort of at least growing there is a supply dynamic versus a demand dynamic? And should we be expecting more sort of linear growth for the quarter as we think about the -- with visibility on supply? Thank you.\nJeff Clarke: Well, I think clearly, Hopper supply is available today. I believe there is references yesterday that Blackwell is in production and ramping. We're open for business and taking orders. The message that I really wanted to drive in our remarks is on day 27 of the fiscal year, we're trying to communicate that we are at least $15 billion in AI shipments. Our 5-quarter pipeline continues to grow. It's several multiples of our backlog. We are going to pursue every opportunity with the CSPs and in enterprise. These large-scale systems are accelerating and getting bigger. Models are quickly moving to reasoning models, which consume and require more computational capability, i.e., more computers. And the use cases continue to get clearer for enterprise to drive the return on investments they want to see to actually use AI more broadly. Algorithm innovation continues to accelerate. Again, these reasoning models are -- will consume more computational capability. They're moving to be multimodal, which even consumes more kind of like where this is going. We're optimistic. I don't see supply as an issue. Clearly, these are about building the right architecture. There's a customer preparation or customer readiness component of this, new data centers getting powered, getting water, getting cooling. There's other materials beyond the GPU, getting the rack, getting the cold plates, getting the CDUs, the PDUs, all of that is what we orchestrate. We have line of sight that is at least $15 billion. We'll continue to update as that might change. And we're all in. I don't know what else I can tell you. I hope that helped.\nPaul Frantz: Thanks a lot, Samik. Justin, we'll take one more question, please, and then we'll hand it over to Jeff for a close.\nOperator: Our final question will come from Asiya Merchant with Citigroup.\nAsiya Merchant: Great, thank you for squeezing me in here. Jeff, if I can just ask about your pipeline and the backlog itself, I mean to the extent that you see enterprises and sovereigns in that makes -- how has that changed, say, relative to a quarter ago and how you see that progressing as you ramp up or as you flush through your pipeline and your backlog? Thank you.\nJeff Clarke: Well, it's maybe slightly repetitive to the previous question. The 5-quarter pipeline grew quarter-over-quarter and has grown every quarter since the 9680 was launched. The CSP component grew, the enterprise component grew, the enterprise customer base grew, sectors like education, technology, manufacturing and government grew. Our buyer base in AI continues to grow, what we shipped in Q4. The revenue in Q4 was up. The number of new buyers was up. We're well over several -- a couple of thousand of unique customers. So it has a healthy mix of enterprise. It clearly has a healthy mix of CSPs. It continues to grow to this notion of several multiples. It's with the technologies that are out and available today, and we're excited to see that. And quite honestly, I can't remember the second half of your question. So if you'll refresh my memory, I will answer it.\nAsiya Merchant: No, that's good. And then just to the extent that you see your attach with those enterprises, how much of that is really factored into your fiscal '26 guide?\nJeff Clarke: To the best of our ability, we factor in the attach of services, our professional services, our deployment services, our installation services, the ability to sell networking and network installation, the ability to sell storage. It's an all-inclusive number when we look at that at least $15 billion of AI servers in the marketplace -- shipped in the marketplace.\nPaul Frantz: Asiya, thank you, and handing it over to Jeff for our close.\nJeff Clarke: Sure. Thanks, everybody. I hope you can tell FY '25 was a strong year. We delivered 8% revenue and 10% EPS growth with $3.9 billion in capital returned to shareholders. Our AI business grew to $10 billion while also improving ISG margins year-over-year. In FY '26, we expect to grow revenue and EPS in excess of our long-term value framework. We expect our AI business will grow to at least $15 billion given our robust opportunity pipeline, our engineering, our services and financing advantages. This AI business drives incremental operating profit and is EPS-accretive. We'll continue to modernize the company, reducing operating expenses as we grow, driving further leverage in the P&L. We remain committed to our capital allocation framework, where we've announced an 18% increase in our annual dividend, and our share repurchase authorization increased by $10 billion. We're excited for the year ahead. Thanks for your time today.\nOperator: Thank you. This concludes today's conference call. We appreciate your participation. You may disconnect at this time.\n\n## AAPL Earnings Call: 2025-01-30 17:00:00\n\nSuhasini Chandramouli: Good afternoon, and welcome to the Apple Q1 Fiscal Year 2025 Earnings Conference Call. My name is Suhasini Chandramouli, Director of Investor Relations. Today's call is being recorded. Speaking first today are Apple CEO, Tim Cook, and he will be followed by CFO, Kevan Parekh. After that, we'll open the call to questions from analysts. Please note that some of the information you'll hear during our discussion today will consist of forward-looking statements, including, without limitation, those regarding revenue, gross margin, operating expenses, other income and expense, taxes, capital allocation, and future business outlook, including the potential impact of macroeconomic conditions on the company's business and results of operations. These statements involve risks and uncertainties that may cause actual results or trends to differ materially from our forecast. For more information, please refer to the risk factors discussed in Apple's most recently filed annual report on Form 10-K and the Form 8-K filed with the SEC today along with the associated press release. Apple assumes no obligation to update any forward-looking statements, which speak only as of the date they are made. I'd now like to turn the call over to Tim for introductory remarks.\nTim Cook: Thank you, Suhasini. Good afternoon, everyone, and thanks for joining the call. Before I talk about our results I'd like to take a moment to acknowledge the devastating wildfires that impacted the Los Angeles area this month. From our retail teams to Apple TV+, Apple Music, Fitness Plus, Beats and more LA is home to many of our team members. Our thoughts are with everyone who is beginning the road to recovery. For our part, we are contributing to the relief efforts and we will continue to support our teams and the local community. Now turning to the quarter. Today, Apple is reporting revenue of $124.3 billion for the December quarter, up 4% from a year ago, and an all-time record. EPS also set an all-time record of $2.40, 10% higher year-over-year. We achieved all-time revenue records across the majority of the countries and regions we track, including the Americas, Europe, Japan, and the rest of Asia Pacific. We also continue to see momentum in emerging markets, setting all-time revenue records in a number of markets, including Latin America, the Middle East, and South Asia, among others. In services, we achieved an all-time revenue record, and in the past year, we've seen nearly $100 billion in revenue from our services business. I'm also pleased to announce that we reached a new record for our installed base with over 2.35 billion active devices. In October, we released the first set of Apple Intelligence features in U.S. English for iPhone, iPad, and Mac, and we rolled out more features and expanded to more countries in December. Now users can discover the benefits of these new features in the things they do every day. They can use writing tools to help find just the right words, create fun and unique images with Image Playground and Genmoji, handle daily tasks and seek out information with a more natural and conversational Siri, create movies of their memories with a simple prompt, and touch up their photos with clean up. We introduced visual intelligence with camera control to help users instantly learn about their surroundings. Users can also seamlessly access chat GPT across iOS, iPadOS and MacOS. And we were excited to recently begin our international expansion with Apple Intelligence now available in Australia, Canada, New Zealand, South Africa, and the U.K. We're working hard to take Apple Intelligence even further. In April, we're bringing Apple Intelligence to more languages, including French, German, Italian, Portuguese, Spanish, Japanese, Korean, and simplified Chinese, as well as localized English to Singapore and India. And we'll continue to roll out more features in the future, including an even more capable Siri. Apple Intelligence builds on years of innovations we've made across hardware and software to transform how users experience our products. Apple Intelligence also empowers users by delivering personal context that's relevant to them. And importantly, Apple Intelligence is a breakthrough for privacy and AI with innovations like Private Cloud Compute, which extends the industry-leading security and privacy of Apple devices into the cloud. Apple Intelligence opens up an exciting new frontier and is already elevating experiences across iPhone, iPad, and Mac. We're going to keep investing in innovation and in transformative tools that help users in their everyday lives. Let me now turn to our results for the quarter, starting with iPhone. iPhone revenue came in at $69.1 billion, reaching all-time iPhone revenue records in dozens of markets and regions. Our iPhone 16 lineup takes the smartphone experience to the next level in so many ways, and Apple Intelligence is one of many reasons why customers are excited. With the A18 powered iPhone 16 and iPhone 16 Plus, users are getting a big boost in battery life and incredible camera experiences with camera control. Our amazingly powerful iPhone 16 Pro models go even further with larger-than-ever displays and a pro camera system so advanced it can turn moments into masterpieces. In Mac, revenue was $9 billion for the December quarter, 16% higher year-over-year, driven by significant excitement around the world for our latest Mac lineup. The Mac is more than just a powerful tool. It's a launchpad to enable users to bring their best ideas and boldest creations to life. And there are so many reasons to choose Mac, from the breathtaking performance of the M4 family of chips to the groundbreaking and growing capabilities of Apple Intelligence. Every product in the Mac lineup offers something extraordinary, whether that's the super portable MacBook Air, the powerhouse MacBook Pro, the world's best all-in-one iMac, or the small wonder that is the Mac Mini, which is not only stunningly capable, but is our first carbon neutral Mac. All of this is enabled by the unparalleled power of Apple Silicon. iPad revenue was $8.1 billion, up 15% from a year ago, driven by strong interest for our latest products. We love hearing from customers, who are discovering for the first time the versatility of iPad from the ultra-portal iPad Mini, built from the ground up for Apple intelligence, to the powerful M4 iPad Pro in a stunningly thin and light design. iPad is there for our users whenever they need it and wherever they go and we are pleased to see so much excitement and enthusiasm for our lineup. Wearables home and accessories revenue came in at $11.7 billion. With its most advanced display yet and a thinner more comfortable design, the all-new Apple Watch Series 10 is the perfect companion to help users pursue their health and fitness goals this year. From the powerful Vitals app to more customizable activity rings, users have an ever-increasing set of innovative health tools at their fingertips and watchOS 11. Health innovation has long been a focus for us, and we're committed to continuing to advance this work, because we know how much it matters to our users. We've introduced new hearing health features on AirPods Pro 2, and new sleep apnea notifications on Apple Watch are also helping users learn of a potentially serious condition that's thought to affect up to a billion people worldwide. During the quarter, we also brought Apple Vision Pro to even more countries, enabling more customers to discover the magic of spatial computing. Users are enjoying incredible immersive entertainment experiences and powerful new features and enhancements to Mac virtual display. Vision Pro is also supercharging the creative process and the incredibly talented director John M. Chu recently shared how its extraordinary capabilities helped him bring the movie Wicked to life. Turning to services, we set an all-time revenue record of $26.3 billion for the December quarter, growing 14% from a year ago. We set all-time records in the Americas, Europe, and rest of Asia-Pacific, and a December quarter record in Japan. Five years since launch, Apple TV+ continues to be home to incredible storytelling that viewers love. There's nothing quite like the anticipation that comes when a fan favorite returns, and we were thrilled to debut the second season of Severance earlier this month. We have so much in store for our subscribers this year with new shows like The Studio and Your Friends and Neighbors. And we can't wait for the premiere of Formula 1 starring Brad Pitt on June 27, which will take viewers inside the sport in a truly unprecedented way. We're excited that Apple TV+ continues to draw attention and accolades. To-date, Apple TV+ productions have earned more than 2,500 nominations and 538 wins. During the quarter, we were also excited to launch a new Find My Service that can help our users when they lose their luggage. For the first time, if you put an air tag in your suitcase, you'll be able to share its location information with many major airlines, so they can quickly track down your bags if they get lost. Turning to retail, our teams went above and beyond to help customers find the perfect gift throughout the holiday season. We also celebrated openings of new stores in China, Spain, and the U.S. and we were excited to announce plans to connect with even more customers this year by adding a fifth store in the UAE and bringing our online store to Saudi Arabia this summer. We can't wait to welcome customers to the first of several flagship store locations in Saudi Arabia that were opening beginning in 2026. I just had the chance to visit both countries last month, and I had a great time meeting with customers and team members. There's an incredible energy and passion for technology in these growing markets. Every day, I get deeply moving notes about the many ways our technology is enriching our users' lives. I recently got a note from a customer who put his watch on his father's wrist when he feared something was wrong with him. The watch alerted them that the father was an AFib and they were able to get him to the hospital for potentially life-saving treatment. Another user put his new watch on for the first time and within 15 minutes was notified of a low heart rate that led to a necessary pacemaker. And there are so many touching notes around the profound impact of our new hearing health feature like a recent user who told me it had changed her life, allowing her to take part in conversations with her children and grandchildren. These are the kind of stories that remind us of how profoundly important our work is, and it drives us to innovate each and every day. At Apple, the future is full of promise and potential. We're always searching across a world of possibilities, finding those places where we can do the most good and putting all of our energy and ingenuity into making something special. With that, I'll turn it over to Kevin.\nKevan Parekh: Thanks Tim, and good afternoon everyone. I'm going to cover the results for the first quarter of our fiscal year. We are very pleased to report an all-time high for revenue with December quarter revenue of $124.3 billion, up 4% year-over-year. We achieved all-time revenue records in the Americas, Europe, Japan, and rest of Asia Pacific and grew in the vast majority of markets we track. Products revenue was $98 billion, up 2% year-over-year, driven by growth from iPad and Mac. Thanks to our incredible customer satisfaction and strong loyalty, our installed base of active devices reached an all-time high across all products and geographic segments and is now over 2.35 billion active devices. Services revenue reached an all-time record of $26.3 billion, up 14% year-over-year. We grew in every geographic segment and achieved all-time records in both developed and emerging markets. Company gross margin was 46.9% at the high-end of our guidance range and up 70 basis points sequentially, primarily driven by favorable mix. Products gross margin was 39.3%, up 300 basis points sequentially, primarily driven by favorable mix and leverage. Services gross margin was 75%, up 100 basis points sequentially, primarily driven by mix. Operating expenses of $15.4 billion landed at the midpoint of our guidance range and up 7% year-over-year. This strong business performance resulted in all-time records for both net income at $36.3 billion and diluted earnings per share of $2.40, up 10% year-over-year. Operating cash flow was also strong at $29.9 billion, which included the impact of the $11.9 billion we paid during the quarter in connection with the state aid decision. Now, I'm going to provide some more details for each of our revenue categories. iPhone revenue was $69.1 billion, roughly flat to the prior year. We grew in the majority of markets we track and reached all-time revenue records in several developed markets, including Canada, Western Europe, and Japan and in emerging markets like Latin America, the Middle East, and South Asia. The iPhone Active installed base grew to an all-time high in total in an average geographic segment. We also set an all-time record for upgraders. According to a recent survey from Kantar during the December quarter, iPhone was a top-selling model in the U.S., Urban China, India, the U.K., France, Australia, and Japan. We continue to see high levels of customer satisfaction in the U.S. at 96% as measured by 451 research. Mac generated $9 billion in revenue, up 16% year-over-year. We saw strength across our lineup from the new Mac Mini to the latest MacBook Air and MacBook Pro models. This incredible performance was broad-based with double-digit growth in every geographic segment. With our latest advances in Apple Silicon and our fastest neural engine ever, customers are able to take advantage of the full capabilities of AI and Mac. The Mac installed base reached an all-time high and we saw a double-digit growth for both upgraders and customers new to the Mac. Additionally, customer satisfaction in the U.S. was recently measured at 94%. iPad revenue was $8.1 billion, up 15% year-over-year, driven by the new iPad Mini and latest iPad Air. The iPad installed base reached another all-time high, and over half of the customers who purchased an iPad during the quarter were new to the product. Customer satisfaction was at 96% in the U.S. based on the latest reports from 451 Research. Wearable's home and accessories revenue was $11.7 billion, down 2% year-over-year. Customers are excited about the new AirPods 4 and the latest hearing health features in AirPods Pro 2. On watch, although we face a difficult compare against the watch Ultra 2 launch last year, the Apple Watch installed base reached a new all-time high, with over half of customers purchasing an Apple Watch during the quarter being new to the product. Customer satisfaction for watch in the U.S. was reported at 94%. Our services revenue reached an all-time high of $26.3 billion, up 14% year-over-year. Services continues to see strong momentum, and the growth of our installed base of active devices gives us great opportunities for the future. We also see increased customer engagement with our services offerings. Both transacting and paid accounts reached new all-time highs, with paid accounts growing double-digits year-over-year. Paid subscriptions also grew double-digits. We have well over 1 billion paid subscriptions across the services on our platform. We remain focused on improving the breadth and quality of our services offerings, from new games on Apple Arcade to exciting new programming on Fitness Plus, and the continued expansion of features like Tap to Pay, now live in 20 markets. Turning to enterprise, we have seen businesses continue to expand their deployments of our products and services. Deutsche Bank launched its Mac as Choice program for the developers and also issued the latest MacBook Air as a standard computer for their entire mortgage lending division. And we're excited to see leading enterprises such as SAP leverage Apple Intelligence in the U.S., with features like writing tools, summarize, and priority notifications to enhance both their employee and customer experiences. We also see strong demand in our emerging markets. For example, Zomato, a leading food ordering and delivery company in India, has deployed 1,000 of Macs across their workforce to foster innovation. In Vision Pro continues to see more use cases in enterprise, with Cisco's new spatial meetings delivering a fully immersive video conferencing experience for remote collaboration and learning. Let me quickly summarize our cash position and capital return program. We ended the quarter with $141 billion in cash and marketable securities. We repaid $1 billion in maturing debt and decreased commercial paper by $8 billion, resulting in $97 billion in total debt. Therefore, net cash at the end of the quarter was $45 billion. During the quarter, we returned over $30 billion to shareholders. This included $3.9 billion in dividends and equivalents and $23.3 billion through open market repurchases of 100 million Apple shares. As usual, we will provide an update to our capital return program when we report results for the March quarter. As we move ahead into the March quarter, I'd like to review our outlook which includes the types of forward-looking information that Suhasini referred to at the beginning of the call. The color we're providing today assumes that the macroeconomic outlook doesn't worsen from what we're projecting today for the current quarter. As the dollar is strengthened significantly, we expect foreign exchange to be a headwind and to have a negative impact on revenue of about 2.5 percentage points on a year-over-year basis. Despite that headwind, we expect our March quarter total company revenue to grow low to mid-single-digits year-over-year. We expect services revenue to grow low-double-digits year-over-year. When you remove the negative impact of the foreign exchange headwinds I described earlier, the year-over-year growth rate would be comparable to that of the December quarter. We expect gross margin to be between 46.5% and 47.5%. We expect operating expenses to be between $15.1 billion and $15.3 billion. We expect OI&E to be around negative $300 million, excluding any potential impact from the mark-to-market of minority investments, and our tax rate to be around 16%. Finally, today our Board of Directors has declared a cash dividend of $0.25 per share of common stock payable on February 13, 2025, to shareholders of record as of February 10, 2025. With that, let's open to call the questions.\nSuhasini Chandramouli: Thank you, Kevin. We ask that you limit yourself to two questions. Operator, may we have the first question please?\nOperator: Certainly, we will go ahead and take our first question from Erik Woodring with Morgan Stanley. Please go ahead.\nErik Woodring: Great guys, Thanks so much for taking my questions. Tim, in your prepared remarks, you had noted that iPhone 16 models are selling better in markets where Apple Intelligence is available? And I'm just wondering if you could double-click on that comment a bit and share any other details you believe could better help us understand how Apple Intelligence is really impacting iPhone demand and/or what features you find that users are using most often already? And then I just have a quick follow-up. Thank you.\nTim Cook: Yes, Eric. Hi, it's Tim. The -- we did see that the markets where we had rolled out Apple Intelligence, that the year-over-year performance on the iPhone 16 family was stronger than those where Apple Intelligence was not available. In terms of the features that people are using, they're using all of the ones that I'd referenced in my opening comments from writing tools to image playground and Genmoji to visual intelligence and more. And so we see all of those being used. The cleanup is another one that is popular and people love seeing that one demoed in the stores as well. We only had 2, 2.5 weeks or so during the December quarter of the second release of [18.2] (ph) and then only had the U.K. and the other English language countries for the 2.5 weeks. And so we've got just the early indications at the moment, but we were glad\u2026\nErik Woodring: Okay, that's really helpful.\nTim Cook: Yes.\nErik Woodring: Okay, thank you for that, Tim. It's helpful. And then, you know, if we just touch on China, obviously, in the news fairly frequently, if we set aside China Macro, which I understand is still challenging, can you maybe talk about the headwinds that that Apple faces, whether that's, you know, shifting preferences for Western technology brands in favor of domestic vendors, or is this just a function of not necessarily having Apple intelligence available with the iPhone 16, which is, you know, not necessarily helping replacement cycles. Just maybe double clicking on, on what you think and what you're hearing in China as a regard as it relates to the iPhone. Thanks so much.\nTim Cook: Yes, sure. If you look at our greater China revenue for the quarter, we were down 11% year-over-year. And over half of the decline that we experienced was driven by change in channel inventory from the beginning to the end of the quarter. And of course on the Apple intelligence side we have not rolled out in China and as we just talked about we did see better results in the markets that we had rolled out in than markets we hadn't rolled out in. And of course, it's the most competitive market in the world. And so all of those things are true. In terms of the macro situation, there was a fiscal stimulus or subsidy announced in very recently in January that did not affect the December quarter. There were some provincial subsidies in the December quarter, but the national program was announced, I believe, on January 20. And it does cover the categories that we have products in from smartphones to tablets and PCs and smart watches up to a certain, a maximum price point. And so we do see fiscal stimulus occurring and we'll be glad to talk about what that looks like on the next call.\nErik Woodring: Great. Thanks so much, Tim. Good luck.\nTim Cook: Thank you.\nSuhasini Chandramouli: Thank you, Eric. Operator, can we have the next question, please?\nOperator: Our next question is from Ben Reitzes with Melius. Please go ahead.\nBen Reitzes: Hey, guys. Thanks a lot for the question. And, hey, Tim, I wanted to ask you who -- you knew this one was coming, but there's a perception that you're a big beneficiary of lower cost of compute and I was wondering if you could give your worldly perspective here on the DeepSeek situation and if you are going to, if you, if anything's happened to change your views in terms of a tailwind to margins and your ability to execute even due to the potential for cost to come down due to that development and probably what was going to happen anyway. But I'd love your perspective on that and then have a quick follow-up. Thanks.\nTim Cook: Sure. In general, I think innovation that drives efficiency is a good thing. And that's what you see in that model. Our tight integration of silicon and software, I think, will continue to serve us very well. As you know, we do things on the device, and we do things in the private cloud and which mimics from a architectural point of view the -- what happens on the device. And from a CapEx point of view, we've always taken a very prudent and deliberate approach to our expenditure and we continue to leverage a hybrid model, which I think continues to serve us well.\nBen Reitzes: Oh, great. All right. Thanks, Tim. And then, you know, just with regard to, you know, the iPhone trajectory, do you feel like, I guess, what is -- you obviously don't talk about new products and stuff like that, but do you feel that there's a lot of room for form factor innovation in the future? Or do you feel that the current lineup kind of it shows where you're going? I guess without pulling punches wondering if you, you thought you know in terms of the phone innovation if there's a lot more to come and you could see the kind of current market changing a bit over the next two to three years. Thanks.\nTim Cook: I think, Ben, I think there's a lot more to come and I could not feel more optimistic about our product pipeline. So I think there's a lot of innovation left on the smartphone.\nBen Reitzes: Thanks a lot, Tim.\nTim Cook: Yes, thank you.\nSuhasini Chandramouli: Thank you, Ben. Operator, could we have the next question, please?\nOperator: Our next question is from Michael Ng with Goldman Sachs. Please go ahead.\nMichael Ng: Good afternoon. Thank you for the question. I have two as well. First, it was encouraging to hear about the record for iPhone upgraders, which I think is something you haven't said for about a year now. I was wondering if you could talk a little bit about what you would attribute this upgrade strength to? Has Apple Intelligence played a role in helping upgrades in the markets that you've launched in? Thanks.\nTim Cook: Yes, thank you for the question. If you look at iPhone, we did set an all-time record for upgraders, so we've never seen a higher level of upgraders before. The installed base hit a new all-time high as well. And if you look at the 16, compared to the 15 from launch, which occurred, as you know, in September, so this is across now two quarters from September to the end of the December fiscal quarter, the 16 outperformed the 15. And so I think you can conclude from that, that there are compelling reasons to upgrade. And in the markets where we had launched Apple Intelligence, they outperformed the markets that we did not. So lots\u2026\nMichael Ng: Great, thank you, Tim. That's\u2026\nTim Cook: Yes, lots of good color there.\nMichael Ng: Great, thank you, Tim. That's very clear. And then I had one about the iPad Pro and for the thinner version. I was just wondering if you could talk about that thin form factor for the iPad Pro. How did it help iPad sales overall and what did your kind of marketing consumer research tell you about how consumers valued that thin product form factor? Thank you.\nTim Cook: It's a good question. iPad overall grew 15% for the quarter and it was more driven by iPad Air and the entry level iPad than it was the top level iPad. But overall we could not be more pleased with the iPad category growing 15%. It's a great achievement for the quarter. And probably what is most important is that over half of the sales in the December quarter went to customers who were new to the iPad. So that tells us that there's a good amount of customers there to attract.\nMichael Ng: Thank you very much, Tim.\nTim Cook: Yes. Thank you.\nSuhasini Chandramouli: Thanks, Mike. Operator, could we have the next question, please?\nOperator: Our next question is from Amit Daryanani from Evercore. Please go ahead.\nAmit Daryanani: Good afternoon, everyone. I have two as well. Maybe to start with, you folks are seeing some very robust growth trends in emerging markets right now for Apple products? Can you just add a high level, just talk about the durability of growth that you see in emerging markets? And then do you think the summation of these emerging markets are starting to get big enough or perhaps starting to grow fast enough that it can actually offset some of the China headwinds you're going through?\nTim Cook: We have great results in a number of emerging markets. And as you know from past calls, I'm particularly keen on India. India set a December quarter record during the quarter. And we're opening more stores there. We've announced that we're going to open four new stores there. We also, the iPhone was the top selling model in India for the quarter. And it's the second largest smartphone market in the world and the third largest for PCs and tablets and so there's a huge market and we are -- we have very modest share in these markets. And so I think there's lots of upside there. And that's just one of the emerging markets.\nKevan Parekh: Yes, maybe I'll add, Amit, that in emerging markets we're also seeing double-digit growth on the install base, both in total and for the iPhone as well. So that's also an encouraging sign.\nAmit Daryanani: Perfect. Thank you. And then, you know, just a question on gross margins for the March quarter. You folks are guiding gross margin is flattish on a sequential basis. Typically, I think it tends to be guided up a little bit, 50 basis points, so sequentially. Can we just touch on like, what are the offsets of the puts and takes you see here on gross margins? And Kevan, maybe you can just talked about its FX having an outsized impact in your margin profile as well in March?\nKevan Parekh: Yes, Amit, let me take that One. You know, as we mentioned in my remarks, we're guiding to 46.5% to 47.5%. So we think it's, you know, we're very pleased with that level of guidance. As you mentioned, there's always puts and takes. We do think there's going to be some FX headwinds, which we talked about, that's going to affect, you know, our revenue growth as well. You know, it'll have an impact here on the margin, a sequential impact on margins. But we think that's going to be offset by favorable costs and the relative mix of services. We also, as you know, when we move from Q1 to Q2, especially on the product side, because Q1 is such a large quarter for a products business, we do have a loss of leverage. So there are some puts and takes, and I think we feel good about the range. We think it's a very, very strong guide for gross margin.\nSuhasini Chandramouli: Thanks, Amit. Operator, could we get the next question, please?\nOperator: Our next question is from Wamsi Mohan with Bank of America. Please go ahead.\nWamsi Mohan: Yes, thank you so much. Tim, I want to follow-up on your comment about channel inventory in China. I was wondering if you could maybe address more broadly if channel inventory across your different product lines and regions? Do you feel they're elevated or out of range in any other regions? And given the clearing event that kind of happened in China, I guess in the quarter, should we think of a more normal progression quarter-on-quarter into the March quarter in China in particular, and I will follow.\nTim Cook: Yes, I don't want to project sales for the current quarter by region, but if you if you look at the channel inventory and look at iPhone in the aggregate, so on a worldwide basis we're very comfortable with our channel inventory position in the -- in China my point was that our channel inventory reduced from the beginning of the quarter to the end of the quarter, and that was over half of the reduction in the reported results. And so if you look, part of the reason for that is that our sales were a bit higher than we forecasted them to be toward the end of the quarter. And so we ended a little leaner than we had expected to.\nWamsi Mohan: Okay, that's very clear. Thank you.\nTim Cook: Yes, thank you.\nWamsi Mohan: And then maybe as my follow-up, your services growth has been very strong and I know you've kind of been navigating some pretty challenging regulatory burdens on the business globally. So how should investors think about maybe either a top line or margin headwind that let's say you're currently absorbing in your results that could potentially maybe reverse in a more balanced regulatory environment? Thank you so much.\nKevan Parekh: Yes. So I think one, I just wanted to kind of reiterate the fact that, you know, our services business had an all-time record for December quarter of 14%. And that was a one strength that we saw across all geographic segments and also was very broad base across all of our services. So we have, as you know, a very broad services portfolio. And so we do see, you know, good momentum across the board. And as well, we continue to see increasing engagement across the customer base, across all of the service offerings, both transacting and paid accounts. We talked about reaching all-time highs, and we have over now 1 billion paid subscriptions across the services platform.\nSuhasini Chandramouli: All right. Thanks, Wamsi. Operator, could we get the next question, please?\nOperator: Our next question is from Samik Chatterjee with JPMorgan. Please go ahead.\nSamik Chatterjee: Hi. Thanks for taking my questions. I guess for the first one, if I -- I mean, you had a great quarter on Macs and iPads both. And I'm just curious, in terms of if you can help us think about the sustainability of this double-digit growth that you saw in both the product lines, and more interest are also here, we are talking about Apple Intelligence sort of influencing volumes on iPhones, but any thoughts on sort of how -- what does that influence look like in terms of volumes for Macs, for example, where I think there's a lot of conversation on AI PCs, how you're thinking about the impact there? And I have a quick follow-up. Thank you.\nTim Cook: Yes. If you look at Mac, Mac was up 16% and on iPad, we were up 15%. The Mac was driven by the very strong uptake on our new products during the quarter and the continued success of the MacBook Air. And so as you know, we've launched an M4-based MacBook Pro, an iMac and a Mac Mini during the quarter. We believe we've got the best AI PC out there for running workloads. The silicon in the Mac is, and it has been for several years now, designed by us and really designed for these workloads. And so I don't want to project at the category level for the future, but we're incredibly pleased with both the Mac and the iPad for the quarter.\nSamik Chatterjee: Okay. And Tim, I'm going to use your earlier discussion about India as a strong emerging market to sort of ask you about the supply chain planning there in terms of how much of the supply chain planning there that you're doing is more of a reflection of the growth expectations from that market relative to in terms of diversification of the supply chain? And how should we sort of think about that strategy in terms of that particular country? Thank you.\nTim Cook: Yes. If you look at the manufacturing we do there, we do manufacturing both for the domestic market, and we export. And so in -- our business needs a certain economies of scale for it to make sense to manufacture in country. And so that really means that we're going to be both a use for the domestic market and an export market.\nSamik Chatterjee: Great. Thank you.\nTim Cook: Yes, thanks.\nSuhasini Chandramouli: Thank you, Samik. Operator, could we get the next question, please?\nOperator: Our next question is from David Vogt with UBS. Please go ahead.\nDavid Vogt: Great, thanks, guys, for taking my question. So maybe, Tim, this is for you. I'm trying to think about your commentary around Apple Intelligence being sort of a momentum driver for the iPhone business. But when I think about your kind of framework for the March quarter, if I kind of adjust for channel inventory over the last couple of years, kind of, feels like your iPhone revenue for the March quarter is going to be relatively similar to the quarter two years ago and even the quarter last year? So how do we square kind of the momentum versus kind of the iPhone business effectively really kind of unchanged over the last couple of years? And then second, when I think about kind of the gross margin profile of the business, obviously, you've done a great job in taking gross margins up. Where do you think we sit in terms of, on the services side at least, where margins could go? It looks like the 75% margin has been incredibly successful quarter. But just trying to get a sense for where do you think this number could go over the intermediate term? Thank you.\nTim Cook: Yes. If you look at Apple Intelligence, what my point earlier was, that markets where we had rolled out Apple Intelligence during the Q1 period performed better on a year-over-year basis than markets where we had not. And so that gives us -- it's a positive indicator that we were pleased with. There are many compelling reasons to upgrade. And the other thing I would say, that I think I mentioned earlier, is that if you look at it from a launch to the end of the December quarter, and so that goes back to September, the 16 family is outperforming the 15 family. And so I think those are two good data points. Our next round of language rollouts will be in April. And so it will be at the -- in our Q3 quarter. And I'll let Kevan take the gross margin question.\nDavid Vogt: Yes, great.\nKevan Parekh: Hi, David. How are you? So on the Services gross margin, I think maybe just stepping back a second. Services business in general in aggregate is accretive to the overall company margin. And one of the things, as an important reminder, is we've got a very broad services portfolio. And those businesses have very different margin profiles. And so I think, one, it's because of the nature of those businesses and in part also because of the way we account for them. And so one of the big factors that drive the Services gross margins and relative performance of those different businesses within the portfolio. We also have the dynamic of some scale businesses like payment services, iCloud, that are actually growing. And there, when we add incremental users, those end up being accretive to margins as well. And so in general, what we saw in the December quarter was nice momentum across our entire services business that allows us to deliver that 75% margin at the services level. And I think our guidance takes into consideration what we think we're going to land from a company standpoint of 46.5% to 47.5%, which again, we think is a strong guide.\nDavid Vogt: Great, thanks, guys.\nSuhasini Chandramouli: All right, thank you, David. Operator, could we have the next question, please?\nOperator: Our next question is from Krish Sankar with TD Cowen. Please go ahead.\nKrish Sankar: Yes, thanks for taking my question. I also had two of them. One, the first one for Tim. You had very strong Mac growth, 16% year-over-year last quarter. Just wondering how much of that was driven by some of the Mac silicon innovation versus a replacement cycle for Macs?\nTim Cook: I don't know the answer to your question precisely, but I think it is a combination of these products are so compelling, the M4-based products are so compelling, that it's driving both upgrades at the double-digit level and it's driving switchers at a double-digit level. And so we're seeing both come out, and I think it's just because of the compelling products.\nKrish Sankar: Got it. Got it. Thanks for that, Tim. And then a follow-up for Kevan on the gross margin. I want to ask you on the product side. Last quarter, you had 39.3%, which is very strong, similar to a year ago period. I'm kind of curious how much more levels do you have on the product side to improve the gross margin? Or do you think with some of the more new AI-related devices, there's more upside to gross margin from here on the product hardware side?\nKevan Parekh: Yes. Thanks, Krish, for the question. So on the product side, as you mentioned, we had pretty strong sequential improvement, 300 basis points, for the December quarter. That was really driven by, we talked about, favorable mix and leverage. As you know, in Q1, again, it's a launch quarter for many products, and so we tend to benefit from the leverage that we get from that higher volume. I would say, in general, our gross margin on products is driven by a number of factors. One of them is the various product launches that we have. Different products do have different margin profiles. And so that mix does make a difference. And in particular, what we're seeing is, for example, many of our mix is across like phone, for example, we're seeing customers gravitate towards our Pro products because of things like affordability that allows our customers to get into our best products, which have favorable gross margins. So we're continuing to see that trend, that impacted us in the December quarter. As well, I think we're in a favorable commodity environment from a cost standpoint. And so we're benefiting from that as well in the December quarter. And then that's going to be, as we talked about, we're going to have a foreign exchange headwind heading into the March quarter, but we figured that's contemplated in the guidance range that we gave, the 46.5% to 47.5%.\nKrish Sankar: Thanks, Kevan. Thanks, Tim.\nSuhasini Chandramouli: Thank you, Krish. Operator, could we get the next question, please?\nOperator: Our next question is from Richard Kramer with Arete Research. Please go ahead.\nRichard Kramer: Thanks very much. My first question is for Tim. I'd like to ask about what might accelerate the pace of Apple Intelligence adoption. I guess do you see this simply as a question of time i.e., to launch more markets and languages or increase the percentage of installed base devices that can support it? Or is it a question of money, i.e., shifting R&D or marketing spend towards AI? And based on other prior Apple services, do you expect a sort of tipping point where adoption will go mainstream? Thanks.\nTim Cook: I do believe it will go mainstream. I'm getting feedback from people using different features today. And this is -- keep in mind that on the iPhone side of our business, you either have to have an iPhone 15 Pro or iPhone 16 to use Apple Intelligence. And so the -- as that base grows, I think the usage will continue to grow. And I think -- I know from my own personal experience, once you start using the features, you can't imagine not using them anymore. I know I get 100s of e-mails a day, and the summarization function is so important. So I think it's a combination of that. And of course, in April, we roll out a whole series of new languages that we had mentioned, and so the base grows further.\nRichard Kramer: Okay, thank you. And then, Kevan, one of Luca's legacies was really getting Apple to record margin levels and also maintaining very consistent pricing across the product range. But taking the current high levels of profitability as fairly stable, what observations might you share about price sensitivity of users and whether having a wider range of pricing across the products might unlocks potentially further market share gains or boost overall product growth?\nKevan Parekh: Yes, it's a good question. I think one, I don't think we're going to really depart from what served us pretty well to now. I mean we always take it into consideration, looking at short-term -- comparison between the short term and the long term. I think we've had a pretty disciplined pricing strategy, which would serve us pretty well. And I think we're going to continually kind of stick with that as far as I can tell.\nRichard Kramer: Okay, thanks.\nSuhasini Chandramouli: Thank you, Richard. Operator, could we get the next question, please?\nOperator: Our next question is from Atif Malik with Citi. Please go ahead.\nAtif Malik: Hi, thank you for taking my question. How do you guys see the potential tariff impact to your product for consumer demand under Trump 2.0 you guys did find under Trump 1.0?\nTim Cook: We are monitoring the situation and don't have anything more to add than that.\nAtif Malik: Great. And Tim, as a follow-up, there is a lot of discussion on agentic AI, the use of agents. Do you guys see the upgraded series expected in April as something that will, let's say, be the killer application among the suite of features that you have announced in Apple Intelligence?\nTim Cook: I think the killer feature is different for different people. But I think for most, they're going to find that they're going to use many of the features every day. And certainly, one of those is the -- is Siri, and that will be coming over the next several months.\nAtif Malik: Thank you.\nSuhasini Chandramouli: All right. Thank you, Atif. Operator, could we please get the last question?\nOperator: Our last question is from Ben Bollin from Cleveland Research Company. Please go ahead.\nBen Bollin: Good evening, everyone. Thanks for taking the question. Tim, I'm interested in your thoughts and how you would have us think about the average useful life of these devices in the wild. And in particular, curious, if you look at the strength you saw in fiscal \u201821 and how that might support accelerated refresh opportunity into the future?\nTim Cook: Yes. Ben, I think it's different for different types of users. I mean you have very early adopter kind of users that are very quick to jump on the latest technology that upgrade very frequently. And then you have people that are on the entire opposite side of that barbell. And most people are between those two points. And so I do think there were lots of units that are sold during the COVID period of time, and it's a huge opportunity for us as a company to -- for more than one of the product categories.\nBen Bollin: That\u2019s it from me. Thanks, Tim.\nTim Cook: Thank you.\nSuhasini Chandramouli: All right. Thanks, Ben. A replay of today's call will be available for two weeks on Apple Podcasts or as a webcast on apple.com/investor and via telephone. The number for the telephone replay is 866-583-1035. Please enter confirmation code 7398532 followed by the pound sign. These replays will be available by approximately 5 p.m. at Pacific Time today. Members of the press with additional questions can contact Josh Rosenstock at 408-862-1142. And financial analysts can contact me, Suhasini Chandramouli, with additional questions at 408-974-3123. Thanks again for joining us here today.\nOperator: Once again, this does conclude today's conference. We do appreciate your participation.\n\n## NVDA Earnings Call: 2025-02-26 17:00:00\n\nChrista: Good afternoon. My name is Christa, and I will be your conference operator today. At this time, I would like to welcome everyone to NVIDIA Corporation's Fourth Quarter Earnings Call. All lines have been placed on mute to prevent any background noise. After the speakers' remarks, there will be a question and answer session. If you would like to ask a question during this time, simply press star followed by the number one on your telephone keypad. And if you would like to withdraw your question, Thank you. Stewart Stecker. You may begin your conference. Thank you.\nStewart Stecker: Good afternoon, everyone, and welcome to NVIDIA Corporation's conference call for the fourth quarter of fiscal 2025. With me today from NVIDIA Corporation are Jensen Huang, president and chief executive officer, and Colette Kress, executive vice president and chief financial officer. I'd like to remind you that our call is being webcast live on NVIDIA Corporation's Investor website. Webcast will be available for replay until the conference call discuss our financial results, the first quarter of fiscal 2026. The content of today's call is NVIDIA Corporation's property. It can't be reproduced or transcribed without prior written consent. During this call, we may make forward-looking statements based on current expectations, these are subject to a number of significant risks and uncertainties and our actual results may differ materially. A discussion of factors that could affect our future financial results and business, please refer to the disclosure in today's earnings release. Our most recent forms 10-K and 10-Q, and the reports that we may file on form 8-K with the Securities and Exchange Commission. All our statements are made as of today, February 26, 2025, based on information currently available to us. Except as required by law, we assume no obligation to update any such statements. During this call, we will discuss non-GAAP financial measures. Confined and reconciliation of these non-GAAP financial measures GAAP financial measures in our CFO commentary, which is posted on our website. With that, let me turn the call over to Colette.\nColette Kress: Thanks, Stewart. Q4 was another record quarter. Revenue of $39.3 billion was up 12% sequentially and up 78% year on year. And above our outlook, of $37.5 billion. For fiscal 2025, revenue was $130.5 billion. Up 114% in the prior year. Let's start with data center. Data center revenue for fiscal 2025 was $115.2 billion. More than doubling from the prior year. In the fourth quarter, it is in a revenue of $35.6 billion was a record, up 16% sequentially and 93% year on year. As the Blackwell ramp commenced, and Hopper 200 continued to contribute growth, In Q4, Blackwell sales exceeded our expectations. We delivered $11 billion of Blackwell revenue to meet strong demand. This is the fastest product ramp in our company's history. Unprecedented in its speed and scale. Blackwell production is in full gear across multiple configurations, and we are increasing supply quickly. Expanding customer adoption. Our Q4 data center compute revenue jumped 18% sequentially and over 2x year on year. Customers are racing to scale infrastructure to train the next generation of cutting-edge models and unlock the next level of AI capabilities. With Blackwell, it will be common for these clusters to start with 100,000 GPUs or more. Shipments have already started for multiple infrastructures of this size. Post-training and model customization are fueling demand for NVIDIA Corporation infrastructure and software as developers and enterprises leverage techniques such as fine-tuning, reinforcement learning, and distillation to tailor models for domain-specific use cases. Hugging Face alone hosts over 90,000 derivatives traded from the Llama Foundation model. The scale of post-training and model customization is massive and can collectively demand orders of magnitude more compute than pretraining. Our inference demand is accelerating. Driven by test time scaling and new reasoning models. Like OpenAI's O3, DeepSeq R1, and Grok 3. Long-thinking reasoning AI can require 100x more compute per task compared to one-shot inferences. Blackwell was architected for reasoning AI inference. Blackwell supercharges reasoning AI models with up to 25x higher token throughput and 20x lower cost versus Hopper 100. It is revolutionary. Transformer engine is built for LLM. And mixer of experts inference. And its NVLink domain delivers 14x the throughput of PCIe Gen 5. Ensuring the response time, throughput, and cost efficiency needed to tackle the growing complexity of inferences scale. Companies across industries are tapping into NVIDIA Corporation's full-stack inference platform to boost performance and slash cost. Now tripled inference throughput and cut cost by 66% using NVIDIA Corporation TensorRT for its screenshot feature. Perplexity sees 435 million monthly queries and reduced its inference costs 3x with NVIDIA Corporation Triton inference server and TensorRT LLM. Microsoft Bing achieved a 5x speedup at major TCO savings for visual search across billions of images with NVIDIA Corporation, TensorRT, and acceleration libraries. Blackwell has great demand for inference. Many of the early GV200 deployments are earmarked for inference. A first for a new architecture. Blackwell addresses the entire AI market from pretraining, post-training, to inference across clouds, to on-premise, to enterprise. Its programmable architecture accelerates every AI model and over 4,400 applications ensuring large infrastructure investments against obsolescence in rapidly evolving markets. Our performance and pace of innovation are unmatched. We're driven to a 200% reduction in inference cost in just the last two years. We delivered the lowest TCO and the highest ROI. And full-stack optimizations for NVIDIA Corporation and our large ecosystem including 5.9 million developers continuously improve our customers' economics. In Q4, large CSPs represented about half of our data center revenue. And these sales increased nearly 2x year on year. Large CSPs were some of the first to stand up Blackwell, with Azure, GCP, AWS, and OCI, bringing GV200 systems to cloud regions around the world to meet surging customer demand for AI. Regional cloud hosting NVIDIA Corporation GPUs increased as a percentage of data center revenue. Reflecting continued AI factory build-outs globally and rapidly rising demand for AI reasoning models and agents. Coreweave launched a 100,000 GV200 cluster-based instance with NVLink switch and Quantum-2 InfiniBand. Consumer Internet revenue grew 3x year on year. Driven by an expanding set of generative AI and deep learning use cases. These include recommender systems, vision language understanding, synthetic data generation search, and agentic AI. For example, XAI is adopting the GV200 to train and inference its next generation of Grok AI models. Meta's cutting-edge Andromeda, advertising engine runs on NVIDIA Corporation's Grace Hopper Superchip. Serving vast quantities of ads across Instagram, Facebook applications. Andromeda harnesses Grace Hopper's fast interconnect and large memory to boost inference, throughput by 3x. Enhanced ad personalization, and deliver meaningful jumps in monetization and ROI. Enterprise revenue increased nearly 2x year on accelerating demand model fine-tuning. Agentic AI workflows. And GPU-accelerated data processing. We introduced NVIDIA Corporation Llama Numitron model family nodes to help developers create and deploy AI agents across a range of applications, including customer support, fraud detection, and product supply chain and inventory management. Leading AI agent platform providers, including SAP and ServiceNow, are among the first to use new models. Health care leaders, IQVIA, and Lumenon. And Mayo Clinic as well as ARC and Institute are using NVIDIA Corporation AI to speed drug discovery enhance genomic research, and pioneer advanced health care services with generative and agentic AI. As AI expands beyond the digital world, NVIDIA Corporation infrastructure and software platforms are increasingly being adopted to power robotics and physical AI development. One of the early and largest robotics applications and autonomous vehicles were virtually every AV company is developing on NVIDIA Corporation, in the data center. NVIDIA Corporation's automotive vertical revenue is expected to grow to approximately $5 billion this fiscal year. At CES, Hyundai Motor Group announced it is adopting NVIDIA Corporation Technologies to accelerate AV and robotics development and smart factory initiatives. Vision transformers, self-supervised learning, multimodal sensor fusion, and high-fidelity simulation are driving breakthroughs in AV development and will require 10x more compute. At TDX, we announced the NVIDIA Corporation Cosmos World foundation model platform. Just as language foundation models have revolutionized language AI, Cosmos is a physical AI to revolutionize robotics. The robotics and automotive companies, including ride-sharing giant Uber, are among the first to adopt the platform. From a geographic perspective, sequential growth in our data center revenue was strongest in the US, driven by the initial ramp of Blackwell. Countries across the globe are building their AI ecosystems and demand for compute infrastructure is surging. France's \u20ac200 billion AI investment and the EU's \u20ac200 billion Invest AI initiative offer a glimpse into the build-out that will redefine global AI infrastructure in the coming years. Now as a percentage of total data center revenue, data center sales in China remained well below levels seen onset of export controls. China shipments absent any change in regulations, we believe that will remain roughly at the current percentage. The market in China for data center solutions remained very competitive. We will continue to comply with export controls while serving our customers. Networking revenue declined 3% sequentially. Our networking attached to GPU compute systems is robust at over 75%. We are transitioning from small NVLink 8 with InfiniBand to large NVLink 72. The Spectrum X. Spectrum X and NVLink switch revenue increased and represents a major new growth sector. We expect networking a return to growth in Q1. AI requires a new class of networking. NVIDIA Corporation offers NVLink switch systems for scale of compute. For scale out, we offer Quantum InfiniBand for HPC supercomputers, and SpectrumX for Ethernet environments. Spectrum X enhances the Ethernet for AI computing and has been a huge success. Microsoft Azure OCI, Fortease, and others are building large AI factories with SpectrumX. The first Stargate data centers will use Spectrum X. Yesterday, Cisco announced integrating Spectrum X into their networking portfolio to help enterprises build AI infrastructure. With its large enterprise footprint and global reach, Cisco will bring NVIDIA Corporation Ethernet to every industry. Now moving to gaming and AR PCs. Gaming revenue of $2.5 billion decreased 22% sequentially and 11% year on year. Full year revenue of $11.4 billion increased 9% year on year. And demand remains strong throughout the holiday. However, Q4 shipments were impacted by supply constraints. We expect strong sequential growth in Q1 as supply increases. The new GeForce RTX 50 series desktop and laptop GPUs are here. Built for gamers, creators, and developers, they fuse AI and graphics, redefining visual computing. Powered by the Blackwell architecture, fifth-generation tensor cores, and fourth-generation RT cores and featuring up to 3,400 AI TOPS. These GPUs deliver a 2x performance leap and new AI-driven rendering, including neural shaders, digital human technologies, geometry, and lighting. The new DLSS 4 boosts frame rates up to 8x with AI-driven frame generation turning one rendered frame into three. It also features the industry's first real-time application of transformer models packing 2x more parameters and 4x to compute unprecedented visual fidelity. We also announced a wave of GeForce Blackwell laptop GPUs with new NVIDIA Corporation Max-Q technology that extends battery life, by up to an incredible 40%. These laptops will be available starting in March from the world's top manufacturers. Moving to our professional visualization business. Revenue of $511 million was up 5% sequentially and 10% year on year. Full year revenue of $1.9 billion increased 21% year on year. Key industry verticals driving demand include automotive and health care. NVIDIA Corporation Technologies and generative AI are reshaping design engineering, and simulation workloads. Increasingly, these technologies are being leveraged in leading software platforms. From ANSYS, Cadence, and Siemens fueling demand for NVIDIA Corporation RTX workstations. Now moving to automotive. Revenue was a record $570 million, up 27% sequentially and up 103% year on year. Full year revenue of $1.7 billion increased 55% year on year. Strong growth was driven by the continued ramp in autonomous vehicles, including cars and robotaxis. At CES, we announced Toyota the world's largest automaker will build its next generation vehicles on NVIDIA Corporation Oren, running the safety-certified NVIDIA Corporation Drive OS. We announced Aurora and Continental. Will deploy driverless trucks at scale powered by NVIDIA Corporation Drive 4. Finally, our end-to-end autonomous vehicle platform, NVIDIA Corporation DRIVE Hyperion, has passed industry safety assessments by Ryland, two of the industry's foremost authorities, automotive-grade safety and cybersecurity, NVIDIA Corporation is the first AV platform to receive a comprehensive set of third-party assessments. Moving to the rest of the P&L. GAAP gross margins, was 73%. And non-GAAP gross margins were 73.5%. Down sequentially as expected with our first deliveries of the Blackwell architecture. As discussed last quarter, Blackwell is a customizable AI infrastructure with several different types of NVIDIA Corporation build chips. Multiple networking options, and for air and liquid-cooled data center. We exceeded our expectations in Q4, in ramping Blackwell, increasing system availability, providing several configurations to our customers. As Blackwell ramps, we expect gross margins to be in the low seventies. We initially, we are focused on expediting the manufacture as they race to build out Blackwell infrastructure. When fully ramped, we have many opportunities to improve the cost and gross margin. Will improve and return to the mid-seventies. Late this fiscal year. Sequentially, GAAP operating expenses were up 9% and non-GAAP operating expenses were 11%, reflecting higher engineering development costs and higher compute and infrastructure costs for new product introductions. In Q4, we returned $8.1 billion to shareholders, the form of share repurchases cash dividends. Let me turn to the outlook in the first quarter. Total revenue is expected to be $43 billion. Plus or minus 2%. Continuing with its strong demand, we expect a significant ramp of Blackwell in Q1. We expect sequential growth. In both data center and gaming. Within data center, we expect sequential growth from both. Compute and networking. GAAP and non-GAAP gross margins are expected to be 70.6%. And 71% respectively. Plus or minus 50 basis points. GAAP and non-GAAP operating expenses are expected to be approximately $5.2 billion and $3.6 billion. We expect full year fiscal year 2026 operating expenses grow to grow to be in the mid-thirties. GAAP and non-GAAP other incoming expenses are expected to be an income of approximately $400 million. Excluding gains and losses, from non-marketable and publicly held equity securities. GAAP and non-GAAP tax rates are expected to be 17% plus or minus 1% excluding any discrete items. Further financial details are included in the CFO commentary and other information available on our IR website. Including a new financial information AI agent. In closing, let me highlight upcoming events for the financial community. We will be at the TD Cowen Healthcare Conference in Boston on March 3rd. And at the Morgan Stanley Technology, Media, and Telecom Conference in San Francisco. On March 5th. Please join us for our annual GTC conference starting Monday, March 17th, in San Jose, California. Jensen will deliver a news-packed keynote on March 18th, and we will host a Q&A session for our financial analysts. Next day, March 19th. We look forward to seeing you at these events. Our earnings call to discuss the results for our first quarter of fiscal 2026 is scheduled for May 28th, 2025. We are going to open up the call, operator. To questions. If you could start that, that would be great.\nChrista: Thank you. At this time, I would like I also ask that you please limit yourself to one question. For any additional questions, please requeue. And your first question comes from C.J. Muse with Cantor Fitzgerald. Please go ahead.\nC.J. Muse: Yeah. Good afternoon. Thank you for taking the question. I guess, for me, Jensen, as test time compute and reinforcement learning shows such promise, we're clearly seeing increasing blurring in the lines between training and inference. What does this mean for the potential future of potentially inference-dedicated clusters? And how do you think about the overall impact to NVIDIA Corporation and your customers? Thank you.\nJensen Huang: Yeah. I appreciate that, C.J. There are now multiple scaling laws. There's the pretrained scaling laws. And that's gonna continue to scale because we have multimodality. We have data that came from reasoning that are now used to pretraining. And then the second is post-training scaling law. Using reinforcement learning human feedback, reinforcement learning AI feedback, reinforcement learning verifiable rewards, the amount of computation you use for post-training is actually higher than pretraining. And it's kinda sensible in the sense that you could while you're using reinforcement learning, generate an enormous amount of synthetic data or synthetically generated tokens. AI models are basically generating tokens to train AI models. That's post-train. And the third part, this is the part that you mentioned, is test time compute or reasoning. Long thinking, inference scaling, basically the same ideas. And there's you have chain of thought, you have search. The amount of tokens generated, the amount of inference compute needed, is already a hundred times more than the one-shot examples and the one-shot capabilities of large language models in the beginning and that's just the beginning. This is just the beginning. The idea that the next generation could have thousands of times and even hopefully extremely thoughtful and simulation-based and search-based models that could be hundreds of thousands, millions of times more compute than today, is in our future. And so the question is how do you design such an architecture? Some of the models are autoregressive. Some of the models are diffusion-based. Some of the times you want your data center to have disaggregated inference. Sometimes it's compacted. And so it's hard to figure out what is the best configuration of a data center, which is the reason why NVIDIA Corporation's architecture is so popular. We run every model. We are great at training. The vast majority of our compute today is actually inference, and Blackwell takes all of that to a new level. We designed Blackwell with the idea of reasoning models in mind. And you look at training, it's many times more performant. But what's really amazing is for long-thinking, test time scaling reasoning AI models, we're tens of times faster, 25 times higher throughput. And so Blackwell is gonna be incredible across the board. And when you have a data center, that allows you to configure and use your data center based on are you doing more pretraining now, post-training now? Or scaling out your inference our architecture is fungible, and easy to use. In all of those different ways. And so we're seeing, in fact, much, much more concentration of a unified architecture than ever before.\nChrista: Your next question comes from the line of Joseph Moore with JPMorgan. Please go ahead.\nJoseph Moore: I wonder if you could talk about GV200 at CES. You sort of talked about the complexity of the rack-level systems and the challenges you have. And then as you said in the prepared remarks, we've seen a lot of general availability. You know, where are you in terms of that ramp? Are there still bottlenecks to consider at a systems level above and beyond the chip level? And just you know, have you maintained your enthusiasm for the NVLink 72 platforms?\nJensen Huang: Well, I'm more enthusiastic today than I was at CES. And the reason for that is because we shipped a lot more to CES. We have some 350 plants manufacturing the one and a half million components that go into each one of the Blackwell racks. Base Blackwell racks. Yes. It's extremely complicated. And we successfully and incredibly ramped up Grace Blackwell. Delivering some $11 billion of revenues last quarter. We're gonna have to continue to scale as demand is quite high and customers are anxious and impatient to get their Blackwell systems. You'd probably seen on the web a fair number of celebrations about Grace Blackwell Systems coming online and we have them, of course. We have a fairly large installation of Grace Blackwell for our own engineering and our own design teams and software teams. Coreweave has now gone public about the successful bring-up of theirs. Microsoft has. Of course, OpenAI has. And you're starting to see many come online. So I think the answer to your question is nothing is easy about what we're doing. But we're doing great, and all of our partners are doing great.\nChrista: Your next question comes from the line of Vivek Arya with Bank of America Securities. Please go ahead.\nVivek Arya: Thank you for taking my question. Could I just you wouldn't mind confirming if Q1 is the bottom for gross margins? And then, Jensen, my question is for you. What is on your dashboard to give you the confidence that the strong demand can sustain into next year and has DeepSeq and whatever innovations they came up with, has that changed that view in any way? Thank you.\nColette Kress: Let me first take the first part of the question. Regarding the gross margin. During our Blackwell ramp, our gross margins will be in the low seventies. At this point, we are focusing on expediting our manufacturing. Expediting our manufacturing is to make sure that we can provide customers as soon as possible. Our Blackwell is fully ramped. And once it does, I'm sorry. Blackwell fully ramps, we can improve our cost and our gross margin. So we expect to probably be in the mid-seventies later this year. You know, walking through what you heard, Jensen speak about the systems and their complexity. They are customizable in some cases. They've got multiple networking options. Have liquid cool and water-cooled. So we know there is an opportunity for us to improve these gross margins going forward. But right now, we are gonna focus on getting the manufacturing plate into our customers as soon as possible.\nJensen Huang: We know several things, Vivek. We have a fairly good line of sight of the amount of capital investment that data centers are building out towards. We know that going forward, the vast majority of software is gonna be based on machine learning. And so accelerated computing and generative AI, reasoning AI, are going to be the type of architecture you want in your data center. We have, of course, forecast and plans from our top partners. And we also know that there are many innovative really exciting start-ups that are still coming online. As new opportunities for developing the next breakthroughs in AI, whether it's agentic AIs, reasoning AIs, or physical AIs. The number of start-ups are still quite vibrant and each one of them needs a fair amount of computing infrastructure. So I think the whether it's the near-term signals or the mid-term signals. Near-term signals, of course, are, you know, POs and forecasts and things like that. Mid-term signals, would be the level of infrastructure and CapEx scale out compared to previous years. And then the long-term signals it has to do with the fact that we know fundamentally software has changed. From hand coding that runs on CPUs through machine learning and AI-based software that runs on GPUs and accelerated computing systems. So we have a fairly good sense that this is the future of software. And then maybe as you roll it out, another way to think about that is we've really only touched consumer AI and search and some amount of consumer generative AI. Advertising, recommenders, kind of the early days of software. The next wave's coming. Agentic AI for enterprise, physical AI for robotics. And Sovereign AI has different regions build out their AI for their own ecosystems. And so each one of these are barely off the ground, and we can see them. We can see them because, you know, obviously, we're in the center of much of this development. And we can see great activity happening in all these different places. And these will happen. So near-term, mid-term, long-term.\nChrista: Your next question comes from the line of Matt Ramsay with Cowen. Please go ahead.\nMatt Ramsay: Yeah. Good afternoon. Thanks for taking my question. Your next generation Blackwell Ultra is set to launch in the second half of this year. In line with the team's annual product cadence. Jensen, can you help us understand the demand dynamics for Ultra given that you'll still be ramping the current generation Blackwell solutions? How do your customers and the supply chain also manage the simultaneous ramps of these two products and is the team still on track to execute Blackwell Ultra in the second half of this year?\nJensen Huang: Yes. Blackwell Ultra is second half. As you know, the first Blackwell was have we had a hiccup? That probably cost us a couple of months. We're fully recovered, of course. The team did an amazing job recovery. And all of our supply chain partners and just so many people helped us recover at the speed of light. And so now we've successfully ramped production of Blackwell. But that doesn't stop the next train. The next train is you know, it's on an annual rhythm. And, Blackwell Ultra with, new networking, new memories, and, of course, new processors and all of that is coming online. We've been working with all of our partners and customers laying this out. They have all of the necessary information. And we'll work with everybody to do the proper transition. This time between Blackwell, Blackwell Ultra, the system architecture is exactly the same. It's a lot harder going from Hopper to Blackwell because we went from an NVLink 8 system to a NVLink 72 base system. So the chassis, the architecture of the system, the hardware, the power delivery, all of that had to change. This was quite a challenging transition. But the next transition will slot right in. Grace Blackwell Ultra will slot right in. We've also already revealed and been working very closely with all of our partners on the click after that. And the click after that is called Vera Rubin. And, all of our partners are getting up to speed on the transition of that. And so preparing for that transition and, again, we're gonna provide a big, big, huge step up. And so come to GTC, and I'll hold on to you about Blackwell Ultra, Vera Rubin, and then show you what's the one click after that. Really, really exciting new product, so come to GTC, please.\nChrista: Your next question comes from the line of Timothy Arcuri with UBS. Please go ahead.\nTimothy Arcuri: Thanks a lot. Jensen, we hear a lot about custom ASICs. Can you kinda speak to the balance between custom ASIC and merchant GPU? We hear about some of these heterogeneous super clusters to use both GPU and ASIC. Is that something customers are planning on building or will these infrastructures remain fairly distinct? Thanks.\nJensen Huang: Well, we build very different things than ASICs. In some ways, completely different in some areas we intercept. We're different in several ways. One, NVIDIA Corporation's architecture is general. You know, whether you've optimized for autoregressive models or diffusion-based models or vision-based models or multimodal models or text models. We're great in all of it. We're great in all of it because our software stack is so our architecture is responsible. Our software stack is ecosystem is so rich that we're the initial target of, you know, most exciting innovations and algorithms. And so by definition, we're much, much more general than narrow. We're also really good from the end to end. From data processing, the curation of the training data, to the training of the data, of course, to reinforcement learning used in post-training. All the way to inference with test time scaling. So, you know, we're general. We're end to end. And we're everywhere. And because we're not in just one cloud, we're in every cloud, we could be on-prem. We could be in, you know, in a robot. Our architecture is much more accessible. And a great target initial target for anybody who's starting up a new company. And so we're everywhere. And then the third thing I would say is that our performance and our rhythm is so incredibly fast. Remember that these data centers are always fixed in size. They're fixed in size or they're fixed in power. And if our performance per watt is anywhere from 2x to 4x to 8x, which is not unusual. It translates directly to revenues. And so if you have a 100-megawatt data center, if the performance or the throughput that 100-megawatt or that gigawatt data center is four times or eight times higher your revenues for that gigawatt data center is eight times higher. And the reason that is so different than data centers of the past is because AI factories are directly monetizable through its tokens generated. And so the token throughput of our architecture being so incredibly fast is just incredibly valuable to all of the companies that are building these things for revenue generation reasons. And capturing the fast ROIs. So I think the third reason is performance. And then the last thing that I would say is the software stack is incredibly hard. Building an ASIC is no different than what we do. We have to build a new architecture. And the ecosystem that sits on top of our architecture is ten times more complex today than it was two years ago. And that's fairly obvious because the amount of software this world building on top of architecture is growing exponentially and AI is advancing very quickly. So bringing that whole ecosystem on top of multiple chips is hard. And so I would say that those four reasons and then finally, I will say this. Just because the chip is designed doesn't mean it gets deployed. And you've seen this over and over again. There are a lot of chips that get built. But when the time comes a business decision has to be made. And that business decision is about deploying a new engine, a new processor into a limited AI factory in size and power and find. And our technology is, you know, not only more advanced, more performant, it has much, much better software capability, and very importantly, our ability to deploy is lightning fast. And so these things are enough for the faint of heart as everybody knows now. And so there's a lot of different reasons why we do well. Why we win.\nChrista: Your next question comes from the line of Ben Reitzes with Melius Research. Please go ahead.\nBen Reitzes: Yeah. Hi. Ben Reitzes here. Hey. Thanks a lot for the question. Hey, Jensen. It's a geography-related question. You know, you did a great job explaining some of the demand underlying, you know, factors here on the strength. But the US was up about $5 billion or so sequentially. And I think, you know, there is a concern about whether the US can pick up the slack if there's regulations towards other geographies. And I was just wondering as we go throughout the year, you know, if this kind of surge in the US continues and it's gonna be whether that's okay. And if that underlies your growth rate, how can you keep growing so fast with this mix shift towards the US? Your guidance looks like China is probably up sequentially. So just wondering if you could go through that dynamic and maybe Colette can weigh in. Thanks a lot.\nJensen Huang: China is approximately the same percentage as Q4. And as in as previous quarters. It's about half of what it was before the export control. But it's approximately the same in percentage. With respect to geographies, the takeaway is that AI is software. It's modern software. It's incredible modern software. But it's modern software. And AI has gone mainstream. AI is used in delivery services everywhere, shopping services everywhere. You know? You were to buy a quart of milk is delivered to you. AI was involved. And so almost everything that a consumer service provides AI's at the core of it. Every student will use AI as a tutor. Health care services use AI. Financial services use AI. No fintech company will not use AI. Every fintech company will. Climate tech company uses AI. Mineral Discovery now uses AI. The number of every higher education, every university, uses AI. So I think it is fairly safe to say that AI has gone mainstream. And that it's being integrated into every application. And our hope is that, of course, the technology continues to advance safely and advance in a helpful way to our society. And with that, you know, we're I do believe that we're at the beginning of this new transition. And what I mean by that in the beginning, is remember behind us has been decades of data centers and decades of computers that have been built. And they've been built for a world of hand coding and general-purpose computing. And CPUs and so on and so forth. And going forward, I think it's fairly safe to say that that world is going to be almost all software will be infused with AI. All software and all services will be based on ultimately based on machine learning, and the data flywheel is gonna part of improving software and services. And that the future computers will be accelerated. The future computers will be based on AI. And we're really three years into that journey. And in modernizing computers that have taken decades to build out. And so I'm fairly sure that we're in the beginning of this new era. And then lastly, no technology has ever had the opportunity to address a larger part of the world's GDP than AI. No software tool ever has. And so this is now a software tool that can address a much larger part of the world's GDP, more than any time in history. And so the way we think about growth and the way we think about whether something is big or small. Has to be in the context of that. And when you take a step back and look at it from that perspective, we're really just in the beginnings.\nChrista: Your next question comes from the line of Aaron Rakers with Wells Fargo. Please go ahead. Erin, your line is open. Your next question comes from Mark Lipacis with Evercore ISI. Please go ahead.\nMarshall Pappas: Hi. This is Marshall Pappas. Thanks for taking the question. Question. I had a clarification and a question. Colette, for the clarification. Did you say that enterprise within the data center grew 2x year on year for the January quarter? And if so, does that would that make it the faster growing than the hyperscalers? And then, Jensen, for you, the question, hyperscalers are the biggest purchasers of your solutions, but they buy equipment for both internal and external workloads, external workloads being cloud services that enterprises use. So the question is, can you give us a sense of how that hyperscale expense splits between that external workload and internal and as these new AI workflows and applications come up, would you expect enterprises to become a larger part of that consumption mix? And does that impact how you develop your service your ecosystem? Thank you.\nColette Kress: Sure. Thanks for the question regarding our enterprise business. Yes. It grew 2x. Very similar to what we were seeing with our large CSPs. Keep in mind, these are both important areas to understand. Working with the CSPs can be working on large language models. Can be working on inference on their own work? But keep in mind, that is also where the enterprises are surfacing. Your enterprises are both with your CSPs, as well as in terms of building on their own. They're both growing quite well.\nJensen Huang: The CSPs are about half of our business. And the CSPs have internal consumption, and external consumption, as you say. And we're using of course, used for internal consumption. We work very closely with all of them to optimize workloads that are internal to them because they have a large infrastructure of NVIDIA Corporation gear that they could take advantage of. And the fact that we could be used for AI on the one hand, video processing on the other hand, data processing like Spark. We're fungible. And so the useful life. Our infrastructure is much better. If the useful life is much longer, then the TCO is also lower. And so the second part is how do we see the growth of enterprise or not CSPs, if you will, going forward? And the answer is I believe, long term. It is by far larger. And the reason for that is because if you look at the computer industry today, and what is not served by the computer industry is largely industrial. Let me give you an example. When we say enterprise, and let's say let's use a car company as an example because they make both soft things and hard things. And so in the case of a car company, the employees would be what we call enterprise. And agentic AI and software planning systems and tools, and we have some really exciting things to with you guys at GTC. Those agentic systems are for employees to make employees more productive. To design, to market, plan, to operate their company. That's agentic AIs. On the other hand, the cars that they manufacture also need AI. They need an AI system that trains the cars treats this entire giant fleet of cars, and you know, today, there's some billion cars on the road. Someday, there'd be a billion cars on the road, and every single one of those cars will be, you know, robotic cars. And they'll all be collecting data, and we'll be improving them using an AI factory where they whereas they have a car factory today, in the future, they'll have a car factory and an AI factory. And then inside the car itself is a robotic system. And so as you can see, there are three computers involved. And there's the computer that helps the people. There's the computer that builds the AI for it. The machineries. It could be, of course. Could be a tractor. It could be a lawnmower. It could be a human or a robot that's being developed today. It could be a building. It could be a warehouse. These physical systems require a new type of AI we call physical AI. They can't just understand the meaning of words and languages but they have to understand the meaning of the world. Friction and inertia, object permanence, and cause and effect, and all of those types of things that are common sense to you and I. But you know, AI has to go learn those physical effects. So we call that physical AI. That whole part of using agentic AI to revolutionize the way we work inside companies. That's just starting. This is now the beginning of the agentic AI era. And you hear a lot of people talking about it and got some really great things going on. And then there's the physical AI after that, and then there's robotic systems after that. And so these three computers are all brand new. And my sense is that long term, this will be by far a larger of a mold which kinda makes sense. You know, the world the world's GDP is represented by either heavy industries industrials. And companies that are providing for those.\nChrista: Your next question comes from the line of Aaron Rakers with Wells Fargo. Please go ahead.\nAaron Rakers: Yeah. Thanks for letting me back in. Jensen, I'm curious as we now approach the two-year anniversary of really the Hopper inflection that you saw in 2023 in Gen AI in general. We think about the roadmap you have in front of us, how do you think about the infrastructure that's been deployed from a replacement cycle perspective and whether, you know, if it's GV300 or if it's the Rubin cycle where we start to see maybe some refresh opportunity. I'm just curious to how you look at that.\nJensen Huang: Yeah. I appreciate it. First of all, people are still using Voltas. And Pascals, and Amperes. And the reason for that is because they're always things that because CUDA is so programmable, you could use it right well, one of the major use cases right now is data processing and data curation. You find a circumstance that an AI model is not very good at? You present that circumstance to a vision language model, let's say. Let's say it's a car? You present that circumstance to a vision language model, the vision language model actually looks at the circumstances. It's a this isn't this is what happened, and I wasn't very good at it. You then take that response, this the prompt, and you go and prompt an AI model to go find in your whole link of data of other circumstances like that. Whatever that circumstance was. And then you use an AI to do domain randomization and generate a whole bunch of other examples. And then from that, you can go train the model. And so you could use the Amperes to go and do data processing and data curation and machine learning-based search. And then you create the training dataset, which you then present to your Hopper systems for training. And so each one of these architectures are completely are you know, they're all CUDA compatible, and so everything runs on everything. But if you have infrastructure in place, and you can put the less intensive workloads onto the installed base of the past. All of our CPUs are very well employed.\nChrista: We have time for one more question, and that question comes from Atif Malik with Citi. Please go ahead.\nAtif Malik: Hi. Thank you for taking my question. I have a follow-up question on gross margins, Colette. I understand there are many moving parts that will yield and NVLink 72 and Ethernet mix. And you kind of tiptoed the earlier question if April quarter is the bottom. But second half would have to ramp, like, 200 basis point per quarter to get to the mid-seventies range that you're giving, for the end of the fiscal year. And we still don't know much about tariffs impact to broader semiconductor. So what kind of gives you the confidence in that trajectory in the back half of this year?\nColette Kress: Yeah. Thanks for the question. Our gross margins, they're quite complex. In terms of the material. And everything that we put together in a Blackwell system. Tremendous amount of opportunity to look at a lot of different pieces of that. On how we can better improve our gross margins over time. Remember, we have many different configurations as well. On Blackwell. That will be able to help us do that. So, together, working after we get some of these really strong ramping completed for our customers we can begin a lot of that work. If not, we're gonna probably start as soon as possible. If we can improve it in the short term, we will also do that. Tariffs, at this point, it's a little bit of an unknown. It's an unknown until we understand further what the US government's plan is, its timing, it's where, and how much. So at this time, we are awaiting but again, we would, of course, always follow export control and or tariffs in that manner.\nChrista: Ladies and gentlemen, that does conclude our question and answer session. I'm sorry. Thank you.\nJensen Huang: No. No. I'm gonna just wanna thank you. Up to, Jensen? And, like, the medium, a couple things. I just wanna thank you. Thank you, Colette. Demand for Blackwell is extraordinary. AI is evolving beyond perception. And generative AI into reasoning. With reasoning AI, we're observing another scaling law. Inference time or test time scaling. The more computation the more the model thinks the smarter the answer. Models like OpenAI's Grok 3, DeepSeq R1, are reasoning models that apply inference time scale. Reasoning models can consume a hundred times more compute. Future reasoning models can consume much more compute. DeepSeq R1 has ignited global enthusiasm. It's an excellent innovation. But even more importantly, it has open-sourced a world-class reasoning AI model. Nearly every AI developer is applying R1. Or chain of thought and reinforcement learning techniques like R1. To scale their model's performance. We now have three scaling laws, as I mentioned earlier. Driving the demand for AI computing. The traditional scaling laws of AI remain intact. Foundation models are being enhanced with multimodality. And pretraining is still growing. But it's no longer enough. We have two additional scaling dimensions. Post-training scaling, where reinforcement learning fine-tuning, model distillation, require orders of magnitude more compute than pretraining alone. Inference time scaling and reasoning where a single query can demand a hundred times more compute. We designed Blackwell for this moment a single platform that can easily transition from pretraining, post-training, and test time scaling. Blackwell's MP4 transformer engine, and NVLink 72 scale-up fabric. And new software technologies let Blackwell process reasoning AI models 25 times faster than Hopper. Blackwell, in all of these configurations, is in full production. Each Grace Blackwell NVLink 72 rack is an engineering marvel. One and a half million components produced across 350 manufacturing sites by nearly a hundred thousand factory operators. AI is advancing at light speed. We're at the beginning of reasoning AI and inference time scaling. But we're just at the start of the age of AI. Multimodal AIs. Enterprise AI, Sovereign AI. And physical AI are right around the corner. We will grow strongly in 2025. Going forward, data centers will dedicate most of CapEx to accelerated computing and AI. Data centers will increasingly become AI factories. And every company will have a either rented or self-operated. I wanna thank all of you for joining us today. Come join us at GTC in a couple of weeks gonna be talking about Blackwell Ultra, Rubin, and other new computing networking, reasoning AI, physical AI products. And a whole bunch more. Thank you.\nChrista: This concludes today's conference call. You may now disconnect.",
  "generated_at": "2025-03-10T18:48:19.474953"
}